{
    "Q1": {
        "從1903版起，Windows 10更新要佔用7GB的磁碟空間確保安裝成功 ": "在下一個Windows重大更新中，為確保安裝過程順利，Windows會主動保留7GB的磁碟空間，以供系統更新、Windows應用程式、暫存檔、系統快取之用。去年1809版Windows 10更新釋出之前，微軟提醒用戶要注意磁碟容量，但並未說明要多少。周二微軟指出，從1903版開始，Windows 10更新會主動在用戶磁碟保留7GB空間，以確保順利安裝更新。微軟指出，從下一次Windows 重大更新（1903版或191H）起，將有部份磁碟空間會被挪為更新、Windows應用程式、暫存檔和系統快取所用。如果不這麼做，當用戶磁碟快滿時，部份Windows功能及app跑起來就會變得不穩定。透過保留磁碟空間，上述這些就不會搶去PC上寶貴的磁碟空間，也能正常運作。微軟也指出，這個方法將能使未來Windows更新更順利。每版Windows更新下載前，都會要求PC騰出特定大小的磁碟並優先使用。開始更新時，在保留空間中不需要的OS檔案會被刪除，由更新使用整個空間。正常情況下Windows 不再佔用其他磁碟空間，但如果有必要，就會自動使用額外可用磁碟，要是還不夠，Windows會再引導用戶外接磁碟或清除檔案來取得足夠資源。至於要騰出多少空間，微軟預期大約7GB，但實際容量要視用戶日常使用狀況而定，例如今天的暫存檔可能會導致未來得保留更多磁碟空間。此外，微軟也可能依據電腦診斷資料及用戶意見來調整保留的空間。微軟提醒，保留的磁碟空間無法從作業系統移除，建議用戶透過移除不必要的功能和語言來降低保留的磁碟空間。預裝1903版的機器，或是全新安裝（clean install）1903的電腦則會自動啟用這項新措施。它會自動於背景執行，使用者什麼也不用做。這也意謂著，未來一些硬碟太小的小型運算裝置，像是僅採用32GB快閃磁碟的電腦安裝Windows 10更新就有碰到一些麻煩。這項新功能已經加入Windows測試版Build 18298，開發人員或企業IT可以加入Windows Insider測試計畫完成調查以試用本功能。2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "「無聲資料損毀」難防　Btrfs檔案系統來保護 ": "熱門搜尋 : 熱門搜尋 : 新世代檔案系統Btrfs最早是由Oracle在Linux上所開發，是一個基於寫入時複製（Copy-on-Write）的檔案系統。它採用GPLv2的授權方式，於Linux Kernel 2.6.29時合併入Linux Kernel主線，並在2014年時宣佈它的磁碟格式進入穩定版本。但其實它最早的發展歷程，要從2008年由當時任職IBM實驗室的Ohad Rodeh的一篇開創性論文開始（Ohad Rodeh. (2008, February). B-trees, Shadowing, and Clones. ACM Transactions on Storage (TOS), Volume 3 Issue 4, Article No. 2.）。該論文參考了當時幾個最先進的檔案系統如WAFL及ZFS上的寫入時複製（Copy-on-Write）技術，並將之套用在檔案系統常見的B-tree資料結構中。當時在Oracle服務的Chris Mason便根據這篇論文的研究成果開發出Btrfs，而他也從此成為Btrfs的主要開發者一直到現在。目前參與Btrfs開發的主要廠商包括Facebook、SUSE、Fujitsu及Oracle。從2015年開始，Btrfs成為SUSE Linux Enterprise的預設檔案系統。Ext4的主要開發者Theodore Ts'o曾表示：「雖然Ext4已經添加了不少新特性，不過那只是之前舊科技的延續，考慮到Btrfs所帶來在擴展性、可靠性、與管理便利性的進步，它將是檔案系統發展的下一步」。無所不在的無聲資料損毀（Silent Data Corruption）隨著儲存技術的進步，單位面積╱體積的儲存容量不斷提高，儲存成本持續地下降，為這個產業帶來前所未見的榮景。但隨著資料量不斷的成長，如何將它們長久且正確地保留下來，一直是個很有挑戰性的問題。造成儲存裝置資料錯誤的原因很多，例如硬碟運作時的震動、資料當初就到寫入錯誤的位置（Misdirected Write）或不完全寫入（Torn Write）、儲存單元不斷縮小造成的訊噪比下降、同時又要求高速讀寫，使得越來越難保證資料儲存的正確性。其實儲存裝置的韌體（Firmware）本身就具有一定的容錯能力，例如大多數硬碟都具備將壞軌重新映射到備用磁軌的能力。以現代常見的NAS專用硬碟來說，大約每11TiB的資料讀取，才會發生一次韌體無法修復的讀取錯誤。不過，使用這類修復機制的前提是，必須依賴儲存裝置能在讀寫時就察覺錯誤。在某些類型的錯誤中，硬體的讀寫操作其實有順利完成，但部分資料內容悄悄發生變化而損毀，以致於儲存裝置無法套用原本的修復機制，這類型的錯誤就稱為無聲資料損毀（Silent Data Corruption）。圖1即為一張照片發生無聲資料損毀後，翻轉一個Bit的結果（Bit rot、Bit flip）。雖然類似的無聲資料損毀並不是天天發生，但在資料量大的情況下，或是資料本身具有高價值，即使很低比例的無聲資料損毀，也會成為系統管理員必須認真考慮的一部分。事實上，無聲資料損毀有可能發生在系統的任何一地方。 一項由威斯康辛大學麥迪遜分校和NetApp合作的大型研究計畫，使用NetApp實際部署在客戶端的檔案伺服器，藉由軟體層為每個資料區塊（Data Block）記錄額外的Checksum來捕捉硬碟韌體所無法處理的資料損毀事件。研究結果顯示，150萬顆硬碟在41個月的運作期間，總計偵測到超過四十萬次的Checksum不一致事件。另一項由歐洲核子研究組織CERN資料中心所做的統計顯示，在約100PiB的資料流量中，有192MiB的資料發生無聲損毀。傳統RAID架構的限制一些對可靠度要求較高的儲存系統，經常會將數個儲存裝置組成RAID的架構，圖2所示即為一個常見含四顆硬碟的RAID-5陣列。當Disk A出現壞軌或是硬碟故障，即可用Disk B、C、D將資料復原，此架構已證實對一般明確的壞軌或是硬碟故障所造成的資料損毀非常有用。但對於硬體沒有回報錯誤的無聲資料損毀，這種傳統的RAID架構往往力不從心，主要的問題來自偵錯代價大、難以定位錯誤兩個方面。 \n\n\n\n1\n2\n3\n\n\n\n呼叫專業服務機器人！豹小秘神救援零接觸測溫老字號 IT 網管監控神器　大秀自動流程與智慧分析用多雲策略建構災備善用5G三大獨特性　生態系結盟創新模式應用阿里雲推馳雲計劃　為全球中小企提供援助並加快雲端科技應用電子簽名導入區塊鏈　實現最高的資料安全性防疫也防駭！企業遠端工作 4 大重點助持續營運數位鑑識須在不疑處有疑　僅靠靜態分析易陷盲點軟協新任理事長沈柏延上任　力助產業數位轉型兆勤科技聯手 McAfee　打造全面零死角資安解決方案搞懂ICMP協定及工具 抵擋「死亡之Ping」攻擊網路設備入門新手必讀 Cisco IOS最基礎教學建立VLAN邏輯分割網段  詳解交換器Trunk設定人臉辨識拓展金融市場　技術高下實測見分曉NAT穿透技術 從外部直接溝通私有IP路由協定基礎知識入門 詳解路由特性與分類從STP到RSTP　認識多重生成樹協定無類別區隔路由CIDR技術 依需求善用有限IP位址深入了解IP位址與子網路遮罩開源OpenKM文管系統 立即打造知識管理平台第171期2020年4月任意雲端、單一體驗，釋放資料價值之新IT儲存架構解析Dell Technologies儲存創新　引領轉型旅程高階儲存較勁　NVMe全面來襲追蹤我們Featrue us本站使用cookie及相關技術分析來改善使用者體驗。瞭解更多",
        "磁帶逆襲，挑戰摩爾定律 ": "熱門搜尋 : 熱門搜尋 : \r\n在半導體摩爾定律將死的時代，有一項「老科技」挺住各方唱衰，不僅穩定維持效能與容量增長，更在新時代找到關鍵定位，成為雲端與大數據環境中守護資料的最後防線。這項科技就是磁帶機。\r\n\r\n近二十年來隨著磁碟技術飛快進步，磁帶儲存系統每年都要被趨勢專家「賜死」，預言終將退出市場。時至今日，預言不僅沒有成真，磁帶儲存技術反而在雲端、大數據、AI所帶來的巨量資料洪流中，成為儲存冷資料的最佳選擇，同時也在資安威脅肆虐的網路環境中，為企業守住資料的最後一道防線。\r\n\r\n資料爆量，是磁帶機再度雄起的第一道助力。近年來雲端、大數據、物聯網技術成熟普及，資料增加的速度遠超過企業想像。IDC預測，全球資料量將在2025年達到160ZB的規模，是2016年的十倍！\r\n\r\n面對大數據與AI的時代，擁有數據就是擁有金礦。許多數據即使在當下沒有迫切用途，未來也可能成為資料淘金的重要來源。此外，由於個資管理與資料治理法規日趨嚴格，企業資料保存年限不斷拉長，種種內外因素加乘，資料的長期保存竟成為IT的隱性負擔。IT預算有限、任務無窮，資源必須優先投注於高價值的商業應用，沒有立即應用需求的「冷資料」勢必要用更具經濟性的方式來長期儲存。此時，每GB儲存成本僅有硬碟機六分之一的磁帶機，就成為企業最佳的選擇。\r\n\r\n多數人可能誤以為磁帶機是上個世紀的骨灰級技術，事實上，磁帶機技術持續進化，讀寫速度與容量穩定增加、成本也持續降低，表現比任何儲存媒介都更為優異。相較之下，磁碟技術則已面臨物理學極限。磁紀錄的最小單位被稱為「超順磁極限」，而硬碟技術幾已達到超順磁極限，單位面積的磁錄密度難以增加，磁片轉速也難以提升，這些拗口事實代表的意義就是：硬碟機容量即將到達極限，且單位儲存成本也無法像磁帶機般持續降低。因此，在可見的未來，磁帶機將是唯一能夠跟得上數據增長的儲存方案。\r\n\r\n面對日益猖獗的惡意攻擊，全球資安專家對於資料保護已有共識：企業組織不可能擋得下所有攻擊，但可以確保最核心的系統與數據不受損害，將破壞與損失降到最低。而其底線，就是「絕對不能讓資料陷入無法回復的絕境」。\r\n\r\n磁帶機就是這個防禦策略的最後一道防線，憑藉其離線儲存特性，在「即時數據」與「受保護數據」之間創造一個真空地帶，讓惡意者無法透過任何網路方式來存取或破壞這些關鍵資料。正因如此，磁帶成為世界各國企業組織存放珍貴史料、研發紀錄、客戶數據甚至國家機密的儲存載體成為極端狀況時最可信賴的資料後盾。\r\n\r\n\r\n\r\n\r\n＜本文作者：于伯琨現為IBM硬體系統事業部總經理＞\r\n\r\n    \r\n\r\n近二十年來隨著磁碟技術飛快進步，磁帶儲存系統每年都要被趨勢專家「賜死」，預言終將退出市場。時至今日，預言不僅沒有成真，磁帶儲存技術反而在雲端、大數據、AI所帶來的巨量資料洪流中，成為儲存冷資料的最佳選擇，同時也在資安威脅肆虐的網路環境中，為企業守住資料的最後一道防線。\r\n\r\n資料爆量，是磁帶機再度雄起的第一道助力。近年來雲端、大數據、物聯網技術成熟普及，資料增加的速度遠超過企業想像。IDC預測，全球資料量將在2025年達到160ZB的規模，是2016年的十倍！\r\n\r\n面對大數據與AI的時代，擁有數據就是擁有金礦。許多數據即使在當下沒有迫切用途，未來也可能成為資料淘金的重要來源。此外，由於個資管理與資料治理法規日趨嚴格，企業資料保存年限不斷拉長，種種內外因素加乘，資料的長期保存竟成為IT的隱性負擔。IT預算有限、任務無窮，資源必須優先投注於高價值的商業應用，沒有立即應用需求的「冷資料」勢必要用更具經濟性的方式來長期儲存。此時，每GB儲存成本僅有硬碟機六分之一的磁帶機，就成為企業最佳的選擇。\r\n\r\n多數人可能誤以為磁帶機是上個世紀的骨灰級技術，事實上，磁帶機技術持續進化，讀寫速度與容量穩定增加、成本也持續降低，表現比任何儲存媒介都更為優異。相較之下，磁碟技術則已面臨物理學極限。磁紀錄的最小單位被稱為「超順磁極限」，而硬碟技術幾已達到超順磁極限，單位面積的磁錄密度難以增加，磁片轉速也難以提升，這些拗口事實代表的意義就是：硬碟機容量即將到達極限，且單位儲存成本也無法像磁帶機般持續降低。因此，在可見的未來，磁帶機將是唯一能夠跟得上數據增長的儲存方案。\r\n\r\n面對日益猖獗的惡意攻擊，全球資安專家對於資料保護已有共識：企業組織不可能擋得下所有攻擊，但可以確保最核心的系統與數據不受損害，將破壞與損失降到最低。而其底線，就是「絕對不能讓資料陷入無法回復的絕境」。\r\n\r\n磁帶機就是這個防禦策略的最後一道防線，憑藉其離線儲存特性，在「即時數據」與「受保護數據」之間創造一個真空地帶，讓惡意者無法透過任何網路方式來存取或破壞這些關鍵資料。正因如此，磁帶成為世界各國企業組織存放珍貴史料、研發紀錄、客戶數據甚至國家機密的儲存載體成為極端狀況時最可信賴的資料後盾。\r\n\r\n\r\n\r\n\r\n＜本文作者：于伯琨現為IBM硬體系統事業部總經理＞\r\n\r\n    \r\n\r\n資料爆量，是磁帶機再度雄起的第一道助力。近年來雲端、大數據、物聯網技術成熟普及，資料增加的速度遠超過企業想像。IDC預測，全球資料量將在2025年達到160ZB的規模，是2016年的十倍！\r\n\r\n面對大數據與AI的時代，擁有數據就是擁有金礦。許多數據即使在當下沒有迫切用途，未來也可能成為資料淘金的重要來源。此外，由於個資管理與資料治理法規日趨嚴格，企業資料保存年限不斷拉長，種種內外因素加乘，資料的長期保存竟成為IT的隱性負擔。IT預算有限、任務無窮，資源必須優先投注於高價值的商業應用，沒有立即應用需求的「冷資料」勢必要用更具經濟性的方式來長期儲存。此時，每GB儲存成本僅有硬碟機六分之一的磁帶機，就成為企業最佳的選擇。\r\n\r\n多數人可能誤以為磁帶機是上個世紀的骨灰級技術，事實上，磁帶機技術持續進化，讀寫速度與容量穩定增加、成本也持續降低，表現比任何儲存媒介都更為優異。相較之下，磁碟技術則已面臨物理學極限。磁紀錄的最小單位被稱為「超順磁極限」，而硬碟技術幾已達到超順磁極限，單位面積的磁錄密度難以增加，磁片轉速也難以提升，這些拗口事實代表的意義就是：硬碟機容量即將到達極限，且單位儲存成本也無法像磁帶機般持續降低。因此，在可見的未來，磁帶機將是唯一能夠跟得上數據增長的儲存方案。\r\n\r\n面對日益猖獗的惡意攻擊，全球資安專家對於資料保護已有共識：企業組織不可能擋得下所有攻擊，但可以確保最核心的系統與數據不受損害，將破壞與損失降到最低。而其底線，就是「絕對不能讓資料陷入無法回復的絕境」。\r\n\r\n磁帶機就是這個防禦策略的最後一道防線，憑藉其離線儲存特性，在「即時數據」與「受保護數據」之間創造一個真空地帶，讓惡意者無法透過任何網路方式來存取或破壞這些關鍵資料。正因如此，磁帶成為世界各國企業組織存放珍貴史料、研發紀錄、客戶數據甚至國家機密的儲存載體成為極端狀況時最可信賴的資料後盾。\r\n\r\n\r\n\r\n\r\n＜本文作者：于伯琨現為IBM硬體系統事業部總經理＞\r\n\r\n    \r\n\r\n面對大數據與AI的時代，擁有數據就是擁有金礦。許多數據即使在當下沒有迫切用途，未來也可能成為資料淘金的重要來源。此外，由於個資管理與資料治理法規日趨嚴格，企業資料保存年限不斷拉長，種種內外因素加乘，資料的長期保存竟成為IT的隱性負擔。IT預算有限、任務無窮，資源必須優先投注於高價值的商業應用，沒有立即應用需求的「冷資料」勢必要用更具經濟性的方式來長期儲存。此時，每GB儲存成本僅有硬碟機六分之一的磁帶機，就成為企業最佳的選擇。\r\n\r\n多數人可能誤以為磁帶機是上個世紀的骨灰級技術，事實上，磁帶機技術持續進化，讀寫速度與容量穩定增加、成本也持續降低，表現比任何儲存媒介都更為優異。相較之下，磁碟技術則已面臨物理學極限。磁紀錄的最小單位被稱為「超順磁極限」，而硬碟技術幾已達到超順磁極限，單位面積的磁錄密度難以增加，磁片轉速也難以提升，這些拗口事實代表的意義就是：硬碟機容量即將到達極限，且單位儲存成本也無法像磁帶機般持續降低。因此，在可見的未來，磁帶機將是唯一能夠跟得上數據增長的儲存方案。\r\n\r\n面對日益猖獗的惡意攻擊，全球資安專家對於資料保護已有共識：企業組織不可能擋得下所有攻擊，但可以確保最核心的系統與數據不受損害，將破壞與損失降到最低。而其底線，就是「絕對不能讓資料陷入無法回復的絕境」。\r\n\r\n磁帶機就是這個防禦策略的最後一道防線，憑藉其離線儲存特性，在「即時數據」與「受保護數據」之間創造一個真空地帶，讓惡意者無法透過任何網路方式來存取或破壞這些關鍵資料。正因如此，磁帶成為世界各國企業組織存放珍貴史料、研發紀錄、客戶數據甚至國家機密的儲存載體成為極端狀況時最可信賴的資料後盾。\r\n\r\n\r\n\r\n\r\n＜本文作者：于伯琨現為IBM硬體系統事業部總經理＞\r\n\r\n    \r\n\r\n多數人可能誤以為磁帶機是上個世紀的骨灰級技術，事實上，磁帶機技術持續進化，讀寫速度與容量穩定增加、成本也持續降低，表現比任何儲存媒介都更為優異。相較之下，磁碟技術則已面臨物理學極限。磁紀錄的最小單位被稱為「超順磁極限」，而硬碟技術幾已達到超順磁極限，單位面積的磁錄密度難以增加，磁片轉速也難以提升，這些拗口事實代表的意義就是：硬碟機容量即將到達極限，且單位儲存成本也無法像磁帶機般持續降低。因此，在可見的未來，磁帶機將是唯一能夠跟得上數據增長的儲存方案。\r\n\r\n面對日益猖獗的惡意攻擊，全球資安專家對於資料保護已有共識：企業組織不可能擋得下所有攻擊，但可以確保最核心的系統與數據不受損害，將破壞與損失降到最低。而其底線，就是「絕對不能讓資料陷入無法回復的絕境」。\r\n\r\n磁帶機就是這個防禦策略的最後一道防線，憑藉其離線儲存特性，在「即時數據」與「受保護數據」之間創造一個真空地帶，讓惡意者無法透過任何網路方式來存取或破壞這些關鍵資料。正因如此，磁帶成為世界各國企業組織存放珍貴史料、研發紀錄、客戶數據甚至國家機密的儲存載體成為極端狀況時最可信賴的資料後盾。\r\n\r\n\r\n\r\n\r\n＜本文作者：于伯琨現為IBM硬體系統事業部總經理＞\r\n\r\n    \r\n\r\n面對日益猖獗的惡意攻擊，全球資安專家對於資料保護已有共識：企業組織不可能擋得下所有攻擊，但可以確保最核心的系統與數據不受損害，將破壞與損失降到最低。而其底線，就是「絕對不能讓資料陷入無法回復的絕境」。\r\n\r\n磁帶機就是這個防禦策略的最後一道防線，憑藉其離線儲存特性，在「即時數據」與「受保護數據」之間創造一個真空地帶，讓惡意者無法透過任何網路方式來存取或破壞這些關鍵資料。正因如此，磁帶成為世界各國企業組織存放珍貴史料、研發紀錄、客戶數據甚至國家機密的儲存載體成為極端狀況時最可信賴的資料後盾。\r\n\r\n\r\n\r\n\r\n＜本文作者：于伯琨現為IBM硬體系統事業部總經理＞\r\n\r\n    \r\n\r\n磁帶機就是這個防禦策略的最後一道防線，憑藉其離線儲存特性，在「即時數據」與「受保護數據」之間創造一個真空地帶，讓惡意者無法透過任何網路方式來存取或破壞這些關鍵資料。正因如此，磁帶成為世界各國企業組織存放珍貴史料、研發紀錄、客戶數據甚至國家機密的儲存載體成為極端狀況時最可信賴的資料後盾。\r\n\r\n\r\n\r\n\r\n＜本文作者：于伯琨現為IBM硬體系統事業部總經理＞\r\n\r\n    \r\n\r\n＜本文作者：于伯琨現為IBM硬體系統事業部總經理＞\r\n\r\n    \r\n呼叫專業服務機器人！豹小秘神救援零接觸測溫老字號 IT 網管監控神器　大秀自動流程與智慧分析用多雲策略建構災備善用5G三大獨特性　生態系結盟創新模式應用阿里雲推馳雲計劃　為全球中小企提供援助並加快雲端科技應用電子簽名導入區塊鏈　實現最高的資料安全性防疫也防駭！企業遠端工作 4 大重點助持續營運數位鑑識須在不疑處有疑　僅靠靜態分析易陷盲點軟協新任理事長沈柏延上任　力助產業數位轉型兆勤科技聯手 McAfee　打造全面零死角資安解決方案搞懂ICMP協定及工具 抵擋「死亡之Ping」攻擊網路設備入門新手必讀 Cisco IOS最基礎教學建立VLAN邏輯分割網段  詳解交換器Trunk設定人臉辨識拓展金融市場　技術高下實測見分曉NAT穿透技術 從外部直接溝通私有IP路由協定基礎知識入門 詳解路由特性與分類從STP到RSTP　認識多重生成樹協定無類別區隔路由CIDR技術 依需求善用有限IP位址深入了解IP位址與子網路遮罩開源OpenKM文管系統 立即打造知識管理平台第171期2020年4月任意雲端、單一體驗，釋放資料價值之新IT儲存架構解析Dell Technologies儲存創新　引領轉型旅程高階儲存較勁　NVMe全面來襲追蹤我們Featrue us本站使用cookie及相關技術分析來改善使用者體驗。瞭解更多",
        "啟用vTPM 2.0磁碟防護　加密保全虛擬機器 ": "熱門搜尋 : 熱門搜尋 : \n\r\n    .img_src {\r\n    background-color: rgba(0,0,0,.35);\r\n    display: inline-block;\r\n    padding: 5px 10px;\r\n    position: absolute;\r\n    right: 0;\r\n    color: #fff;\r\n    bottom: 0;\r\n    font-size: 13px;\r\n    /*margin-right: 44px;*/\r\n}\r\n    .img_src:before {\r\n        display: inline;\r\n        content: \"\\5716\\7247\\4F86\\6E90\\FF1A\";\r\n    }\r\n.img_src ::after, ::before {\r\n    box-sizing: border-box;\r\n}\r\n\n\n\r\n    無論任何規模與型態的組織，只要有使用到資訊系統與網路連線，皆需要一定程度的安全防護措施。在眾多資訊安全的防護措施當中，除了人員出入管制、身分認證、防火牆、防毒、入侵偵測系統外，IT人員對於「加密」這個專有名詞肯定不陌生，因為它的主要目的就是保護資料的安全，讓資料不易被外流或讓有心人士取得。\r\n\r\n只是在整個IT運作環境中，不同的服務類型與存取方式，皆有不同的加密保護方案，必須完全弄清楚組織現階段所迫切需要的是哪一種解決方案，才能對症下藥有效地預防可能的資料外洩事件發生。此外，還必須注意所選擇的解決方案，是否會嚴重影響用戶端或管理端平日工作上的不便，否則又會引發另一項IT管理上的難題。\r\n\r\n究竟加密保護的方案有哪些，以下依照不同的四大保護目標來加以分類說明：\r\n\r\n‧網路與服務連接：為了確保用戶從登入的帳號密碼到操作過程中的各種資料傳遞不會遭到竊取，通常都必須針對用戶端的網路或服務連線，要求使用所選定的加密保護措施，常見的有Wi-Fi網路的WPA加密、網站的HTTPS（SSL）連線、E-mail服務的TLS以及VPN網路的IPSec連線。\r\n\r\n‧檔案：為了避免檔案被未經授權的開啟，除了檔案權限配置外，就是要針對其內容進行加密，常見有Windows內建的EFS。當然也可以僅針對文件設定讀取或寫入的密碼，常見的就是Office內建的功能。此外，還有支援Office與PDF文件內容進階保護的AD RMS。關於這一類的加密保護方案，目前也有許多第三方的解決方案，其目的便是為了限制未經授權的列印、轉寄、存取期限等等。\r\n\r\n‧資料庫：現今無論是哪一種資料庫系統，幾乎都有一套自家的機密保護機制，以確保資料表（Table）內存放的各類型資料，必須透過相同的演算法則及相對的解密金鑰，才能取得正確的資料。常見保護的敏感資料包括帳號、密碼以及組織人事資料。\r\n\r\n‧設備：當企業允許行動工作者將敏感資料隨著洽公而攜出時，保護整個行動設備（例如筆電）內所有磁碟資料的安全而非特定檔案，以確保用戶無法透過USB磁碟、光碟、硬碟卸除存取、網路等途徑來洩漏檔案資料，並且自動嚴格保存讀寫紀錄，以利於法務單位的稽核，其中以結合TPM晶片的Windows BitLocker，便屬於這類的保護措施。\r\n\n關於vTPM保護功能\n\r\n透過電腦主機板內建的TPM（Trusted Platform Module）晶片，來加密保護作業系統中磁碟資料的安全，是早在Windows Vista版本開始便已經提供，也就是結合了大家所熟知的Windows BitLocker功能。\r\n\r\nTPM版本的發布與維護，主要是由一個非營利組織的TCG（Trusted Computing Group）機構所負責，目前最新的版本是TPM 2.0，並且被廣泛運用在許多商用的筆記型電腦內。\r\n\r\n所謂vTPM（Virtual Trusted Platform Module），顧名思義就是以TPM相同的安全保護機制應用在虛擬機器中，以確保虛擬機器實體檔案外流所造成的資訊安全問題，讓外流的虛擬機器無法在其他VMware的相容平台中啟動或存取。\r\n\r\n想要使用VMware vTPM的虛擬機器加密保護功能，必須滿足vSphere架構的六大先決條件，分別是已部署第三方KMS伺服器並完成連接配置、Guest OS必須是Windows Server 2016 (64 bit）或Windows 10 (64 bit）、ESXi主機必須為6.7以上版本、vCenter Server 6.7以上版本、虛擬機器硬體14版本、虛擬機器必須採用EFI Firmware來開機。\r\n\r\nTPM與vTPM之間有何差別呢？其實兩者都是執行相同的功能，只是前者採硬體的信賴平台模組來作為認證或金鑰儲存區，後者則是以軟體來完成，也就是使用.nvram檔案做為安全的儲存區，而該檔案便是透過虛擬機器加密功能進行加密。\r\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\n\n\n\n\r\n    (adsbygoogle = window.adsbygoogle || []).push({});\r\n\r\n    $(function () {\r\n        if ($(window).width() < 768) {\r\n            $(\"#share-buttons\").hide();\r\n        }\r\n    })\r\n\n\r\n只是在整個IT運作環境中，不同的服務類型與存取方式，皆有不同的加密保護方案，必須完全弄清楚組織現階段所迫切需要的是哪一種解決方案，才能對症下藥有效地預防可能的資料外洩事件發生。此外，還必須注意所選擇的解決方案，是否會嚴重影響用戶端或管理端平日工作上的不便，否則又會引發另一項IT管理上的難題。\r\n\r\n究竟加密保護的方案有哪些，以下依照不同的四大保護目標來加以分類說明：\r\n\r\n‧網路與服務連接：為了確保用戶從登入的帳號密碼到操作過程中的各種資料傳遞不會遭到竊取，通常都必須針對用戶端的網路或服務連線，要求使用所選定的加密保護措施，常見的有Wi-Fi網路的WPA加密、網站的HTTPS（SSL）連線、E-mail服務的TLS以及VPN網路的IPSec連線。\r\n\r\n‧檔案：為了避免檔案被未經授權的開啟，除了檔案權限配置外，就是要針對其內容進行加密，常見有Windows內建的EFS。當然也可以僅針對文件設定讀取或寫入的密碼，常見的就是Office內建的功能。此外，還有支援Office與PDF文件內容進階保護的AD RMS。關於這一類的加密保護方案，目前也有許多第三方的解決方案，其目的便是為了限制未經授權的列印、轉寄、存取期限等等。\r\n\r\n‧資料庫：現今無論是哪一種資料庫系統，幾乎都有一套自家的機密保護機制，以確保資料表（Table）內存放的各類型資料，必須透過相同的演算法則及相對的解密金鑰，才能取得正確的資料。常見保護的敏感資料包括帳號、密碼以及組織人事資料。\r\n\r\n‧設備：當企業允許行動工作者將敏感資料隨著洽公而攜出時，保護整個行動設備（例如筆電）內所有磁碟資料的安全而非特定檔案，以確保用戶無法透過USB磁碟、光碟、硬碟卸除存取、網路等途徑來洩漏檔案資料，並且自動嚴格保存讀寫紀錄，以利於法務單位的稽核，其中以結合TPM晶片的Windows BitLocker，便屬於這類的保護措施。\r\n\n關於vTPM保護功能\n\r\n透過電腦主機板內建的TPM（Trusted Platform Module）晶片，來加密保護作業系統中磁碟資料的安全，是早在Windows Vista版本開始便已經提供，也就是結合了大家所熟知的Windows BitLocker功能。\r\n\r\nTPM版本的發布與維護，主要是由一個非營利組織的TCG（Trusted Computing Group）機構所負責，目前最新的版本是TPM 2.0，並且被廣泛運用在許多商用的筆記型電腦內。\r\n\r\n所謂vTPM（Virtual Trusted Platform Module），顧名思義就是以TPM相同的安全保護機制應用在虛擬機器中，以確保虛擬機器實體檔案外流所造成的資訊安全問題，讓外流的虛擬機器無法在其他VMware的相容平台中啟動或存取。\r\n\r\n想要使用VMware vTPM的虛擬機器加密保護功能，必須滿足vSphere架構的六大先決條件，分別是已部署第三方KMS伺服器並完成連接配置、Guest OS必須是Windows Server 2016 (64 bit）或Windows 10 (64 bit）、ESXi主機必須為6.7以上版本、vCenter Server 6.7以上版本、虛擬機器硬體14版本、虛擬機器必須採用EFI Firmware來開機。\r\n\r\nTPM與vTPM之間有何差別呢？其實兩者都是執行相同的功能，只是前者採硬體的信賴平台模組來作為認證或金鑰儲存區，後者則是以軟體來完成，也就是使用.nvram檔案做為安全的儲存區，而該檔案便是透過虛擬機器加密功能進行加密。\r\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\r\n究竟加密保護的方案有哪些，以下依照不同的四大保護目標來加以分類說明：\r\n\r\n‧網路與服務連接：為了確保用戶從登入的帳號密碼到操作過程中的各種資料傳遞不會遭到竊取，通常都必須針對用戶端的網路或服務連線，要求使用所選定的加密保護措施，常見的有Wi-Fi網路的WPA加密、網站的HTTPS（SSL）連線、E-mail服務的TLS以及VPN網路的IPSec連線。\r\n\r\n‧檔案：為了避免檔案被未經授權的開啟，除了檔案權限配置外，就是要針對其內容進行加密，常見有Windows內建的EFS。當然也可以僅針對文件設定讀取或寫入的密碼，常見的就是Office內建的功能。此外，還有支援Office與PDF文件內容進階保護的AD RMS。關於這一類的加密保護方案，目前也有許多第三方的解決方案，其目的便是為了限制未經授權的列印、轉寄、存取期限等等。\r\n\r\n‧資料庫：現今無論是哪一種資料庫系統，幾乎都有一套自家的機密保護機制，以確保資料表（Table）內存放的各類型資料，必須透過相同的演算法則及相對的解密金鑰，才能取得正確的資料。常見保護的敏感資料包括帳號、密碼以及組織人事資料。\r\n\r\n‧設備：當企業允許行動工作者將敏感資料隨著洽公而攜出時，保護整個行動設備（例如筆電）內所有磁碟資料的安全而非特定檔案，以確保用戶無法透過USB磁碟、光碟、硬碟卸除存取、網路等途徑來洩漏檔案資料，並且自動嚴格保存讀寫紀錄，以利於法務單位的稽核，其中以結合TPM晶片的Windows BitLocker，便屬於這類的保護措施。\r\n\n關於vTPM保護功能\n\r\n透過電腦主機板內建的TPM（Trusted Platform Module）晶片，來加密保護作業系統中磁碟資料的安全，是早在Windows Vista版本開始便已經提供，也就是結合了大家所熟知的Windows BitLocker功能。\r\n\r\nTPM版本的發布與維護，主要是由一個非營利組織的TCG（Trusted Computing Group）機構所負責，目前最新的版本是TPM 2.0，並且被廣泛運用在許多商用的筆記型電腦內。\r\n\r\n所謂vTPM（Virtual Trusted Platform Module），顧名思義就是以TPM相同的安全保護機制應用在虛擬機器中，以確保虛擬機器實體檔案外流所造成的資訊安全問題，讓外流的虛擬機器無法在其他VMware的相容平台中啟動或存取。\r\n\r\n想要使用VMware vTPM的虛擬機器加密保護功能，必須滿足vSphere架構的六大先決條件，分別是已部署第三方KMS伺服器並完成連接配置、Guest OS必須是Windows Server 2016 (64 bit）或Windows 10 (64 bit）、ESXi主機必須為6.7以上版本、vCenter Server 6.7以上版本、虛擬機器硬體14版本、虛擬機器必須採用EFI Firmware來開機。\r\n\r\nTPM與vTPM之間有何差別呢？其實兩者都是執行相同的功能，只是前者採硬體的信賴平台模組來作為認證或金鑰儲存區，後者則是以軟體來完成，也就是使用.nvram檔案做為安全的儲存區，而該檔案便是透過虛擬機器加密功能進行加密。\r\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\r\n‧網路與服務連接：為了確保用戶從登入的帳號密碼到操作過程中的各種資料傳遞不會遭到竊取，通常都必須針對用戶端的網路或服務連線，要求使用所選定的加密保護措施，常見的有Wi-Fi網路的WPA加密、網站的HTTPS（SSL）連線、E-mail服務的TLS以及VPN網路的IPSec連線。\r\n\r\n‧檔案：為了避免檔案被未經授權的開啟，除了檔案權限配置外，就是要針對其內容進行加密，常見有Windows內建的EFS。當然也可以僅針對文件設定讀取或寫入的密碼，常見的就是Office內建的功能。此外，還有支援Office與PDF文件內容進階保護的AD RMS。關於這一類的加密保護方案，目前也有許多第三方的解決方案，其目的便是為了限制未經授權的列印、轉寄、存取期限等等。\r\n\r\n‧資料庫：現今無論是哪一種資料庫系統，幾乎都有一套自家的機密保護機制，以確保資料表（Table）內存放的各類型資料，必須透過相同的演算法則及相對的解密金鑰，才能取得正確的資料。常見保護的敏感資料包括帳號、密碼以及組織人事資料。\r\n\r\n‧設備：當企業允許行動工作者將敏感資料隨著洽公而攜出時，保護整個行動設備（例如筆電）內所有磁碟資料的安全而非特定檔案，以確保用戶無法透過USB磁碟、光碟、硬碟卸除存取、網路等途徑來洩漏檔案資料，並且自動嚴格保存讀寫紀錄，以利於法務單位的稽核，其中以結合TPM晶片的Windows BitLocker，便屬於這類的保護措施。\r\n\n關於vTPM保護功能\n\r\n透過電腦主機板內建的TPM（Trusted Platform Module）晶片，來加密保護作業系統中磁碟資料的安全，是早在Windows Vista版本開始便已經提供，也就是結合了大家所熟知的Windows BitLocker功能。\r\n\r\nTPM版本的發布與維護，主要是由一個非營利組織的TCG（Trusted Computing Group）機構所負責，目前最新的版本是TPM 2.0，並且被廣泛運用在許多商用的筆記型電腦內。\r\n\r\n所謂vTPM（Virtual Trusted Platform Module），顧名思義就是以TPM相同的安全保護機制應用在虛擬機器中，以確保虛擬機器實體檔案外流所造成的資訊安全問題，讓外流的虛擬機器無法在其他VMware的相容平台中啟動或存取。\r\n\r\n想要使用VMware vTPM的虛擬機器加密保護功能，必須滿足vSphere架構的六大先決條件，分別是已部署第三方KMS伺服器並完成連接配置、Guest OS必須是Windows Server 2016 (64 bit）或Windows 10 (64 bit）、ESXi主機必須為6.7以上版本、vCenter Server 6.7以上版本、虛擬機器硬體14版本、虛擬機器必須採用EFI Firmware來開機。\r\n\r\nTPM與vTPM之間有何差別呢？其實兩者都是執行相同的功能，只是前者採硬體的信賴平台模組來作為認證或金鑰儲存區，後者則是以軟體來完成，也就是使用.nvram檔案做為安全的儲存區，而該檔案便是透過虛擬機器加密功能進行加密。\r\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\r\n‧檔案：為了避免檔案被未經授權的開啟，除了檔案權限配置外，就是要針對其內容進行加密，常見有Windows內建的EFS。當然也可以僅針對文件設定讀取或寫入的密碼，常見的就是Office內建的功能。此外，還有支援Office與PDF文件內容進階保護的AD RMS。關於這一類的加密保護方案，目前也有許多第三方的解決方案，其目的便是為了限制未經授權的列印、轉寄、存取期限等等。\r\n\r\n‧資料庫：現今無論是哪一種資料庫系統，幾乎都有一套自家的機密保護機制，以確保資料表（Table）內存放的各類型資料，必須透過相同的演算法則及相對的解密金鑰，才能取得正確的資料。常見保護的敏感資料包括帳號、密碼以及組織人事資料。\r\n\r\n‧設備：當企業允許行動工作者將敏感資料隨著洽公而攜出時，保護整個行動設備（例如筆電）內所有磁碟資料的安全而非特定檔案，以確保用戶無法透過USB磁碟、光碟、硬碟卸除存取、網路等途徑來洩漏檔案資料，並且自動嚴格保存讀寫紀錄，以利於法務單位的稽核，其中以結合TPM晶片的Windows BitLocker，便屬於這類的保護措施。\r\n\n關於vTPM保護功能\n\r\n透過電腦主機板內建的TPM（Trusted Platform Module）晶片，來加密保護作業系統中磁碟資料的安全，是早在Windows Vista版本開始便已經提供，也就是結合了大家所熟知的Windows BitLocker功能。\r\n\r\nTPM版本的發布與維護，主要是由一個非營利組織的TCG（Trusted Computing Group）機構所負責，目前最新的版本是TPM 2.0，並且被廣泛運用在許多商用的筆記型電腦內。\r\n\r\n所謂vTPM（Virtual Trusted Platform Module），顧名思義就是以TPM相同的安全保護機制應用在虛擬機器中，以確保虛擬機器實體檔案外流所造成的資訊安全問題，讓外流的虛擬機器無法在其他VMware的相容平台中啟動或存取。\r\n\r\n想要使用VMware vTPM的虛擬機器加密保護功能，必須滿足vSphere架構的六大先決條件，分別是已部署第三方KMS伺服器並完成連接配置、Guest OS必須是Windows Server 2016 (64 bit）或Windows 10 (64 bit）、ESXi主機必須為6.7以上版本、vCenter Server 6.7以上版本、虛擬機器硬體14版本、虛擬機器必須採用EFI Firmware來開機。\r\n\r\nTPM與vTPM之間有何差別呢？其實兩者都是執行相同的功能，只是前者採硬體的信賴平台模組來作為認證或金鑰儲存區，後者則是以軟體來完成，也就是使用.nvram檔案做為安全的儲存區，而該檔案便是透過虛擬機器加密功能進行加密。\r\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\r\n‧資料庫：現今無論是哪一種資料庫系統，幾乎都有一套自家的機密保護機制，以確保資料表（Table）內存放的各類型資料，必須透過相同的演算法則及相對的解密金鑰，才能取得正確的資料。常見保護的敏感資料包括帳號、密碼以及組織人事資料。\r\n\r\n‧設備：當企業允許行動工作者將敏感資料隨著洽公而攜出時，保護整個行動設備（例如筆電）內所有磁碟資料的安全而非特定檔案，以確保用戶無法透過USB磁碟、光碟、硬碟卸除存取、網路等途徑來洩漏檔案資料，並且自動嚴格保存讀寫紀錄，以利於法務單位的稽核，其中以結合TPM晶片的Windows BitLocker，便屬於這類的保護措施。\r\n\n關於vTPM保護功能\n\r\n透過電腦主機板內建的TPM（Trusted Platform Module）晶片，來加密保護作業系統中磁碟資料的安全，是早在Windows Vista版本開始便已經提供，也就是結合了大家所熟知的Windows BitLocker功能。\r\n\r\nTPM版本的發布與維護，主要是由一個非營利組織的TCG（Trusted Computing Group）機構所負責，目前最新的版本是TPM 2.0，並且被廣泛運用在許多商用的筆記型電腦內。\r\n\r\n所謂vTPM（Virtual Trusted Platform Module），顧名思義就是以TPM相同的安全保護機制應用在虛擬機器中，以確保虛擬機器實體檔案外流所造成的資訊安全問題，讓外流的虛擬機器無法在其他VMware的相容平台中啟動或存取。\r\n\r\n想要使用VMware vTPM的虛擬機器加密保護功能，必須滿足vSphere架構的六大先決條件，分別是已部署第三方KMS伺服器並完成連接配置、Guest OS必須是Windows Server 2016 (64 bit）或Windows 10 (64 bit）、ESXi主機必須為6.7以上版本、vCenter Server 6.7以上版本、虛擬機器硬體14版本、虛擬機器必須採用EFI Firmware來開機。\r\n\r\nTPM與vTPM之間有何差別呢？其實兩者都是執行相同的功能，只是前者採硬體的信賴平台模組來作為認證或金鑰儲存區，後者則是以軟體來完成，也就是使用.nvram檔案做為安全的儲存區，而該檔案便是透過虛擬機器加密功能進行加密。\r\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\r\n‧設備：當企業允許行動工作者將敏感資料隨著洽公而攜出時，保護整個行動設備（例如筆電）內所有磁碟資料的安全而非特定檔案，以確保用戶無法透過USB磁碟、光碟、硬碟卸除存取、網路等途徑來洩漏檔案資料，並且自動嚴格保存讀寫紀錄，以利於法務單位的稽核，其中以結合TPM晶片的Windows BitLocker，便屬於這類的保護措施。\r\n\n關於vTPM保護功能\n\r\n透過電腦主機板內建的TPM（Trusted Platform Module）晶片，來加密保護作業系統中磁碟資料的安全，是早在Windows Vista版本開始便已經提供，也就是結合了大家所熟知的Windows BitLocker功能。\r\n\r\nTPM版本的發布與維護，主要是由一個非營利組織的TCG（Trusted Computing Group）機構所負責，目前最新的版本是TPM 2.0，並且被廣泛運用在許多商用的筆記型電腦內。\r\n\r\n所謂vTPM（Virtual Trusted Platform Module），顧名思義就是以TPM相同的安全保護機制應用在虛擬機器中，以確保虛擬機器實體檔案外流所造成的資訊安全問題，讓外流的虛擬機器無法在其他VMware的相容平台中啟動或存取。\r\n\r\n想要使用VMware vTPM的虛擬機器加密保護功能，必須滿足vSphere架構的六大先決條件，分別是已部署第三方KMS伺服器並完成連接配置、Guest OS必須是Windows Server 2016 (64 bit）或Windows 10 (64 bit）、ESXi主機必須為6.7以上版本、vCenter Server 6.7以上版本、虛擬機器硬體14版本、虛擬機器必須採用EFI Firmware來開機。\r\n\r\nTPM與vTPM之間有何差別呢？其實兩者都是執行相同的功能，只是前者採硬體的信賴平台模組來作為認證或金鑰儲存區，後者則是以軟體來完成，也就是使用.nvram檔案做為安全的儲存區，而該檔案便是透過虛擬機器加密功能進行加密。\r\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\n關於vTPM保護功能\n\r\n透過電腦主機板內建的TPM（Trusted Platform Module）晶片，來加密保護作業系統中磁碟資料的安全，是早在Windows Vista版本開始便已經提供，也就是結合了大家所熟知的Windows BitLocker功能。\r\n\r\nTPM版本的發布與維護，主要是由一個非營利組織的TCG（Trusted Computing Group）機構所負責，目前最新的版本是TPM 2.0，並且被廣泛運用在許多商用的筆記型電腦內。\r\n\r\n所謂vTPM（Virtual Trusted Platform Module），顧名思義就是以TPM相同的安全保護機制應用在虛擬機器中，以確保虛擬機器實體檔案外流所造成的資訊安全問題，讓外流的虛擬機器無法在其他VMware的相容平台中啟動或存取。\r\n\r\n想要使用VMware vTPM的虛擬機器加密保護功能，必須滿足vSphere架構的六大先決條件，分別是已部署第三方KMS伺服器並完成連接配置、Guest OS必須是Windows Server 2016 (64 bit）或Windows 10 (64 bit）、ESXi主機必須為6.7以上版本、vCenter Server 6.7以上版本、虛擬機器硬體14版本、虛擬機器必須採用EFI Firmware來開機。\r\n\r\nTPM與vTPM之間有何差別呢？其實兩者都是執行相同的功能，只是前者採硬體的信賴平台模組來作為認證或金鑰儲存區，後者則是以軟體來完成，也就是使用.nvram檔案做為安全的儲存區，而該檔案便是透過虛擬機器加密功能進行加密。\r\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\r\n透過電腦主機板內建的TPM（Trusted Platform Module）晶片，來加密保護作業系統中磁碟資料的安全，是早在Windows Vista版本開始便已經提供，也就是結合了大家所熟知的Windows BitLocker功能。\r\n\r\nTPM版本的發布與維護，主要是由一個非營利組織的TCG（Trusted Computing Group）機構所負責，目前最新的版本是TPM 2.0，並且被廣泛運用在許多商用的筆記型電腦內。\r\n\r\n所謂vTPM（Virtual Trusted Platform Module），顧名思義就是以TPM相同的安全保護機制應用在虛擬機器中，以確保虛擬機器實體檔案外流所造成的資訊安全問題，讓外流的虛擬機器無法在其他VMware的相容平台中啟動或存取。\r\n\r\n想要使用VMware vTPM的虛擬機器加密保護功能，必須滿足vSphere架構的六大先決條件，分別是已部署第三方KMS伺服器並完成連接配置、Guest OS必須是Windows Server 2016 (64 bit）或Windows 10 (64 bit）、ESXi主機必須為6.7以上版本、vCenter Server 6.7以上版本、虛擬機器硬體14版本、虛擬機器必須採用EFI Firmware來開機。\r\n\r\nTPM與vTPM之間有何差別呢？其實兩者都是執行相同的功能，只是前者採硬體的信賴平台模組來作為認證或金鑰儲存區，後者則是以軟體來完成，也就是使用.nvram檔案做為安全的儲存區，而該檔案便是透過虛擬機器加密功能進行加密。\r\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\r\nTPM版本的發布與維護，主要是由一個非營利組織的TCG（Trusted Computing Group）機構所負責，目前最新的版本是TPM 2.0，並且被廣泛運用在許多商用的筆記型電腦內。\r\n\r\n所謂vTPM（Virtual Trusted Platform Module），顧名思義就是以TPM相同的安全保護機制應用在虛擬機器中，以確保虛擬機器實體檔案外流所造成的資訊安全問題，讓外流的虛擬機器無法在其他VMware的相容平台中啟動或存取。\r\n\r\n想要使用VMware vTPM的虛擬機器加密保護功能，必須滿足vSphere架構的六大先決條件，分別是已部署第三方KMS伺服器並完成連接配置、Guest OS必須是Windows Server 2016 (64 bit）或Windows 10 (64 bit）、ESXi主機必須為6.7以上版本、vCenter Server 6.7以上版本、虛擬機器硬體14版本、虛擬機器必須採用EFI Firmware來開機。\r\n\r\nTPM與vTPM之間有何差別呢？其實兩者都是執行相同的功能，只是前者採硬體的信賴平台模組來作為認證或金鑰儲存區，後者則是以軟體來完成，也就是使用.nvram檔案做為安全的儲存區，而該檔案便是透過虛擬機器加密功能進行加密。\r\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\r\n所謂vTPM（Virtual Trusted Platform Module），顧名思義就是以TPM相同的安全保護機制應用在虛擬機器中，以確保虛擬機器實體檔案外流所造成的資訊安全問題，讓外流的虛擬機器無法在其他VMware的相容平台中啟動或存取。\r\n\r\n想要使用VMware vTPM的虛擬機器加密保護功能，必須滿足vSphere架構的六大先決條件，分別是已部署第三方KMS伺服器並完成連接配置、Guest OS必須是Windows Server 2016 (64 bit）或Windows 10 (64 bit）、ESXi主機必須為6.7以上版本、vCenter Server 6.7以上版本、虛擬機器硬體14版本、虛擬機器必須採用EFI Firmware來開機。\r\n\r\nTPM與vTPM之間有何差別呢？其實兩者都是執行相同的功能，只是前者採硬體的信賴平台模組來作為認證或金鑰儲存區，後者則是以軟體來完成，也就是使用.nvram檔案做為安全的儲存區，而該檔案便是透過虛擬機器加密功能進行加密。\r\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\r\n想要使用VMware vTPM的虛擬機器加密保護功能，必須滿足vSphere架構的六大先決條件，分別是已部署第三方KMS伺服器並完成連接配置、Guest OS必須是Windows Server 2016 (64 bit）或Windows 10 (64 bit）、ESXi主機必須為6.7以上版本、vCenter Server 6.7以上版本、虛擬機器硬體14版本、虛擬機器必須採用EFI Firmware來開機。\r\n\r\nTPM與vTPM之間有何差別呢？其實兩者都是執行相同的功能，只是前者採硬體的信賴平台模組來作為認證或金鑰儲存區，後者則是以軟體來完成，也就是使用.nvram檔案做為安全的儲存區，而該檔案便是透過虛擬機器加密功能進行加密。\r\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\r\nTPM與vTPM之間有何差別呢？其實兩者都是執行相同的功能，只是前者採硬體的信賴平台模組來作為認證或金鑰儲存區，後者則是以軟體來完成，也就是使用.nvram檔案做為安全的儲存區，而該檔案便是透過虛擬機器加密功能進行加密。\r\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n呼叫專業服務機器人！豹小秘神救援零接觸測溫老字號 IT 網管監控神器　大秀自動流程與智慧分析用多雲策略建構災備善用5G三大獨特性　生態系結盟創新模式應用阿里雲推馳雲計劃　為全球中小企提供援助並加快雲端科技應用電子簽名導入區塊鏈　實現最高的資料安全性防疫也防駭！企業遠端工作 4 大重點助持續營運數位鑑識須在不疑處有疑　僅靠靜態分析易陷盲點軟協新任理事長沈柏延上任　力助產業數位轉型兆勤科技聯手 McAfee　打造全面零死角資安解決方案搞懂ICMP協定及工具 抵擋「死亡之Ping」攻擊網路設備入門新手必讀 Cisco IOS最基礎教學建立VLAN邏輯分割網段  詳解交換器Trunk設定人臉辨識拓展金融市場　技術高下實測見分曉NAT穿透技術 從外部直接溝通私有IP路由協定基礎知識入門 詳解路由特性與分類從STP到RSTP　認識多重生成樹協定無類別區隔路由CIDR技術 依需求善用有限IP位址深入了解IP位址與子網路遮罩開源OpenKM文管系統 立即打造知識管理平台第171期2020年4月任意雲端、單一體驗，釋放資料價值之新IT儲存架構解析Dell Technologies儲存創新　引領轉型旅程高階儲存較勁　NVMe全面來襲追蹤我們Featrue us本站使用cookie及相關技術分析來改善使用者體驗。瞭解更多",
        "手握全球四成硬碟供貨量的希捷，對今年衰退吹了第一聲哨 ": "根據硬碟大廠希捷最新財報，會計年度 2019 年第二季（2018 年 10~12 月）營收 27.15 億美元，年減 6.8%，這是連續 6 季交出正成長業績後，首見的衰退數據。希捷目前占全球 HDD 市場數量 45%，產值占有率則達 40%，春江水暖鴨先知，客戶打個噴嚏，希捷也有蝴蝶效應。▲ 希捷全球業務暨業務營運資深副總裁鄭萬成看好企業及雲端資料中心市場需求成長。（Source：希捷）這個全球最大的硬碟（HDD）品牌如今面對的，不只是一年來高速成長的資料中心客戶突踩煞車降速，同時 SSD 價格去年價格持續崩跌，可能大幅縮減跟傳統 HDD 價格差距，吸引企業客戶轉向採購 SSD，也讓市場擔憂。北美貿易戰開打，資料中心大量採用的硬碟首當其衝遭關稅加徵，許多伺服器代工廠紛紛將工廠搬離中國，這樣的多事之秋，正好也是希捷慶祝 40 週年的時刻。「我們成立 40 年了，但眼前有個顯著的機會，也有巨大的挑戰，」希捷全球業務暨業務營運資深副總裁鄭萬成說。目前全球雲端產業需求占 HDD 市場高達 30%，近年資料中心建置高速成長，讓希捷連續 6 季業績成長，鄭萬成分析，雲端服務業者目前將 80% 資料儲存 HDD 中，約 20% 熱資料選擇放在 SSD，也因此，對於以 HDD 為核心主要業務的希捷而言，資料中心客戶是非常重要的用戶。對於上季業績降速，鄭萬成坦言，正是因為中國市場跟雲端資料中心需求同步降緩。資料中心是一個景氣循環產業，會有上升跟下降週期，快速成長後會進入庫存消化期，2018 年可以見到資料中心市場有非常強勁的成長，幅度高達 70% 以上，但高成長之後，2019 年將會看到雲端產業會持平或衰退，但他仍強調長期而言雲端市場仍會持續成長，對於這一點他相當有信心。不只希捷對今年雲端產業資料中心建置需求放緩預警，英特爾跟輝達也都在年底財報結算時，預告資料中心建置將降速，短期內先以消化庫存為主，3 家大廠同時開槍預警，也讓市場蒙上陰霾。據了解，Facebook 在 2018 年仍積極規劃資料中心擴張，但下半年面臨需求擴張帶來的電力不足壓力，也放緩機器設備擴充的速度，改以先建置資料中心廠房硬體為主；另一家雲端大廠微軟也傳出，由於 2018 年伺服器拉貨過多，部分拉進資料中心的機器甚至放上 2 個月都還沒啟用，在改善折舊攤提負擔考量下，微軟暫緩繼續擴張增購伺服器與儲存系統。不只是資料中心建置速度放緩，北美貿易戰也使中國硬碟出口美國面臨高關稅課徵壓力。鄭萬成證實，如今許多伺服器 ODM 業者紛紛離開中國製造，規避輸美壓力，但不論政治如何發展，他也點出未來的光明面：現在資料中心仍高度集中美國市場，但非美國以外地區的增加速度將超越美國。舉數據佐證，鄭萬成說，IDC 統計現在公有雲資料中心約 60% 集中美國市場，但到 2025 年，預估北美占有率將降至 40%，足以佐證在北美以外的資料中心數量興起。特別是亞洲市場資料中心的成長力道。鄭萬成更直接點名台灣，有很強的伺服器 ODM 聚落，包括廣達、鴻海、英業達及緯穎都是資料中心伺服器代工大廠，也因此希捷格外重視。為何硬碟廠要重視代工廠關係？鄭萬成直言，因為希捷與雲端原廠、ODM 廠三方都有高關連性，舉例來說，緯穎幫微軟建置資料中心，買希捷 HDD，表面上似乎是微軟指定用希捷的硬碟就可以，但實際上希捷首先必須符合緯穎的認證，所以三者之間其實是一個生態系統，其次，緯穎也可能自行開發一套系統提供網路業者，所以對希捷來說，自始都是三方一起合作，以確保符合客戶需求。在鞏固資料中心客戶關係下，希捷看好未來企業用戶市場的穩定成長，鄭萬成也預估，2025 年時，企業用戶占 HDD 市場占比會從現在 45% 增高至 55%，成為希捷重要市場。希捷另一個挑戰來自於 SSD 價格的崩跌。根據粗估，今年以來 SSD 跌價幅度已經超過 15%，過去 SSD 的優點是速度快，但比較貴；而 HDD 費用較低，所以仍獲得資料中心與企業用戶大量採用，如今兩者價差拉近，對 HDD 龍頭希捷是否帶來威脅？希捷產品開發工程設計資深副總裁 Mike Troemel 說，長期來看，SSD 成本還是比較高，企業市場 SSD 每 GB 價格跟 HDD 相比，仍有超過 10 倍以上的價格距離，雖然兩者價格都持續下滑，希捷的任務，就是利用更先進的技術，協助 HDD 價格不斷下滑。▲ 希捷發表跨世代 HAMR 儲存技術硬碟，2020 年將量產。（Source：希捷）為此，希捷在 2018 年發表了 HAMR（熱輔助磁記錄）儲存技術硬碟，這個硬碟預計 2020 年會開始出貨 20TB 以上大容量企業級產品，目標正是鎖定資料中心用戶。透過 HAMR 技術，硬碟的儲存容量大幅提高，每單位 GB 成本下降，讓 HDD 得以繼續與 SSD 價格保持 10 倍以上價差。Mike 表示，SSD 也不斷研發 2D 或 3D 堆疊技術降低成本，但透過 HAMR 希捷將得以確保 HDD 的競爭力，資料中心客戶不在乎硬碟價格，關心的是總體擁有成本（TOC）。不只是希捷積極研發跳躍式硬碟技術，要延續 HDD 儲存命脈，威騰 WD 去年也宣布 MAMR（微波輔助磁記錄，microwave-assisted magnetic recording）硬碟技術，與 HAMR 的區別在於利用微波取代 HAMR 雷射為媒介。對於歸檔光碟也有意分吃冷資料儲存市場一杯羹，鄭萬成表示沒有評論，他也強調公司開發 HAMR 目的是提供給資料中心做大量資料的儲存，而不是歸檔用途。▲希捷 HAMR 儲存技術硬碟用雷射頭提高儲存密度。（Source：希捷）（本文由 數位時代 授權轉載；首圖來源：pixabay）科技新知，時時更新我的最愛趕快加入最愛頁面Facebook成為我們的小粉絲GOOGLE加入我們一起討論RSS即時更新新知\n\r\n© 2013-2019 TechNews Inc. All rights reserved.  | \n關於我們 |  使用條款 | 隱私權政策 | 著作權與授權轉載 | 語系： TW   EN ",
        "【儲存作業系統：NetApp ONTAP 9.4與9.5】老牌儲存軟體平臺新進化，改善效能、擴展儲存空間管理彈性與效率 ": "NetApp ONTAP作業系統近期推出的9.4與9.5等兩個新版本，在雲端儲存整合、存取效能、儲存空間管理彈性與效益，以及系統與資料可用性等4個面向都有所增強老牌的ONTAP儲存作業系統，是業界最具代表性的儲存軟體平臺之一，也是NetApp旗下主力儲存陣列產品的核心，適用於FAS系列混合儲存陣列、AFF A系列全快閃儲存陣列、ONTAP Select軟體定義儲存，同時也構成了Cloud Volumes Service與Cloud Volumes ONTAP兩種雲端儲存陣列服務的底層。與時俱進的老牌儲存軟體平臺ONTAP作業系統的誕生可追溯到1992年，是當前市場上歷史最悠久的儲存作業系統之一，儘管發展時間很早，但歷經多次改版，ONTAP這個儲存軟體平臺仍能與時俱進，持續跟進新的儲存技術潮流。在7.0版以前，ONTAP原稱為Data ONTAP，當時又分為由原本基於BSD-based架構持續發展而來的7G（2005年推出），與2004年併購Spinnaker Networks後，基於該公司網格架構技術、於2006年推出的GX兩種版本。雖然GX版擁有全新的虛擬化架構，擁有更彈性的架構與更高的效率，發展潛力也更大，但早期的功能還不完整。稍後到了2009年中時，NetApp將兩種版本統一更新到8.0版本編號，並分別改稱7-Mode與Cluster-Mode，持續維持兩種版本平行發展。接下來NetApp雖然逐漸將重心放在擁有全新核心架構的Cluster-Mode版本上，8.2.5版是最後一個提供傳統7-Mode模式的版本，後續的版本都統一為只提供Cluster-Mode，不再有7-Mode與Cluster-Mode版本的區分。而從2016年9月正式發行的9.0版起，NetApp將Data ONTAP改稱為ONTAP，這個版本也就是目前通行的ONTAP版本。所以嚴格說起來，NetApp目前使用的ONTAP作業系統，其實源自2006年的Data ONTAP GX，核心架構與1990年代早期開始發展的Data ONTAP老版本，已有本質上的不同，架構更新穎。ONTAP平臺的最新更新自2018年下半年起，NetApp接連發表了9.4與9.5版等兩個ONTAP作業系統接的重要更新。其中於2018年6月底正式上線的ONTAP 9.4版，主要的功能更新包括；● 擴展FabricPools功能，強化雲端分層儲存應用。● 新增支援NVMe/FC傳輸架構。● 新增非活躍資料報告（Inactive Data Reporting）功能。● 為FlexGroup提供更完整的QoS管理選項。● 支援多通道傳輸架構的SMB協定。● 改進重複資料刪除功能。● 提高儲存密度，支援30TB SSD。至於剛在2018年10月Insight大會中宣布的ONTAP 9.5，則包含了下列這些更新項目：● 擴展FlexCache功能，更完整的支援叢集架構。● 透過支援非對稱命名空間存取架構（Asynchronous Namespace Access，ANA），讓NVMe/FC傳輸連接具備多路徑故障切換能力。● 增強FlexGroup功能，提供更多管理與存取選項支援。● 增強ONTAP Select，改善存取效能。● 改善壓縮功能，提高空間使用效率。● FabricPool功能增強，支援更多儲存選項。● 新增支援NDAS資料保護服務（NetApp Data Availability Services），提供基於雲端的資料保護功能。● 新增同步模式的SnapMirror遠端複製功能（SnapMirror Synchronous，SM-S）。● 新增支援伺服器端Max Data記憶體加速機制。我們可以把這些功能更新，概分為4個主要面向：強化雲端儲存整合、改善存取效能、提高儲存空間管理彈性與效益，以及提高系統與資料的可用性。強化雲端儲存整合主要是強化FabricPools雲端分層儲存功能。這是ONTAP 9.2引進的新功能，在9.4與9.5版兩次更新中都進一步增強。改善存取效能包括新增對NVMe/FC傳輸架構的支援，擴展FlexCache功能，改善ONTAP Select軟體定義儲存套件的效能，支援SMB多路徑傳輸，以及支援Max Data記憶體加速機制等。特別值得一提的是，經由9.4與9.5版的更新後，大幅擴展了ONTAP的分層存取與I/O加速技術的涵蓋範圍，從ONTAP儲存裝置本身的加速（如FlexCache與NVMe/FC），擴展到前端的伺服器（如Max Data），以及公有雲服務上（如FabricPool），包含了用戶可能觸及的每一個存取環節。提高儲存空間管理彈性與效益包括FlexGroup功能的擴展，重複資料刪除與壓縮功能的擴展與改進等幾項。提高系統與資料可用性包括為NVMe/F支援失效切換架構、支援NDAS資料保護服務，以及新增同步模式的SnapMirror遠端複製功能等。在這4個面向中，存取效能、儲存空間管理彈性與可用性這幾項，都是ONTAP作業系統歷來的改版中，經常會涵蓋的更新項目。至於強化雲端儲存的整合，則是近來標榜「Cloud First」的NetApp，當前的產品發展重點。接下來我們便分別從這4個面向，逐一介紹ONTAP 9.4與9.5版的重要新功能。ONTAP新特色1：傳輸架構與I/O效能改進ONTAP的NVMe/FC支援功能，只適用於AFF系列全快閃儲存陣列，目前除了最低階的A200以外，其餘AFF系列產品只需搭配9.4版以上的ONTAP，就能啟用NVMe/FC。圖片來源／NetApp新版ONTAP在提升效能方面的新功能，包括了導入NVMe-oF傳輸架構，擴展檔案傳輸快取功能，支援SMB協定的多通道傳輸，支援新的伺服器端加速機制，以及ONTAP Select軟體定義儲存套件的效能改進等幾項。支援NVMe/FC傳輸架構NVMe是當前固態儲存應用的焦點之一，除了作為SSD介面之外，也衍生出外接應用的NVMe over Fabrics（NVMe-oF）架構，可將NVMe的全新軟體堆疊，嫁接在既有的光纖通道（Fibre Channel，FC）、InfiniBand或RDMA乙太網路上運行，從而達到降低存取延遲的目的。NetApp是在2018年中時，為ONTAP平臺產品線引進了NVMe與NVMe-oF的支援，也在新推出的AFF系列新機型A800上，同時支援NVMe SSD模組，以及基於FC介面的NVMe-oF架構（簡稱NVMe/FC），搭配同步推出的ONTAP 9.4便能運行NVMe/FC，在既有的FC SAN環境下，提供低於200μs等級的存取延遲。目前AFF系列中除了最低階的A200以外，其餘都能支援NVMe/FC傳輸架構。擴展FlexCache功能FlexCache是ONTAP 7.x便有的一項老功能，可作為指定的原始Volume，建立快取用的Volume，然後以區塊為單位快取資料，從而加速NFS、CIFS/NFS等NAS傳輸協定的存取，但只支援單一叢集內的快取，若要為叢集外Volume提供快取，便須在叢集前端，使用一套運行7-Mode的ONTAP系統來充當快取用裝置。ONTAP 9.5的新版FlexCache則採用了稀疏架構（sparsely-populated），可使用FlexGroup架構下的分散式Volume來作為快取用Volume，並提供跨叢集（Inter-cluster）與叢集內（Intra-cluster）兩種模式，為單一叢集或多個叢集提供快取用Volume，但只支援NFS v3協定。FlexexCache的基本概念FlexCache是針對檔案存取協定的快取功能，可在叢集的不同節點內設定快取用Volume，來為指定的原始Volume提供快取加速。讀取資料時若快取命中，便直接從快取Volume讀取資料；寫入I/O也會經由快取Volume的中介，轉給原始Volume。圖片來源／NetAppFlexexCache的兩種模式ONTAP 9.5的FlexCache提供了針對單一叢集的「叢集內」模式，以及針對多叢集的「跨叢集」模式，可在包括遠端叢集在內的跨叢集環境，建立快取用Volume。圖片來源／NetAppONTAP Select軟體定義儲存效能改善ONTAP Select是包裝為虛擬機器的ONTAP儲存裝置軟體定義版，針對VMware ESX部署環境，ONTAP 9.5版ONTAP Select的I/O效能有了顯著進步，原廠宣稱，無論是在硬體RAID還是軟體RAID組態下，比起9.4版的隨機與循序讀寫效能，均有12%到113%的提升。支援SMB多通道傳輸從ONTAP 9.4起，將能允許使用SMB3協定的用戶端主機，透過多個session、以多通道（Multichannel）方式來連結ONTAP儲存裝置，藉此可顯著提高使用SMB傳輸時的吞吐量。支援Max Data記憶體加速機制NetApp的Max Data是NetApp Memory Accelerated Data的簡稱，源自2017年Insight大會中宣布併購的Plexistor公司，是一種透過伺服器端的高速持續性記憶體（Persistent Memory）裝置，來提供快取加速，ONTAP從9.5開始支援這項技術，可讓ONTAP儲存裝置與安裝Optane 3D XPoint DIMM記憶體的伺服器之間，建立自動分層儲存架構，從而提高伺服器端的存取效能。嫁接在FC上的NVMe/FC傳輸架構ONTAP 9.4引進的NVMe/FC傳輸架構，是將NVMe指令包在FCP訊框中，從而能在FC傳輸通道上執行NVMe堆疊，以降低存取延遲。圖片來源／NetAppONTAP新特色２：雲端儲存整合雲端儲存是NetApp近期的重點發展方向，落實到具體的產品層面，則包括Cloud Volumes Services、Cloud Volumes ONTAP等雲端儲存服務，以及FabricPool雲端分層儲存功能這兩個面向。FabricPool是ONTAP 9.2引進的功能，適用於NetApp旗下的AFF全快閃儲存陣列、FAS混合儲存陣列，以及Cloud Volumes 與ONTAP Select等軟體定義形式儲存設備，可將公有雲的物件儲存空間，或NetApp自身StorageGRID物件儲存系統的物件儲存空間，連結本地端ONTAP儲存系統的Aggregate儲存群組，並在分層儲存政策管理下，作為冷資料儲存層，將快照或冷資料轉存到公有雲上，本地端只保留經常存取的熱資料。FabricsPool 的基本概念將公有雲服務商的物件儲存空間，與本地端ONTAP儲存系統的Aggregate儲存群組連結，將雲端儲存空間作為本地端的延伸空間，，然後在分層儲存政策管理下，扮演冷資料儲存層角色。圖片來源／NetApp自ONTAP 9.2引進FabricPool後，接下來的9.4與9.5版，都分別擴展了可支援的產品、公有雲服務商與分層政策類型。在ONTAP 9.2與稍後的9.3上，FabricPool只適用於AFF與FAS系列儲存陣列，公有雲服務商只支援AWS S3，分層政策則有Auto、Snapshot-Only、None等幾種；ONTAP 9.4的FabricPool則增加了適用於ONTAP Select、Cloud Volumes ONTAP等軟體定義儲存產品的能力，而且能同時用於SSD或硬碟Aggregate儲存群組，不像AFF與FAS儲存陣列的FabricPool只能用於全SSD 的Aggregate群組。ONTAP 9.4在搭配的公有雲服務商方面，新增支援微軟的Azure Blob Storage，另外，NetApp StorageGRID物件儲存系統的支援，也是在這一版納入，在分層政策方面，則新增Backup模式。在最新的ONTAP 9.5上，FabricPool又增加了對IBM Cloud Object Storage、Amazon Commercial Cloud Services等兩種公雲服務的支援。彈性的FabricPool 政策選擇Aggregate群組下的Volume可以個別套用FabricPool的分層儲存政策，有4種政策模式可選：Auto模式可將冷資料與快照複本轉存到雲端：snapshot-only模式只將快照副本轉存到雲端；None代表該Volume不將任何資料轉到雲端；Backup模式可將指定Volume的所有寫入資料，都立即轉存到雲端。ONTAP新特色３：儲存空間管理FlexGroup功能增強FlexGroup是2016年底，跟著ONTAP 9.1作業系統一同推出虛擬儲存功能，可以跨多臺叢集節點與多個Aggregate磁碟群組，建立容量達20PB、可容納4,000億個檔案的超大型單一命名空間，並能搭配分散式metadata與跨叢集節點的寫入快取，支援跨節點平行寫入，以及單一命名空間內的自動負載平衡，改善寫入效能瓶頸。接下來ONTAP 9.2增加了為FlexGroup Volume啟用加密的功能，ONTAP 9.3與9.4，又分別提供了設定傳輸率上限與下限的QoS管理功能。而到了ONTAP 9.5，則是為FlexGroup增加了支援FabricPool的能力，可在雲端分層環境下，建立跨Aggregate磁碟群組的大型命名空間，9.5版的FlexGroup也能支援全SSD的Aggregate磁碟群組，還新增了建立qtree子目錄，以及容量配額功能。新增非活躍資料報告功能可以在OnCommand System Manager控制臺上，顯示Aggregate磁碟群組中很少存取的非活躍「冷」資料量，以作為設定FabricPool分層儲存政策的參考。在FAS與AFF系列儲存陣列上，非活躍資料報告功能只適用於全SSD的Aggregate磁碟群組；在ONTAP Select、Cloud Volume ONTAP等軟體定義儲存陣列上，則能支援SSD或硬碟Aggregate群組。重複資料刪除與壓縮功能改進在Aggregate磁碟群組與其底下的Volume層級，各有一系列容量縮減技術。在Volume層級，提供了離線的後處理式重複資料刪除（Dedupe）、inline的即時Dedupe、離線式資料壓縮與Inline資料壓縮。其中離線式壓縮又分為Adaptive與Secondary 兩種。硬碟或混合Volume可適用Inline或離線等兩種壓縮功能，SSD Volume則只能使用inline的即時壓縮。Aggregate層級則有Data Compaction壓縮，以及Inline的IAD 與後處理式Aggregate Dedupe等兩種Dedupe。Volume層級的資料縮減功能，只適用於個別Volume，Aggregate層級的資料縮減，則能在跨Aggregate磁碟群組下的多個Volume，統一進行資料縮減處理。在ONTAP 9.4上，Aggregate層級的Dedupe增加了背景掃描功能，可支援後處理Dedupe。ONTAP 9.5則改進了Adaptive Compression，可提供更高的資料壓縮率。透過控制臺檢視非活躍資料報告自ONTAP 9.4以後，OnCommand SystemManager控制臺便預設啟用非活躍資料報告功能，可以檢視每個Aggregate磁碟群組中很少存取的冷資料容量比重。著眼於提高儲存空間的管理彈性，以及儲存空的使用效率的一系列功能更新。ONTAP新特色４：系統與資料可用性包括為NVMe/FC引進失效切換架構、支援NDAS資料保護服務，以及新增同步模式的SnapMirror遠端複製功能。引進NVMe/FC傳輸的高可用性架構ONTAP 9.4雖然引進了NVMe/FC傳輸架構，但不支援傳輸路徑的失效切換功能，在主機端與ONTAP儲存裝置端之間，只有單路徑連接，還無法滿足對可用性要求較高的用戶需求。這個問題到了ONTAP 9.5獲得了解決，新增了搭配非對稱命名空間存取（ANA）的NVMe/FC多路徑失效切換功能，可以在支援ANA架構的環境，提供主機端與ONTAP儲存裝置之間的NVMe/FC多路徑連接。雖然應用上目前還有許多限制，例如目前只有SuSE Enterprise Linux 15（SLES 15）支援ANA架構，但已較先前的單路徑NVMe/FC大幅提高了可用性。多路徑的NVMe/FC 傳輸架構ONTAP 9.4的NVMe/FC只能在主機端與儲存裝置之間，建立單路徑連接（如左圖），ONTAP 9.5則能透過ANA架構，在主機端與儲存裝置之間建立失效切換的多路徑連接。支援NDAS資料保護服務ONTAP 9.5導入的NDAS，是建立在公有雲上的資料備份與災難還原服務，目前只支援AWS，可利用一臺運行ONTAP 9.5的儲存裝置作為中介，利用ONTAP 9.5內含的proxy功能與Copy to Cloud API，將另一臺ONTAP儲存裝置的FlexVol Volume資料（目前NDAS只支援FlexVol），備份到AWS的S3 bucket空間內保存，還原時則可將該Flex Volume內的LUN或檔案，回復到原始或其他位置。同步模式的SnapMirror遠端複製在老的7-Mode模式時代，曾有過同步模式的SnapMirror遠端複製功能（SnapMirrorSync），不過當ONTAP轉移到新的Cluster-Mode架構後，就只剩非同步模式（Asynchronous）的SnapMirror遠端複製可用，只能提供以分鐘為間隔的RPO（還原點目標），還不能滿足無法忍受任何資料損失的用戶需求。到了最新推出的ONTAP 9.5，終於把同步模式的SnapMirror（簡稱SM-S）帶回來，可在兩個站點之間，提供幾乎完全不損失資料、RPO=0的遠端同步能力。要啟用SM-S，用戶必須為每一個節點購買SM-S授權，目前SM-S可支援FC、iSCSI與NFS v3等3種傳輸協定，並要求兩端點的網路延遲低於10ms。另外，SM-S可支援FabricPool Aggregate磁碟群組下的Volume，但目前還不支援FlexGroup下的Volume。 產品資訊NetApp ONTAP 9.4與9.5●原廠：NetApp(02)8729-5000●建議售價：廠商未提供●最新版本：9.5●適用機型與產品：NetApp FAS系列混合儲存陣列, NetApp AFF A系列全快閃儲存陣列, NetApp ONTAP Select系列軟體定義儲存套件●主要新功能：FlexCach功能擴展,增強FlexGroup選項, NVMe/FC新增支援施效切換, 新增NDAS資料保護服務, 新增同步模式SnapMirror ,支援MaxData加速【註：資料時有異動，正確資訊請洽廠商】2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "​兩大因素影響　希捷保守看今年資料中心市場的成長性 ": "",
        "Google為Compute Engine永久儲存空間增加排程快照功能 ": "使用者現在可以自定義政策，自動對虛擬機器執行個體的磁碟創建快照，還能設定快照留存政策，並且指定快照儲存的區域。Google宣布推出排程快照（Scheduled Snapshots）測試版，讓使用者能夠定期且自動的為虛擬機器執行個體的磁碟產生快照，使用者還能夠指定快照儲存區域，並簡單地以規則管理快照，決定保留或是刪除快照。使用者可以自定義快照計畫，該功能支援小時、天以及周頻率，因此使用者能讓系統以每6個小時創建快照，或是在每周一執行快照任務。除此之外，還可以半自動的管理快照，使用者只要在自定義快照策略中，加入快照保留政策，系統便會依照條件適時自動移除快照。排程快照可以應用在單一磁碟或是同一區域中的多個磁碟，使用者可以按規模創建排程快照。在定義快照時，使用者還能夠使用最新的儲存位置功能，指定快照的儲存區域，像是Google雲端存儲區域和多區域位置，例如us-central1或us，Google表示，為快照選擇指定的儲存位置，能更好地管理快照，對於需要符合資料在地化政策，以及業務連續性要求的企業特別有用。使用者可以使用API、CLI以及GCP開發者主控臺創建排程快照。在主控臺中，使用者在Compute Engine中的快照分頁中，能找到排程快照頁籤創建並管理快照排程，而在磁碟頁籤中，使用者可以將既存的一個或是多個磁碟加入排程計畫。2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "一圖看懂 QSAN XCubeFAS 全快閃儲存新體驗 (140365) ": "在還沒有硬碟的時代，KTV業者該如何撥歌？五六年級生最早上KTV，可是要從包廂內打對講機點歌，服務人員再手動切換卡帶完成撥放歌曲，在硬碟普及之後，便建置伺服器連結包廂，用軟體方式完成撥歌。隨著影音的音質與畫質提高，需要更大的容量，僅僅依靠在伺服器內的硬碟往往不敷使用，便開始連接外接磁碟陣列，後來更開始採用大型儲存區域網路(Storage Area Network；SAN)。現在一般來說一台SAN能讓超過三台主機伺服器串接，並且提供30-40個包廂使用，只要超過這個數量，或者SAN的效能不夠好，就會出現LAG的狀況。為了管理和營運成本的再降低，希望一台磁碟陣列機器，能提供更多的主機伺服器與包廂使用，有些KTV甚至已經開始使用儲存器全快閃陣列來增加效能。\n▲透過高速SSD可以讓你存取大檔案也能十分快速，有著傳統硬碟數十倍的效能表現。中小企業全快閃體驗計畫看到今天介紹的QSAN可能比較陌生，其實他們已經在儲存界耕耘多年，他們家的SAN在前面的KTV實務應用上，甚至可以支援超過120個包廂使用，QSAN廣盛科技對自家產品效能如此要求因為他們是個由一群工程師在2004年成立的公司，當年從研發iSCSI磁碟陣列控制器起家，並於2005年推出第一款iSCSI磁碟陣列控制器P100C，並致力於相關產品的研發。至今QSAN擁有完整的產品線，包括iSCSI、光纖通道、混合儲存區域網路、網路儲存設備、整合型儲存系統等產品。近幾年，學術界與產業界都致力於提升分系統和機器演算法的效能，而系統效能未能一同線性成長，背後就是需要儲存設備也一同提升才能滿足物聯網與巨量化的儲存時代需求，而為了讓大家在數位化浪潮中不被淘汰，QSAN XCubeFAS 2026D是以SSD為主體的新產品，有著傳統硬碟所難以達到的高速讀寫效能，非常適合給中小企業用戶使用。相較於過往1080p為主流的時代，現在的影片沒上4K@60fps很多人還看不上眼，雖然硬碟容量也隨時代進步，但問題在於傳統硬碟的存取速度進步幅度有限，導致容量夠了但速度跟不上的情況。因此現在有不少解決方案都是利用高速SSD替換傳統硬碟，適合需要在短時間內存取大量檔案的中小企業用戶。以QSAN的全快閃解決方案來說，搭載全SSD的儲存陣列在效能上可有3倍的IOPS，且VDI反應時間降低1000%。且透過新的結構設計，讓2U的機架空間內可容納26個SSD，也是世界上第一款2U26槽架構的產品，其效能密度提高了8%。XF2026D搭載的是Seagate大容量SSD， Nytro 3530 SAS SSD單顆容量最高達3.2TB，SAS雙埠頻寬為12Gb/s，另外搭配ECC演算法、媒體生命週期管理等功能，可提升產品可靠性。\n▲更快的速度，更短的反應時間，更佳的效能密度比，這些都是QSAN提供的特色。\n▲QSAN的其中一個特色是能在2U空間內置入業界最多的26個SSD。\n▲QSAN與Seagate合作，搭載大容量SSD，單顆容量高達3.2TB，且具有12Gb/ 秒 SAS 雙埠頻寬及2100MB/ 秒的極速效能。以讀寫效能來說XF2026D可在1毫秒延遲下，依然保持1200000IOPS，這是過往傳統硬碟無法提供的高速讀寫能力。另外搭配QSRAID技術，資料安全上提升9.8倍，管理者不需要擔心SSD生命週期造成的資料毀損等損失，另外透過快速重建、RAID EE技術在資料重建速度提升60倍。XF2026D在可靠度上，QSAN給予了3個保障，其一是永不停機，代表XF2026D在維護、升級、管理等層面提供了極高的可靠度。其次是永不間斷，利用熱插拔、全冗餘設計讓你擴充或是更新、維修時不需要停機。最後是永固保護，QSAN提供了獨特的演算法，QSRAID、QLIFE是專為SSD打造，保護XF2026D免於SSD生命週期到達時面臨的資料遺失。\n▲透過獨特的QSRAID功能，可提升資料保護的強度，以及資料重建的速度。\n▲單次大量部署的情況中，可以節省數十倍的時間。\n▲除了效能表現外，強調三永保障也是產品的特色。然而更換系統是件大事，若未使用過就全面更換總是讓人卻步。QSAN提供了中小企業全快閃體驗計畫，提供XCubeFAS XF2026免費體驗方案，讓你體驗更高效能的資料存取速度，另外還有嚴密的SSD監控功能、遠端備份、資料不間斷可供體驗。QSAN的XF2026D提供了過往傳統硬碟難以達到的高速傳輸，2U的空間內可容納26個SSD，可提供很高的機箱密度比，適合用於短時間存取大量檔案的中小企業用戶。整體而言，高效率、高穩定性，還提供快閃體驗計畫是XF2026D的優勢，若公司近期有更新系統的打算，或許XF2026D可以列入考慮。\n▲建構全新的系統畢竟不是兒戲，現在QSAN提供全SSD系統的體驗計畫。中小企業全快閃體驗計畫",
        "威聯通TS": "搭載Intel最新Coffee Lake平臺處理器，提供新世代I/O介面升級選項不久前發表的TS-x83XU系列，是威聯通（QNAP）最新一代機架式NAS產品線，翻新了硬體核心規格，改用Intel的Coffee Lake平臺Xeon E處理器，並全面搭配ECC記憶體，並提供豐富的擴充介面卡選項，軟體則搭配威聯通QTS NAS作業系統，擁有多樣化的檔案與區塊存取服務功能。威聯通旗下的機架式NAS產品，可依軟體平臺分為基於EXT檔案系統的QTS作業系統，與基於ZFS檔案系統的QES作業系統等兩大類型，TS-x83XU是QTS軟體平臺下的最新一代機架式產品系列，包含2U/8Bay到4U/24Bay等5種機箱款式，其中1U與2U機箱款式都有單電源與雙電源供應器兩種版本，3U與4U款式則均為雙電源供應器。這系列產品的最大特色，是搭載了Intel剛於2018年下半年推出的Xeon E處理器，是市面上第一波採用這種新處理器平臺的NAS產品。整個TS-x83XU系列中，除了最高階的4U機型搭載6核心的Xeon E-2136外，其餘都是搭載4核心Xeon E-2124處理器。在記憶體方面，則全面採用具備ECC功能的DDR4記憶體，不像威聯通先前的NAS產品線只有部份機型採用ECC記憶體。TS-x83XU系列硬體規格方面的另一個特色，是提供了入門級NAS少見的豐富擴充介面卡選擇，各機型都含有1到5個PCIe擴充槽，可搭配選購的各式介面卡，來擴展運算與I/O能力，包括Mustang 200 GPU卡、SAS HBA卡、10GbE網路卡，或是新的25GbE與40GbE網路卡等。而透過搭配SAS HBA卡，TS-x83XU系列均能外接最多8臺3U/16Bay或2U/12Bay的擴充儲存櫃，將系統總容量擴充到136～152臺磁碟。在軟體方面，TS-x83XU系列則是搭載最新的QTS 4.3.5版，提供了簡單易用的網頁控制臺介面、多種檔案與iSCSI區塊存取服務，還有SSD快取與自動分層儲存等功能。比較特別的是，還能搭配威聯通的QVR Pro數位視訊監控功能，可兼用於影像監控服務。 產品資訊：●原廠：威聯通(02)2641-1885●建議售價：廠商未提供●機箱尺寸：1U/4Bay, 2U/8Bay, 2U/12Bay, 3U/16Bay, 4U/24Bay●擴充能力：136～152臺磁碟●處理器：Intel Xeon E-2124或E-2136●記憶體：8/16GB ECC DDR4●主機端埠：GbE, 10GbE,可選購40GbE與25GbE2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "Google揭露蘋果尚未修補的macOS安全漏洞 ": "macOS核心XNU含有本地權限擴張漏洞，駭客能藉機開採macOS的記憶體管理系統並執行修改過的程式蘋果Google的Project Zero團隊在本周揭露了macOS核心XNU的本地權限擴張漏洞。Project Zero是在去年的11月30日向蘋果提報了該漏洞，於90天的期限之後將它公布，只是蘋果尚未修補。根據Project Zero團隊的說明，XNU具備各種介面以在不同的程序間建立寫時拷貝（copy-on-write，COW），包括Mach訊息的外部訊息描述符，這些拷貝的記憶體受到來源程序的保護以避免之後被竄改，否則來源程序就能在目標程序中進行雙重讀取。此一COW行為不只適用於匿名記憶體，也適用於文件映射，意味著在目標程序開始讀取已轉移的記憶體區域之後，記憶體壓力可能導致掌管已轉移記憶體的頁面被頁面快取逐出，有需要時再重新加載，因此，若駭客可在不知會虛擬管理子系統的情況下變更磁碟文件，便形成了安全漏洞。而macOS允許一般用戶掛載檔案系統映像，若呼叫pwrite() 直接變更此一映像時，掛載的檔案系統是不知情的。簡單地說，此一漏洞允許駭客悄悄變更所掛載的磁碟映像，藉由開採macOS的記憶體管理系統來執行修改過的程式。Google表示，蘋果已得知此一問題，並打算在未來的版本中修補，雙方正在合作評估修補選項。iThome Security2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29"
    },
    "Q2": {
        "新限制！電腦沒拔除隨身碟、記憶卡 將無法更新Windows 10 ": "\r\n今年五月微軟預計推出Windows 10 1905年度版本更新，但如果你的電腦插著USB隨身碟或外接SD記憶卡，系統將會禁止使用者進行升級。\n\r\n根據微軟的說法，即將發布的Windows 10 1905更新中，他們設立了一個限制，那就是如果使用者的電腦上，插著任何「外接儲存裝置」，如USB隨身碟、SD記憶卡甚至是行動硬碟等，在進行 Windows 10 1905版本更新時，除非使用者主動將這些裝置拔除，否則系統就不會進行升級，無論手動、自動更新都一樣。\n\r\n那為什麼會有這樣的限制呢？微軟指出，由於Windows 10 1905更新可能會導致系統中原有的磁碟機代號重新映射，例如原本被分配到E槽的USB隨身碟，在1905版本升級後，可能會被重新設定為G槽，有些情況下就連內接磁碟機都會受到影響。\n\r\n雖然說磁碟機代號重設的情況，對於一般使用者而言不會產生太多麻煩，但如果是長期運轉的自動化機器，或者電腦中有些程式，對於磁碟路徑特別敏感，當磁碟機代號變更後，就容易發生錯誤，最嚴重甚至會導致裝置當機，於是微軟才做出「一定要先拔除外接裝置」的更新限制。\n\r\n當電腦上插著 USB 隨身碟，將無法更新下個版本的 Windows 10\r\n今年五月微軟預計推出 Windows 10 1905 年度版本更新，但如果你的電腦插著 USB 隨身碟或外接 SD 記憶卡，系統將會禁止使用者進行升級。\n\r\n根據微軟的說法，即將發布的 Windows 10 1905 更新中，他們設立了一個限制，那就是如果使用者的電腦上，插著任何「外接儲存裝置」，如 USB 隨身碟、SD 記憶卡甚至是行動硬碟等，在進行 Windows 10 1905 版本更新時，除非使用者主動將這些裝置拔除，否則系統就不會進行升級，無論手動、自動更新都一樣。\n\r\n那為什麼會有這樣的限制呢？微軟指出，由於 Windows 10 1905 更新可能會導致系統中原有的磁碟機代號重新映射，例如原本被分配到 E 槽的 USB 隨身碟，在 1905 版本升級後，可能會被重新設定為 G 槽，有些情況下就連內接磁碟機都會受到影響。\n\n\r\n▲ 如果插著外接儲存裝置升級 Windows 10 1905，將會得到無法更新的警告。\n\r\n雖然說磁碟機代號重設的情況，對於一般使用者而言不會產生太多麻煩，但如果是長期運轉的自動化機器，或者電腦中有些程式，對於磁碟路徑特別敏感，當磁碟機代號變更後，就容易發生錯誤，最嚴重甚至會導致裝置當機，於是微軟才做出「一定要先拔除外接裝置」的更新限制。\n\r\n除此之外，微軟也特別指出上述問題，將會於未來的 Windows 10 更新版本號 18877 中得到解決，但很顯然 1905 版本更新發表時，還無法搞定這個 Bug。\n\r\n換句話說，如果使用者想升級到最新版本的 Windows 10，就一定得移除外接儲存裝置。另外，這個限制只會出現 Windows 10 1803、1809 的系統版本，嘗試升級至 1905 版本時出現。\n\r\n不過在微軟發表該技術支援文章後，許多不是很喜歡 Windows 10 半強迫更新的網友戲稱，他們終於找到了不要讓電腦自動更新的方法，那就是讓電腦一直插著隨身碟！\n\r\n●來源：Microsoft\n《原文刊登於合作媒體T客邦，聯合新聞網獲授權轉載。》\n                    或許是因應目前在家工作比例增加，同時需要透過視訊連線進行線上互動的需求也開始變多，Facebook稍早宣布推出名為Messenger Rooms的全新服務，讓使用者可以直接透過連結網址即可快速參加線上視訊會議。                  \n                    隨著新型冠狀病毒疫情在美國境內擴大，蘋果稍早與美國疾病管制與預防中心，以及美國白宮、聯邦緊急事務管理署在內機構合作，共同推出「COVID-19」app，讓使用者能透過簡單提問互動確認是否有感染可能，或判斷是否身處高風險疫區，同時也能讓使用者快速透過app掌握防疫觀念。                  \n                    隨著疫情全球爆發，許多歐美國家皆發布禁令禁止出門，台灣也有許多公司行號、教育機構預先開始準備視訊會議、遠距教學的演練，幸...                  \n                    點數經濟夯，透過Google Play購買App、看電子書、租借電影，現在都能累積點數換優惠了！Google今宣布，作為...                  \n                    由悠遊卡公司打造的悠遊付電子錢包服務，預計會在今年3月底正式上線提供使用，但確定初期僅支援NFC的Android手機綁定後，透過趨近感應方式完成支付，同時也能用於乘坐捷運、公車、火車或高鐵在內交通運輸工具。而iPhone方面則因為蘋果尚未全面開放第三方app使用其完整NFC功能，因此暫時還無法支援感應支付功能，但其他悠遊付功能則與Android手機相同。                  \n                    根據PTT的網友分享「武漢肺炎歷史軌跡比對」這個網站，這是g0v推出一個可以自動檢查你是否碰過新冠肺炎患者的網站，主要的原理就是透過你在Google地圖記錄你的時間軸足跡，比對目前指揮中心公布的患者的足跡，看看兩邊的足跡是否有重疊。當然，你也可以手動自己檢查，但是隨著病例越來越多，當然還是線上直接比對來得方便。                  \n                    多iPhone的使用者，可能會每隔一段時間，就利用上滑的動作去關閉一些沒有用到的應用程式，原因是擔心這些應用程式不關閉可能會耗電。不過，蘋果現在表示，在多數情況下，上滑關閉應用程式不見得會省電，而且反而可能會縮短iPhone的電池壽命、並且手機的動作可能也會變慢。                  \n                    排序是excel中一個十分重要的功能，能讓我們的數據瞬間變的井井有條，但要如何把一個表格內的數據順利的排序，說起來簡單但是實際操作上還是有很多要注意的小重點，才不會不但沒排序好還讓整個表格亂掉。                  \n                    Samsung 三星使用者在台灣時間 2020 年 2 月 20 日下午應該都有收到「尋找我的手機」的通知，但這通知內容只有「1」，到底是什麼情況？\r\n\r\n根據《Yonhap News》韓國聯合通訊社報導，這是 Samsung 三星公司內部測試錯誤才會誤發訊息，對使用者的手機沒有任何影響，並為消費者帶來的不便致歉。                  \n                    儘管近期對手微軟 Teams 正大打廣告，但 Slack 送交美國證管會的文件顯示，IBM 已全面採用 Slack 作為內部協作工具，是全球最大規模企業之一。                  \n                    BBC報導，中國大陸政府推出一款app，讓民眾可以偵測是否有新冠肺炎（武漢肺炎）的確診或疑似患者靠近，察覺自己是否有感染...                  \n                    即便是在即時通訊服務盛行的年代，電子郵件對於一般人而言，依然是相當重要的網路服務，對於多數企業而言更是用於建立聯繫，或是用於確認、溝通工作事項必要工具。                  \n\n\n\n\n\n",
        "【防制資料竄改，阻擋勒索軟體的終極手段】WORM一寫多讀技術的資安新應用 ": "過去主要用於防止資料竄改與法規遵循的一寫多讀（WORM）技術，在資料加密勒索危害日益高漲的今日，也能在保護資料方面提供幫助iThome一寫多讀（Write Once Read Many，WORM）技術，最初是為了法規遵循與資料長期歸檔保存而誕生，但憑藉著防止資料竄改的能力，在今日的資安防護應用中，也能扮演要角。舉例來說，近年來，勒索軟體已成為企業最主要的資安威脅之一，備份雖然被視為因應這類威脅的重要手段，當線上資料遭到勒索軟體侵害後，仍能透過備份複本還原資料，但如果企業的備份架構未能擁有適當的防謢措施，備份複本也可能一同遭到勒索軟體的感染，以致備份複本也不可用。在勒索軟體威脅下，為求保住作為企業資料最後命脈的備份複本，資安廠商與備份軟體廠商，也提出了各式各樣幫助企業保護備份複本的反勒索軟體措施，例如引進離線備份儲存架構（磁帶或可移動的外接磁碟）、為備份軟體引進反勒索軟體的偵測與阻擋加密功能等，不過，這些手段大都是從備份作業的前端來著手，如離線備份是透過實體隔離方式，減少備份複本接觸病毒的機率；備份軟體的反勒索措施則透過監控備份過程，阻擋可疑的資料加密動作。現在則有廠商提出了不同的思路，直接從備份儲存媒體本身著手，利用一寫多讀（WORM）技術防止資料竄改的特性，從根本上防止備份資料遭到勒索軟體的侵害。防制勒索加密的新思路顧名思義，一寫多讀（WORM）技術只允許對儲存媒體寫入一次資料，然後，儲存媒體便成為無法複寫、修改或刪除的唯讀屬性。最初，WORM技術是為了長期資料保存或法規遵循應用而誕生，透過儲存媒體的物理性質特性，或是儲存系統底層軟體、韌體功能，確保寫入儲存媒體或指定儲存區的資料，無法再被更改或刪除，以提供法律與訴訟上的有效性。而利用WORM技術保存資料的特性，對於保障資安也能發揮作用。由於WORM能保證寫入後的資料，狀態不再變化——既不可刪除，也不可更改，徹底「鎖住」了資料狀態，那麼自然也不會遭到勒索軟體的加密。當WORM用於備份儲存時，即使備份複本已感染勒索軟體，但由於WORM機制已經「鎖住」了資料狀態，先天上就遏止了勒索軟體發作、加密或刪除資料的可能性。所以在勒索軟體危害盛行的今日，WORM技術也展現出應用於法規遵循以外領域的潛力，開始有廠商推出結合了WORM技術的備份防護解決方案。WORM技術的基本類型WORM是一項歷史悠久的技術，光學式WORM技術早在30年前就已問世，磁碟式WORM產品推出市場，也已經超過15年。一般來說，WORM技術可以依照儲存媒體的類型，分為光學媒體式與磁性媒體式兩大類型，不過我們認為更邏輯的區分方式，是依照WORM「鎖住」資料的方式，依此可以將WORM概分為物理型、韌體型與軟體型等三大類，分別透過物理特性或機構，儲存裝置韌體，或是儲存系統軟體，來提供WORM能力，這三種形式各自利用不同原理運作，從而擁有不同層次的保存資料能力，以及使用特性。物理型的WORM技術利用儲存媒體本身的物理性質，或是物理機構方面的設計，來提供一寫多讀的能力。許多光學儲存媒體如CD-R、DVD-R等，都能透過材料本身的特性，提供只允許寫入一次，資料從此成為唯讀的能力。物理型WORM最大優點是極為可靠，其防寫措施是建立在儲存媒體的物理性質上，從根本防止了刪改資料的可能性。例如，光學儲存媒體的WORM機制，是透過加熱光碟片染料產生的化學變化，帶來光碟片反射率的變化來實現，而這個過程是不可逆的，只要物理法則沒有被推翻，任何人也無法違逆物理法則、刪改光學WORM媒體的資料，唯有物理破壞手段才能銷毀其中的資料，因而是最可靠的一種WORM技術。光學式WORM的主要缺點，是使用較為不便。首先，光學媒體的容量較小，如BD-R的單碟片容量最大只有50GB，需要很大數量的光學媒體，才能完整保存前端主機的資料。其次，光學式WORM儲存媒體屬於離線儲存裝置，因而也難以因應經常讀取或檢索的需求。除了光學媒體外，磁帶、軟碟片之類的磁性儲存媒體，也能透過遮蓋防寫孔，來達到資料寫入後便不再允許更改的能力，同樣算是一種物理的防寫手段——當寫入資料後，隨即遮蓋防寫孔，便構成了一寫多讀應用。但這種防寫能力是可逆的，只要解除防寫孔就能寫入資料，不能算是真正WORM媒體。類似的，有些SD記憶卡雖然也提供了防寫開關，但同樣是可逆的，而且防寫機制也很容易遭到繞過，防刪改的可靠性並不充份。所以，磁帶與SD卡的WORM應用需求，必須由專門的WORM磁帶與WORM SD卡來提供，而這兩種WORM裝置都是依靠微控制器韌體來提供WORM能力，屬於我們後面介紹的韌體型WORM技術。韌體型的WORM技術利用儲存裝置的韌體，將儲存媒體設定為一寫多讀，適用於磁帶、SD卡與SSD在內的儲存媒體。幾乎所有主流磁帶系統都能提供專用的WORM卡匣，透過磁帶機的微碼控制功能，與磁帶卡匣上的識別微碼配合運作。當磁帶機識別出磁帶是WORM形式時，便會禁止更改或刪除已寫入該磁帶中的資料。如當前最普遍的LTO磁帶，只要是LTO 3以後的規格，都有對應的WORM磁帶版本。另外Sony的AIT、IBM的3592，SotrageTek T10000等磁帶，也都有WORM版本可供選購。不過，即使是WORM磁帶，理論上，也能透過從外部施加強力磁場的方式，透過消磁來強制刪除這類磁性儲存媒體中的資料，所以，必須同時搭配實體管制措施，才能完整保證資料的完整性。類似的，當前也有一些SD卡與SSD提供了WORM功能，透過儲存裝置的微控制器，鎖住Flash記憶體的刪除功能，只剩下寫入與讀取功能，所以特定記憶體區塊被寫入資料後，就無法再刪除與複寫，只能讀取。比起WORM磁帶，WORM SD卡或WORM SSD的防刪改能力更為可靠，雖然依靠微控制器韌體所實現的資料防刪改能力，不像光學WORM裝置那樣絕對不可逆，但是在實務上，繞過微控制器韌體的可能性很低，可認為擁有接近光學WORM技術的可靠性，只有物理破壞手段能銷毀其中的資料。軟體型的WORM技術在儲存陣列設備上，也能利用儲存作業系統的軟體功能，將指定的儲存區設定為一寫多讀，只要設定了WORM，即使是系統管理者，也無法刪改該儲存區的資料。為了保證WORM功能的強固性，多數軟體實作時都會依循一些相關的官方資料保存與資料完整性監控規範，例如美國證券交易委員會的SEC 17a-4(f)（針對證券交易業者的電子資料保存規範），或是美國聯邦政府的FDA 21 CFR Part 11（針對醫療業的電子紀錄保存規範）等。不過，與物理型或韌體型WORM技術比起來，軟體型WORM技術的防刪改能力，仍相對較不可靠，由於是依靠儲存控制器的軟體來提供WORM功能，只要將磁碟機移出儲存設備之外，該磁碟機就連帶失去WORM特性，所以需要搭配實體管制，才能保證完整WORM能力。而軟體型WORM技術的優勢，則是使用便利。首先，是可透過CIFS/SMB、NFS等標準傳輸協定存取，便於因應快速讀取與檢索的需求。其次，可透過設定保存期限，提供「有管制」的可逆機制。一般來說，WORM軟體功能都會提供設定保存期限的選項，讓管理者選擇「鎖住」特定檔案或物件的時間，到期後，便會解除該檔案或物件的WORM狀態，此後便能將資料刪除，回收儲存空間；如果將將保存期設為無限大，則被鎖定的檔案或物件，就成為與WORM光碟或WORM磁帶一樣的永久性WORM。而軟體型WORM技術落實到實際產品上時，又可分為專用型WORM儲存設備，以及通用儲存設備的WORM功能等兩大類型。● 專用型WORM儲存設備如名稱所示，是專門針對法規遵循的資料保存需求、以提供WORM功能為目的設計的儲存設備，這類產品中，最知名的便是Dell EMC的歸檔儲存系統Centera，還有IBM的Total Storage Data Retention 450等。GreenTec USA在這方面也著力甚深，該公司旗下提供了CYBERdisk WORM軟體，以及專供WORM應用的WORMdisk系列外接磁碟，與Ninja系列WORM 儲存伺服器產品，最特別的是，該公司還提供搭配雲端環境應用的WORMcloud服務。● 通用型儲存設備的WORM功能是在NAS類型通用儲存設備系統中，提供WORM軟體功能選項，可將指定的儲存區設定為WORM。目前許多中高階NAS儲存平臺，都提供了WORM功能選項。例如NetApp ONTAP儲存系統的SnapLock功能；Dell EMC旗下Isilon系列NAS的SmartLock功能，PowerMax與Unity儲存陣列NAS應用功能中的File-Level Retention，Data Domain平臺DD OS儲存系統的Retention Lock功能；還有HPE 3PAR儲存陣列 FilePersona軟體套件中的File Lock功能等。另外一些高階的虛擬磁帶櫃（Virtual Tape Library，VTL）產品，也能提供軟體形式的WORM功能選項，如IBM TS7700、富士通ETERNUS CS8000與CS High End等。除了前述高階儲存設備外，有些中、低階或入門級NAS的儲存作業系統，也提供WORM功能選項，如國產廠商QSAN的XCubeNAS，以及商丞（Proware）的Unified Storage，還有3Gen的Unified Platform等，這些產品可為資源有限的用戶，提供低成本的WORM儲存應用。另外，部份公有雲儲存服務的物件儲存環境，目前也提供了WORM功能選項，例如Amazon S3的S3 Object Lock功能，以及Google Cloud Storage的Bucket Lock，可為雲端環境上儲存物件，提供WORM屬性設定。WORM的資安延伸應用WORM雖能保證資料的完整性，但畢竟只是一種消極的保護，作為把守最後一關的防止資料竄改手段。不過，以WORM技術為基礎，再結合其他儲存與資安技術，便能提供更豐富的資安防護應用。例如Dell EMC的Cyber Recovery，便藉由結合WORM、遠端複製、快照、與資安分析等技術，提供了一種嶄新的資安解決方案概念。先經由遠端複製獲得用戶資料的複本，然後透過WORM技術，確保獲得的用戶資料可靠性與不可竄改，再透過快照產生不同時間點、具備或不具備WORM特性的複本，最後將這些複本用於資安掃描、分析或測試等用途。如此一來，便能在保障用戶資料不可刪改的同時，將用戶資料複本用於不同目的，不僅提高複本的可利用性，也擴展了WORM的附加價值。【結合WORM、遠端複製與快照的資安應用】Dell EMC Cyber Recovery儲存業界龍頭Dell EMC推出的Cyber Recovery，是一款應用了一寫多讀（WORM）技術、具備資安防護功能的資料備份歸檔儲存套件。這款產品最初在2016年問世時，稱為Isolated Recovery Solution，2018年以後改稱為Cyber Recovery，目前最新版本是18.1版，其中的18代表2018年，.1代表版本編號，18.1表示這是2018年的第1個主要版本。Cyber Recovery的組成與運作一個Cyber Recovery環境稱作Cyber Recovery Vault（CR Vault），包含了下列元件：● Dell EMC的Data Domain儲存伺服器：負責提供儲存空間，以及WORM、遠端複製與快照等功能。● Cyber Recovery管理伺服器：執行Cyber Recovery軟體，提供系統管理，與對外連接的資料傳輸。● 應用分析伺服器：整合了稱作CyberSense的自動分析功能，提供資安分析服務。● 備份應用還原伺服器：運行Avamar、Networker等備份軟體，負責還原CR Vault內保存的備份資料。● 應用程式還原伺服器：作為應用程式還原的目標裝置。CR Vault最多支援10套Data Domain系統，至於4種應用伺服器，則可安裝在專用的實體伺服器，不過，一般是由1臺Dell EMC VxRail超融合伺服器，透過VMware ESXi HA Cluster平臺以VM型式來部署。CR Vault構成了一個對外實體隔離的環境，用於保存關鍵資料，並提供資安分析與資料還原等應用功能。在標準的Cyber Recovery架構中，要求前端生產環境也要有一套Data Domain儲存設備。基本運作過程可以分為3個階段：Cyber Recovery的運作過程可分為3個階段：（1）資料同步：生產環境的Data Domain儲存設備，透過MTree Replication遠端複製功能，在Air Gap管制下將資料複製到CR Vault的Data Domain儲存設備。（2）建立不可刪改的還原點複本：透過Retention Lock與快照功能，建立不可刪改的多個還原點複本。（3）建立資安分析用複本：透過快照建立可讀寫的複本，用於資安分析、測試等目的。 圖片來源／Dell EMC 階段1  在生產環境，前端主機將資料寫入生產環境的Data Domain儲存設備，然後利用Data Domain的MTree Replication遠端複製功能，將資料同步到CR Vault內的Data Domain儲存設備上。從生產環境到CR Vault的複製作業，是透過管制的Air Gap機制來進行，只有在進行複製時，CR Vault的傳輸埠才會開啟，複製結束後就關閉，維持CR Vault的隔離。 階段2  當CR Vault的Data Domain儲存設備接收到前端生產環境的資料後，透過Data Domain的Retention Lock鎖住備份資料的狀態，成為一份不可刪改的黃金複本（Golden Copy），接下來再利用Data Domain的快照功能，從黃金複本產生多份不同時間點的快照複本，這些快照複本也具備不可刪改的特性。 階段3  在CR Vault建立可寫的複本，然後掛載給分析伺服器或備份應用還原伺服器，用於資安分析、資料還原演練或是測試等情境。Cyber Recovery保護資料的單位，是以Data Domain儲存設備的Mtree儲存區為基準，在生產環境的Data Domain儲存設備上，每一個被保護的Mtree，在CR Vault還鏡的Data Domain儲存設備上，都會產生3個以上對應的Mtree複本，其中1個是作為遠端複製目的地的MTree複本，1或多個透過Retention Lock保存的Mtree複本，還有1個可讀寫、掛載給CyberSense用於資安分析的Mtree複本。WORM扮演的角色整個CR Vault是與外部實體隔離的，唯一的對外通道是Air Gap管制下的傳輸埠，只在資料同步傳輸作業時開啟。而Data Domain的Retention Lock功能，則能確保CR Vault收到的黃金複本不可刪改。透過Air Gap的實體隔離管理，與Retention Lock功能的防止資料刪改能力，共同確保了CR Vault的安全性。Cyber Recovery使用的Retention Lock功能，可以是Governance或Compliance等兩種版本，兩者都能提供個別檔案層級的資料保存時間設定，其中Governance版允許系統管理員調整資料保存設定，Compliance版則需要更高的雙重用戶授權（如系統管理員+資安長），才允許調整資料保存設定，防護等級更高，可符合SEC 17a-4(f)、FDA 21 CFR Part 11、CFTC Rule 1.31b、Sarbanes-Oxley Act、ISO Standard 15489-1等資料安全規範。透過Retention Lock可提供個別檔案層級的資料鎖定與保存期限設定，不過在Cyber Recovery中，是以鎖住整個MTree儲存區為原則。此外，CR Vault也不以長期保存資料為目的，所以建議的Retention Lock設定期限是7～45天。2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "Windows 10 1809 版本已預設隨身碟可「快速移除」 ": "Microsoft Windows 10 作業系統在 1809 與之後的版本，都已經將隨身碟、隨身硬碟等外接儲存裝置設定為「快速移除」，如此一來無須「安全地移除硬體」操作，也可安心的插拔隨身碟裝置。以往系統預設為效能更好，使得常遇到沒安全移除導致資料損壞，甚至也有程式 Hold 住隨身碟導致無法安全移除的狀況；用戶可在磁碟管理中，選擇隨身儲存裝置的內容，並於硬體頁面再選擇隨身儲存裝置後，即可在「原則」頁面中，確定裝置已套用「快速移除」原則。source: support.microsoft.com我是 Sinchen。  Remember Me Lost your password?",
        "群暉展出多款瞄準企業應用新產品 ": "群暉(Synology)在臺北國際電腦展期間舉辦獨立展覽，會場中展出多款以企業環境應用為主的新產品，為企業主提供穩定的運算與儲存設備。臺北國際電腦展 COMPUTEX TAIPEI向來是各家廠商展出年度新品的時間，不過這幾年群暉(Synology)大都自行設置場地展示新品，今年也不例外，只是場地不在電腦展附近，而是在公司所在的一樓空間展示。這次群暉展示的產品當然還是以網路儲存(NAS)為主，其中多款新產品還是以企業應用為主，也有數款未來即將推出的消費型產品。網路存儲系統是現今許多企業的重要設備，此次群暉推出數款新產品，以不同的應用層級供企業選擇。在企業級機架式網路儲存系統方面，群暉展出SA3400、SA3600，還有全快閃儲存的FS3400、FS3600與FS6400。 SA3600機架型的 SA3400與SA3600是採用新命名系列，SA代表是SAS介面，除了機箱本身的儲存裝置安裝空間之外，還可以透過 SAS連接線串接機箱，以擴充更多的儲存空間。SA3400與SA3600皆採用 Intel Xeon D系列處理器，前者為 Xeon D-1541 8核心處理器，而後者則是更高階的Xeon D-1567，擁有高達12個核心。SA3400與SA3600預設皆有16GB的主記憶體，當然也可以依照需求加以擴充，最高可擴充至128GB。 SA3400SA3400與SA3600除了本身擁有12個儲存裝置安裝空間外，利用 SAS介面還可串接如RX-2417sas或是RX-1217sas儲存櫃，最多可串接七個機箱而擁有極大的儲存空間。在網路連接方面則內建二組10Gb與四組1Gb乙太網路，可以設定成備援或是網路聚合模式。 FS3600 FS3400需要高速儲存效能以便使用虛擬機等應用的企業，全快閃儲存伺服器應該是較好的選擇。全快閃的FS3400與FS3600二款產品其主要硬體規格與SA3400/SA3600類似，包括中央處理器、主記憶體與網路連接埠設置數，不同的地方在於內建儲存空間數量與可擴充空間。FS3400/FS3600皆具有24個儲存空間位置，利用SAS介面連接儲存櫃時，最多可串接二個機櫃來擴充空間。 FS6400除了以上二款之外，群暉還推出一款性能更高的全快閃儲存伺服器FS6400。FS6400採用更高階的Intel Xeon Silver 4110 八核心處理器，搭配32GB的主記憶體(最高可擴充至512GB)。儲存容量同樣可支援串接二個磁碟櫃，系統最多可達到72個儲存裝置。 E10M20-T在這幾台機架型的產品中，有一個許多人期待的新產品，即E10M20-T1，這是一片PCIe介面的擴充卡，除了使用Aquantia的10Gb乙太網路之外，後半段還可安裝 M.2規格的PCIe SSD或SATA SSD做為快取之用。安裝尺寸除了常見的2280外，更可支援 22110，上方也有散熱片讓 SSD維持在較佳的性能表現。目前群暉的產品中，只要能安裝PCIe介面卡的產品應該都可以使用。 Unified Controller UC3200在企業級的產品中，還有一款特別的Unified Controller UC3200，這是一款二個節點的控制器，提供企業高可靠性運作。UC3200是群暉首款雙主動架構儲存伺服器，提供不中斷的 iSCSI服務。透過 Dual-Active架構，重要的硬體零件皆有二組，不會因為單個元件損毀而無法服務。 UC3200內有二組完整的系統群暉的 NAS產品其實也有高可用性的功能，不過利用二台NAS組合時，主要是採用軟體解決方案，備援替換的速度稍有受限。但是在 UC3200上，備援接替時間很短，大約在三十秒之內，合乎大部分系統的要求，而且大部分使用者根本感覺不出來服務其實有換成另一台執行。更重要是UC3200沒有複雜設定，單一操作介面輕鬆管理系統。 DVA3219至於消費性產品方面，群暉展示整合深度影像分析技術的可擴充網路監控伺服器 DVA3219，這款外觀看來很像一般四個bay的NAS，但是內部搭載 NVIDIA GeForce GTX 1050Ti顯示卡，加上深度影像分析技術 DVA(Deep Video Analytic)技術，透過深度學習提高物件辨識準確度以及集中計算資源與投資成本。DVA3219可將連接的攝影機等影像資料做分析，包括六種影像分析識別規則，分別為物件偵測、動作偵測、禁止逗留區、人流計數、外來物件與遺失物件，也會自動判別背景的動作，如下雪或是被風吹動的樹葉，可為居家或中小型商場的安全把關。 DS620slim  DS419slim另外有二款屬於slim系列體型非常小巧的 NAS產品，分別為DS419slim與DS620slim，此系列產品因為使用 2.5吋的儲存裝置插槽，讓體型比傳統 3.5吋機種縮小很多。DS620slim採用Intel Celeron J3355處理器，可安裝六個儲存裝置，並具有二個1Gb網路連接埠。而DS419slim就更小巧，它採用Marvell雙核心處理器，四個儲存裝置與二個網路連接埠。想要使用較不占空間的NAS時，這二款應該是個不錯的選擇。在科技媒體多年，為Xfastest News網站科技產品發表會或是記者會採訪記者，也是Xfastest採訪文撰寫編輯。  Remember Me Lost your password?",
        "Dropbox要採用冷儲存服務以節省磁碟使用量與成本 ": "基於用戶檔案存取頻率有高低之分，Dropbox決定建立兩個不同的儲存層分開存放以節省成本，並強調資料不論是存放在暖儲存或冷儲存，幾乎不會造成系統使用上的延遲雲端儲存業者Dropbox宣布即將採用新的冷儲存（Cold Storage）服務，以用來儲存存取頻率較低的資料，並強調資料不論是存放在暖儲存（Warm Storage）或冷儲存，幾乎不會造成用戶的不便。Dropbox在2016年將基礎設施從AWS移回自家架構時，建立了Magic Pocket來容納數個Exabyte（EB）的龐大資料量，迄今已有超過90%的用戶資料是存放在Magic Pocket上。有鑑於使用者存取新舊資料的頻率不同，現在Dropbox新建了冷儲存層，並將原來的Magic Pocket系統更名為暖儲存層。Dropbox指出，檔案剛被上傳時的幾個小時內存取頻率最高，之後的存取頻率便隨著時間而大幅下滑，這使得該站工程師認為若以同樣的方式儲存所有檔案並不合理，於是決定建立兩個不同的儲存層 。其中的暖儲存層其實就是標準的Magic Pocket系統，具備高儲存密度與非常快速的網路連結，而冷儲存層也是基於同樣的硬體及網路，但藉由減少25%的磁碟使用量而能節省成本，卻不會犧牲可用性與續航力。Dropbox說明，當系統判斷資料變冷之後，就會於背景異步將資料轉移至冷儲存，儘管它的存取延遲可能會高於暖儲存層，但用戶幾乎難以辨識兩者的差別。2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "光寶展出雲端儲存及中小企業應用儲存解決方案 優化新世代儲存與伺服器固態硬碟應用 ": "全球固態硬碟領導大廠光寶科技，領先為人工智慧與物聯網發展潮流，帶來先進高效雲端及伺服器領域SSD產品。全力協助企業、產業與科技生態鏈，打造新世代邊緣運算、大數據分析、伺服器及儲存系統。 光寶科技儲存裝置事業群在企業級SSD市場的卓越實力，長期以來持續滿足全球企業的雲端、伺服器及資料中心建置需求。由光碟機儲存市場全球市占第一的優異成績背景，到資料中心領域NVMe SSD占有率全球排名第三的成就，光寶儲存深耕企業級SSD市場早已贏得業界一致肯定。透過最先進的自動化生產流程、國際級PCIE 協定認證(UNH-IOL)，讓光寶儲存能滿足各產業的系統整合規劃目標，無論是主機、伺服器、資料庫、雲端及物聯網建置，都能提供最值得信賴的SSD儲存支援。 光寶科技儲存裝置事業群於5月29日至31日為期三天，在全球營運總部展示的多項最新雲端及中小企業SSD產品應用與技術，充分呼應了本屆台北國際電腦展（Computex 2019）所揭示的AI及IoT趨勢。雲端及伺服器級SSD，能透過效率、穩定及安全性，幫助打從從物聯網、嵌入系統、雲端資料中心到人工智慧應用的儲存架構。光寶SSD解決方案贏得企業信賴的原因，來自嚴格的生產製造及品管流程，所有伺服器與資料中心SSD產品，都通過模擬數據中心環境測試、高低溫測試與高密度讀寫驗證，並有大型專業團隊提供客製化服務。光寶科技儲存裝置中小企業業務處處長何美慧表示：「面對AI與IoT潮流，企業用戶更提昇要求邊緣運算、雲端、伺服及資料中心架構中的儲存能力。光寶儲存在企業SSD市場建立的長期實力，包含了優異的開發團隊、獨家韌體設計，以及最完整的全球品牌與供應鏈支援。因此能針對客戶的雲端、人工智慧及物聯網未來發展，協助量身打造最先進的各式伺服器與資料中心儲存解決方案。」 光寶科技本次展出的最新SSD解決方案，完整涵蓋各型企業市場及應用領域：企業級高效安全解決方案獨家「即時遠端資料監控分析」及「磁碟異常預測」技術，能即時監測碟機健康狀況並分析異常行為，提前預防可能的系統問題。同時支援 Open-channel SSD 架構，能大幅提昇資料處理效率。此外並符合TCG Opal 2.0 規範，並支援加密技術及Secure Boot數位簽章啟動機制，帶來最全面的保密安全性。中小企業應用解決方案針對各產業領域的客製架構，高規格滿足由博弈遊戲機台、網通、POS、IoT到自動化控制的SSD儲存應用。無論是電子遊戲機或博奕設備，提款機與Kiosk公用資訊站，或是伺服路由及工業電腦、嵌入式系統，全系列SSD產品都能以最高使用壽命，以及通過嚴格可靠度測試的高溫、抗震及穩定讀寫規格，滿足所有中小企業的新世代機台及裝置設計。 關於光寶科技儲存裝置事業群光寶科技儲存裝置事業群是全球企業及消費級固態硬碟（SSD）領導廠商，全方位滿足PC客戶端、工業解決方案，企業及雲端運算資料中心的SSD設計，開發及製造需求。LITE-ON為儲存市場領先業界於2012年推出企業級產品。 光寶SSD解決方案提供完整的介面規格級外型尺寸，採用業界先進關鍵零組件，創新設計與嚴格測試帶來最高品質與效能，多樣化產品能滿足各產業客戶的規劃建置選擇。 展間圖輯 如需進一步了解光寶儲存更多相關資訊，請造訪：www.liteonssd.com大家好!!我是XFastest News新聞發佈員，專職科技新聞編輯、業界資訊露出、廣編文章撰寫等，歡迎指教與交流。  Remember Me Lost your password?",
        "Windows 10新政策：外接儲存裝置可直接拔掉，不必再走安全移除程序了 ": "Windows 10 1809更改外接儲存媒體的移除政策，用戶可隨時直接移除USB，不必再走安全移除硬體的程序微軟微軟於Windows 10 1809（Windows 10 October 2018 Update）變更了外接儲存媒體的移除政策，將預設值從「更佳效能」（Better performance）切換成「快速移除」（Quick removal），意謂著Windows 10 1809用戶未來可隨時地直接移除外接的儲存裝置，不必再經由「安全移除硬體」（Safely Remove Hardware）程序。過去當Windows用戶要移除USB或Thunderbolt等任何外接儲存裝置時，都必須先在工作列上點選「安全移除硬體」的圖示，它的目的是為了保護外接裝置上的資料完整性，確保所有的快取操作都已完成。事實上，它也是為了改善系統的效能，讓Windows能夠快取外部磁碟的寫入作業。而當切換至「快速移除」時，Windows無法再快取磁碟寫入作業，以確保它隨時可被移除，因而可能造成系統效能下滑。使用者還是能根據需求變更每個外部裝置的移除政策，但微軟提醒，若切換至「更佳效能」政策時，最好允許寫入快取，而且一定要執行「安全移除硬體」，否則將面臨資料遺失的風險。2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "電腦速度愈來愈慢？硬碟工具助你一臂之力": "新電腦沒買多久，速度卻愈來愈慢，效能愈來愈差?很多人難免會懷疑，是不是買到了瑕疵品?不過，不必疑神疑鬼，也不急著將電腦送修，或許只是電腦缺乏保養，效能降低而已。沒錯!電腦就像汽機車一樣，也必須定期保養，否則，就可能產生類似積碳太多、油管阻塞或潤滑不足等問題。電腦當然不會積碳，但使用一段時間之後，儲存檔案的硬碟空間，也可能變得零碎，導致系統執行效能降低。不過，不必擔心。在Windows系統中，早已經內建了硬碟最佳化機制，定期執行可提升系統運作效率。要執行磁碟最佳化，可以點選左下角的開始程式列表，去到「Windows系統管理工具」中，執行「重組並最佳化磁碟機」程式。出現如上的視窗之後，可以先按中間的⌈分析⌋鍵，讓系統進行磁碟分析，以了解硬碟的檔案分散程度。以我這台電腦為例，C、D、E三個硬碟分割區檔案分散率皆為0，顯示這台電腦硬碟狀況良好，目前不需要進行硬碟最佳化。但有些電腦的檔案分散程度較高，就可以按下右邊的⌈最佳化⌋鍵進行重整。眼尖的網友可能注意到了，這台電腦C碟是比較新型的SSD型硬碟，這種硬碟也需要進行最佳化整理嗎?SSD硬碟的狀況的確不太一樣。傳統的HDD硬碟屬於機械式硬碟，經過長期的使用，硬碟空間可能變得比較分散而零碎，導致同一個檔案可能被分割儲存在不同的位置。因此，當系統要讀取檔案的時候，必須到不同磁區進行存取，一方面拖慢了系統的速度，另一方面，也可能減短了硬碟元件的壽命。因此，為了提升系統效能，每隔一段時間，就會建議執行硬碟最佳化的作業。所謂的硬碟重整或最佳化，就是將同一個檔案內容放在一起，以加快系統讀取的速度。SSD硬碟的情況就完全不同了。SSD沒有機械讀取機制，並不需要特別進行硬碟重整。而且SSD儲存元件也有一定的存取次數限制，進行不必要的重整，反而可能降低硬碟的壽命。對了，了解Windows提供的好用工具之後，讀者可固定一、二週執行一次重整作業。不過，重整最佳化需要不少時間，讀者可利用程式提供的排程功能，讓系統利用空檔自動執行，可節省不少等待的時間喔。",
        "4 個操作步驟，BitLocker eDrive 簡單快速提升固態硬碟儲存安全性 ": "現在有不少人用筆電取代桌機，但攜帶外出使用的資料儲存安全性你在意嗎？可以攜帶外出使用的 3C 裝置，難免會一時大意忘記拿而弄丟了，個人隱私安全性問題多少存在。對於現代人不可或缺的智慧型手機，多數人已懂得利用圖案甚至是指紋辨識，來作為螢幕解鎖的安全性機制，要求高一點還能將記憶卡加密保護。反觀筆電似乎並不怎麼被重視，舉如作業系統帳密機制、指紋辨識裝置等，大多只是限制了使用權。然而當筆電流落到外人手上，只要拆機將磁碟裝置取出來接到其他電腦上，有價值的商業資料、個人私密等檔案內容，通常就會輕易地被看光光。對於廣大的 Windows 作業系統使用族群來說，Microsoft 從 Windows Vista 開始內建 BitLocker 磁碟加密功能（運用 AES 加密演算法），讓使用者能藉此來提升資料儲存安全性。隨著 Windows 版本演進，以往存在的磁碟支援範疇（如系統、資料碟、外接裝置、……）、有無 TPM 模組所衍伸設定繁複等限制，都已經逐步修改至算是簡單易用。BitLocker 典型運作機制屬於軟體加密形式，得透過電腦端的處理器來進行 AES 加解密演算法，固然不挑磁碟裝置（硬碟、固態硬碟、內 / 外接、隨身碟、……）但處理效率變動較大，往往也會影響到筆電的電池續航力。Microsoft 在 Windows 8 推出時新導入了 eDrive 功能，差異在於將 AES 演算工作改交由磁碟裝置來負責，磁碟控制器會在資料存取時自動完成加、解密，因此具有較高的處理效率。eDrive（Encrypted Drive）是植基於 TCG Opal 2.0，以及 IEEE 1667 等國際傳輸加密標準來構成，前者是針對固態硬碟這類快閃記憶體儲存裝置架構特性而生。符合 TCG Opal 2.0 條件要求的固態硬碟，一般稱為 SED（Self-Encrypting Drive，自加密硬碟）機種，運作上屬於全磁碟加密模式（Full Drive Encrypting Drive）形式，但是還得符合 IEEE 1667 標準才能滿足 eDrive 的要求。TCG 等安全管理規範具有相當複雜度，通常是大企業才有能力導入獨立軟體廠商的安全性套件來搭配，這門檻並非中小型公司行號、普羅大眾所能跨越。反觀 BitLocker 所附加 eDrive，它是免費、相對來說簡單容易操作，可協助使用者在安全性、磁碟性能、處理器資源耗用量、筆電電池續航力等條件之間取得平衡點。以下系統要求就不贅述了，最近幾年的主機板、筆電應該都能符合條件，只需要確認 UEFI BIOS 設定值即可。那麼有哪些 eDrive 相容的固態硬碟呢？在消費性機種裡，Crucial 最早響應導入應用，從多年前 M500 到當前最新的 MX500 等主力機種，都符合 eDrive 要求。由於這屬於 SATA 6Gb/s、2.5 吋規格形式機種，若想使用 PCIe 3.0 x4 NVMe 介面產品，像是 Kingston 新推出的 KC2000 系列，定位橫跨商、個人用不失為一個新選項。取 MX500 在 Windows 10（1903）環境為例，由於 Windows 10 推出至今版本眾多，實際操作所遇到、提示內容敘述可能會有些許出入。簡單來說，完成前面「選擇您要解除鎖定這個磁碟機的方式」和「要如何備份您的修復金鑰」這兩個必要設定，如果 eDrive 正常作用只會出現「準備開始加密此磁碟機？」提示、確認訊息，像是在空間狀態下是轉眼之間就完成全碟硬體加密。反之，設置完金鑰卻緊接著詢問「選擇要加密的磁碟大小」與「選擇要使用哪一種加密模式」，代表將以軟體的方式進行加密。如系統提示，乾淨（例如剛完成格式化）磁碟 / 區選用「只加密已使用的磁碟空間」，設定或解除 BitLocker 倒也是飛快，但如果已經有資料就得等上不等時間。至於「加密整個磁碟機」，我們曾以 128GB 容量固態硬碟小試，雖然這麼小卻也得等候十餘分鐘左右，硬、軟體加密的差異再明顯不過。實際寫入約 12.3GB 容量、1057 個零散檔案到 MX500，簡單試驗硬體與軟體加密（只加密已使用的磁碟空間）的處理速度差異，eDrive 硬體加密近乎是在眨眼之間完成，反觀軟體加密模式得等候 62 秒。若先完成加密設定，而後將相同檔案寫入至 MX500，測得速度差異與耗時是小於預期，基於電腦架構特性這點尚屬合理。另外試驗單一大檔案寫入，使用約莫 26.6GB 大小的 ISO 檔案，希望能從中找出 eDrive 有感效益。此組態下傳輸速度出現較為明顯差異，未加密與 eDrive 較軟體加密高出 34MB/s 左右，概略換算速度差異超過 7％。值得留意的是處理器運作狀態，儘管時脈多在 0.88～1.03GHz 之間跳動（軟體加密超過 1.0GHz 的機率略多），但使用率出現了倍數差異。另外以 KC2000 為例，使用常見 ATTO Disk Benchmark、CrystalDiskMark 等基準測試，來觀察當系統開機碟所可能存在差異。概觀來說未加密的各項數據，很合理稍好於 eDrive，而軟體加密最大罩門在於多線程 / 執行緒，落差多則達到 30％ 之譜。最後以 PCMark 8 Storage 測試來搭配驗證之，總評價差異微乎其微，但未加密頻寬可達 708.45MB/s，eDrive 與軟體加密依序遞減 10％ 左右。由於 BitLocker、eDrive 並非 Windows 全新導入功能，我們也不是要驗證各組態對於性能的影響，因此以上僅簡單列出一些試驗結果。總和來說，eDrive 表現是有感優於軟體加密，其資料傳輸速度、當系統開機碟可得體驗，確實和未加密狀態下較為接近。此外是對於處理器的影響，軟體加密使用率明顯高出一截，這對筆電的電池續航力會有不等幅度影響。當然了，BitLocker、eDrive 未必是萬無一失，但起碼可以做到「防君子，不防小人」。畢竟現在用筆電取代桌機的人不在少數，而且不時會攜帶筆電出門使用，哪怕是個人再為不足道的檔案，應該沒有人樂見私密被他人看光光。至於是否該特地挑選 eDrive 相容儲存裝置，這就視個人對於性能的要求了，如果相容那麼在安全性設置上是更有彈性。 自由自在的寫作。[email protected]Comments are closed.半導體到各種終端裝置，測試（Bench）與考驗一直在我們人生（Life）來來回回，網站名稱起源就是如此而來。聯絡我們：[email protected] Copyright © 2020 — BenchLife. All Rights Reserved Designed by WPZOOM",
        "硬碟裝滿資料會變重嗎？答案：傳統硬碟不會，但固態硬碟會喔 ": "\n為提供您更好的網站服務，本網站會使用 Cookies 及其他相關技術優化用戶體驗，繼續瀏覽本網站即表示您同意上述聲明。\n了解隱私權政策\n硬碟是電腦內的必備元件，負責儲存資料，但硬碟裝資料後會變重嗎？電腦內的資料是由 0 和 1 組成的數位訊息，它不是實體的文件、照片，所以乍看之下沒有重量，但實際上卻不是那麼簡單。雖然數位訊息是虛擬的，但硬碟需要用物理方式記錄數位資訊，既然牽涉到實體，那麼硬碟的重量就有機會因此改變。目前市場上最常見的硬碟分為 HDD（Hard Disk Drive，傳統硬碟）和 SSD（Solid-state drive，固態硬碟），我們就用它們紀錄資料的原理，來探討存滿檔案之後，硬碟重量是否會改變。HDD 藉由磁極變化來紀錄檔案。 HDD 裡面有磁性物質，藉由修改磁性物質的磁極方向，來記錄 0 和 1 的數位訊息。磁極修改前後，由於硬碟沒有新增或減少物質，因此 HDD 就算存滿檔案，硬碟重量也不會增加。雖然 HDD 在通電運作的狀況下，重量還是會改變，因為電子是有重量的，但只要切斷電流，重量就不會增加。然而 SSD 又是另外一個故事。SSD 的原理和隨身碟一樣，是使用快閃記憶體儲存資料。快閃記憶體是用電子來記錄 0 和 1 的訊息，電子是有重量的（每顆 9.109 x 10 ^ -31 公斤），因此 SSD 跟隨身碟的重量都會隨著檔案的儲存量而增加。若以 256 GB 的 SSD 硬碟為例，大約會有 2.2 兆（2.2 x 10 ^ 12）個位元；假設一個存滿檔案的 256 GB 硬碟，位元中有一半是「1」，也就是多了 1.1 兆個電子，那麼這顆硬碟的重量就會增加 10^-18 公斤，大約是 6.6 億（6.626 x 10^8）個氫原子的重量，也就是 10^-15 莫耳，是很微小的數字。因此嚴格來說，SSD 存檔之後的重量會改變，但差別實在是太小了，平常根本感覺不出來。先前有英國科學家，也根據電子的重量與網路的資訊量，算出全世界的網路的重量大約是一顆草莓。但這是 2011 年的數字，網路資訊量呈指數成長，或許現在的重量已經跟大象一樣重了。以上是根據訊息傳遞、紀錄的原理，從電子的重量與資訊量來推算資訊的重量，因此以上的數據只是個大概，硬碟實際的重量增減量更複雜。雖然硬碟重量的增減並不會影響它的操作，我們也完全感覺不出來，但我們可以從中了解，很多事情沒有表面上那麼單純，若深入剖析，可以發現許多有趣的秘密。參考資料來源：\n1.《T 客邦》：〈 趣味科普：硬碟裝滿檔案後，重量會變重嗎？〉\n2.《網易科技》：〈 知否|硬盘装满文件后会变重吗？〉\n3.《大紀元》：〈 手機儲存多少資料才會感覺重一點？〉\n（本文提供合作夥伴轉載。首圖來源：Pxhere CC Licensed）傳統硬碟 vs. SSD 固態硬碟，你該怎麼選？\n【DNA 當隨身碟】微軟用 DNA 儲存資料，並成功研發讀取資料的全自動系統 \n螢幕可以觸控，為什麼 iPhone 還要留個 Home 按鍵？全都是因為「人性」 ",
        "善用平行處理與欄式儲存，SQream提供GPU DB加速架構 ": "想要提升資料倉儲與大數據系統的查詢速度，除了導入大規模平行處理系統或記憶體內資料庫，也可以運用SQream DB 這類GPU加速資料庫系統來幫忙若要加速大型資料倉儲系統的存取速度，我們會想到的解決方案，可能有下列幾種：導入大規模平行處理系統（Massively Parallel Processing，MPP）的架構，或是搭配記憶體內資料庫（In-Memory Database），然而，這兩類產品的軟硬體建置成本並不低，前者需配置多臺伺服器一起運作，也將佔用資料中心的空間，後者也有記憶體容量配置的上限，市面上，是否還有其他適合的解決方案可供選擇？今年，我們看到漢領國際引進一套能對應上述需求的產品，稱為SQream DB，它是一種GPU加速資料倉儲系統，在去年9月推出3.0版，資料載入速度是先前版本的2倍，而在資料查詢的部份上， 針對多張資料表的連結（multi-table joins），以及非重複數量統計（count distinct）的作業速度，新版可達到15倍的提升。到了3月，SQream公司改變了這套產品的版號命名規則，定為「年.主要版號.次要版號.修補版號」格式，目前釋出的最新版本是 2019.1.2。SQream是在2010年成立於以色列特拉維夫，該公司花了3年以上的時間，在2014年10月宣布推出主要產品SQream DB，當時的定位是大數據分析SQL資料庫。到了2017年8月，SQream DB發布 1.17版，聚焦在多節點安裝的部份，提供新增功能與改善措施，強調可填補大規模平行處理系統與記憶體內資料庫之間的鴻溝。這套資料庫系統之所以著重在GPU加速，不只是因為它擁有大量運算核心，同時也看重它的記憶體頻寬，可提供極大的資料吞吐能力，同時執行多個複雜的任務。從系統元件的組成來看，SQream DB包含4大部分──SQream DB Daemon（sqreamd）、SQream SQL Editor、SQream Statement Editor、SQream Dashboard，值得注意的是，在安裝指南的文件特別提到，伺服器端必須安裝Nvidia CUDA的驅動程式，由此可知，這套資料庫系統需在搭配Nvidia GPU加速卡的伺服器環境下執行。 採用獨特的資料處理與儲存架構，可縮短載入大量資料的時間而在資料存放的架構上，SQream DB採用的是直欄式（columnar）儲存引擎，能將所要處理的資料進行垂直與水平的分割，便於支援繁重的資料分析處理工作，像是連結、彙整（aggregations）、分類（sorting）。所謂的水平切割，是針對原始資料進行直欄式的切割處理（Columnar Process），讓指定查詢作業能夠存取到特定欄位下的子集合資料，相較於標準的列式儲存（row storage），這種作法可減少磁碟掃描與記憶體I/O存取，而且相當適合GPU這類擅長平行運算的技術。另一種水平分割，是將上述垂直切割後的資料，再進一步分割為資料塊（chunks），如此可提升硬體資源的使用效率，像是相對容量較小的GPU記憶體，使其能夠進行排存（spooling）與快取。資料塊：資料表的超分割（hyper-partitioning）基本上，所有存放在SQream DB的資料表，會自動分割成多個資料塊，而每個資料塊包含了幾百萬個資料點（data point），之後，這些資料塊會經過壓縮，佔用的儲存空間只需幾MB，不需手動介入或維護。換言之，每張資料表的列會分散在多個資料塊當中，而且是橫跨多個欄位來存放，而由於資料塊很小，若要經由PCI匯流排傳輸到GPU當中處理，會比較有效率。同時，這裡所採用的壓縮演算法，會根據不同類型的資料而調整（例如，需依循資料所在地的規則）。一旦資料發生變更，這套自動調適壓縮演算法也會針對特定的資料塊，來決定最佳的壓縮方式。基於這樣的架構，使用者查詢所有資料時，就如同面對一張普通的資料表，同時，又能因應一般資料庫儲存需求快速成長的挑戰。而根據SQream的估算，若從多個外部來源載入資料的作業而言，這套GPU加速資料倉儲系統在資料提取（Data Ingestion）的部分，以每張GPU加速卡為單位時，可達到每小時3.3 TB的存取效能。中繼資料存取：zone map、資料省略在吸取資料（ingest）的當下，SQream DB也會針對存放在資料塊的全部資料列，來收集與儲存中繼資料（metadata），裡面包含了納入資料的數值與屬性範圍。而在中繼資料儲存到系統之際，也會與壓縮的資料塊區隔開來。關於此種metadata的處理方式，一般稱為zone map，已有一些資料庫系統採用。有別於標準的索引機制之處在於，metadata是從資料塊自動收集而來，且透明地橫跨所有資料類型與欄位；同時，也不會佔用太多容量，這邊的中繼資料收集只會佔用1％的儲存空間；此種作法也有助於資料查詢速度的提升，因為經過計算的zone map，可允許資料修剪（data pruning）或資料省略（data skipping）的處理，毋須讀取無關的資料；若要刪除老舊資料，也能受益於這種技術而變得更容易。舉例來說，在SQream DB執行資料查詢時，系統會查看中繼資料的型錄，並且排除那些zone map被辨識為無關查詢的資料塊。也就是說，從磁碟讀取資料時，能夠因為我們在SQL指令當中輸入的Where子句，或是連接一些關鍵欄位（key）時，而不需載入查詢範圍以外的部分。針對所有的資料欄位，SQream DB會自動收集中繼資料，其中，對於數值型的資料處理上，可獲得最佳效益。一般而言，多數資料庫的資料表都有某種時戳或日期的記錄，這類資料通常使用了某種升冪排序的方式，而在SQream DB的系統上，當資料納入SQream DB資料表時，系統會填入資料塊，並在資料塊置入特定日期之際，新的資料塊將會帶入同樣或新的日期而建立。舉例來說，如果我們要查詢橫跨10年的大量歷史資料時，只想分析某日的其中一個小時，在SQream DB的系統當中，就只會掃描該份資料表的1/24；如果想要查看10年期間、每年12月24日的其中一個小時，SQream DB只會掃描資料表的1/8760。換言之，若進一步僅指定相關欄位，SQream DB就能夠讀取範圍更小的資料。針對時間序列型的資料，有了這種層級的刪減技術，系統即使面對指定範圍的查詢，甚至是規模非常大的資料表，仍能夠更快產生出處理的結果，而不需仰賴大型與繁重的索引機制。支援多種擴充系統處理規模的做法此外，若要以縱向擴充（Scale Up）和橫向擴充（Scale Out）等方式，來提升GPU的運算規模，只需在伺服器端換裝或加裝GPU加速卡，比起純CPU的伺服器系統，相對容易擴充運算規模。可運用較多人擅長的SQL語法來進行查詢，並且支援多種資料來源、程式語言、圖像報表平臺另一個SQream DB吸引企業用戶的賣點在於，它本身是一套相容於ANSI SQL標準（ANSI-92）的關聯性資料庫，開發人員可使用普及、熟悉的SQL語法來進行資料查詢，而不像導入其他資料庫或資料倉儲系統，須重新學習語法才能操作。 SQream DB目前支援的資料來源，相當廣泛，可以順利整合公司既有的資料儲存方式。原廠提供了多種驅動程式、連接器，可涵蓋ODBC、JDBC、Python、Node.JS、Java、C++等應用程式開發環境，而能存取Apache Kafka、Apache Spark等大數據系統，同時，也能支援通用檔案格式，像是CSV檔，以及Hadoop環境下的直欄式儲存格式Apache Parquet，以及Infomatica等商業智慧軟體廠商的ETL工具。產品資訊 SQream DB 2019.1.2\n●代理商：漢領國際(02)2709-6983\n●建議售價：廠商未提供\n●硬體需求：2顆8核心Xeon E5-2600 v4系列或POWER9、128GB記憶體（對應每張GPU加速卡）、2張Nvidia Tesla K80/P40/P100、存放作業系統2臺100GB SSD（RAID 1）、加速排存2臺400GB SSD（RAID 1）\n●儲存配置：主要儲存區為10臺600GB SAS介面硬碟或SSD（RAID 5或6），外部SAN/NAS儲存：配合每張GPU加速卡的儲存吞吐量為500 GB/s\n●作業系統需求：64位元Linux（CentOS 7.3、Ubuntu 16.04、Amazon Linux 2017.03）\n●系統安裝方式：Docker（Docker CE 18.03、Nvidia Docker2）、RPM【註：規格與價格由廠商提供，因時有異動，正確資訊請洽廠商】2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "升級Windows 10 1903？PC至少要有32GB硬碟空間 ": "微軟官方資料顯示，要安裝32-bit或64-bit版本的Win 10 1903版，電腦都需具備32GB以上的儲存空間 圖片來源：https://docs.microsoft.com/en-us/windows-hardware/design/minimum/minimum-hardware-requirements-overview#331-storage-device-size 雖然有部分用戶對於即將來到的Windows 10 May 2019 Update (1903)感到如臨大敵，但如果你的電腦想升級到1903版的話，除了處理器要符合最低要求，此外，電腦也需具備最少32GB的儲存容量。根據微軟最近更新的硬體最低需求網頁，不論是安裝32-bit或64-bit版本的Windows 10 1903版，電腦都需具備32GB以上的儲存空間。如果要安裝Windows 10 IoT Enterprise 1903版（或之前版本），32-bit和64-bit版作業系統的儲存容量最小需求分別為16GB和20GB。相較之下，1809或之前版本對PC儲存空間的需求較低，32-bit和64-bit版本分別只需16GB和20GB。1903版何以拉高對裝置儲存需求，或許和它確保安裝成功的措施有關。年初微軟提醒用戶，從這個版本開始，為確保Windows 安裝順利，將會挪用7GB的磁碟空間供更新、Windows應用程式、暫存檔和系統快取所用。否則當用戶磁碟快滿時，部份Windows功能及app跑起來就會變得不穩定。微軟當時還說預設保留的磁碟空間無法從作業系統移除，建議用戶透過移除不必要的功能和語言，來降低保留的磁碟空間。Windows 10的硬碟空間需求增加，對一般筆電來說，這項要求應該不致造成太大困擾，不過部份容量較小的小型筆電可能就會碰上一些麻煩。2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29"
    },
    "Q3": {
        "Hitachi Vantara VSP儲存陣列新入門款式G130 ": "VSP G家族全新入門款式，為SVOS RF儲存平臺沿伸小型環境應用發表於2018年中的VSP G130，近日正式進入臺灣，這款新機型，是Hitachi Vantara針對亞太市場打造的VSP G混合儲存陣列入門款式，搭載了VSP G/F家族標準的SVOS RF作業系統平臺，可提供最大96臺磁碟機與1PB等級原生儲存容量，用戶可選購採用2.5吋與3.5吋磁碟槽的機箱款式，主機端埠亦有16Gb FC或10Gb iSCSI兩種可選。（不過Hitachi只在日本本地板提供完整規格組態，其他地區的版本只有16Gb FC可選）VSP G130源自Hitichi Vantera於2018年5月發表的一系列產品更新，與同時發表的另一款VSP G150，補足了VSP系列在入門級儲存陣列領域的拼圖。5年前（2014年），Hitachi Vantera發表了基於SVOS RF作業系統平臺的VSP G混合儲存陣列，以及VSP F全快閃儲存陣列，逐步取代了以往的VSP、HUS-VM與HUS系列，成為當前Hitachi Vantera旗下的主力儲存產品。但VSP G/F系列一開始設定的應用環境是中階以上，第一波推出的機型中，最低階的VSP G400也是480臺磁碟容量等級，這也導致VSP G系列還不能完全接替HUS100系列，仍需由後者來因應入門級用戶需求。稍晚在2015年中的產品更新中，Hitachi Vantera才推出針對入門級需求的VSP G200與VSP G100，G200可接替HUS130，G100則接替更低階的HUS110。接著相隔3年後發表的VSP G130與VSP G150，則是VSP G家族的入門款式後繼者。G150是G100的後繼者，可提供1.5PB或1.8PB等級最大容量；G130則是針對更低階的入門級環境，最大容量為1.2PB到1.4PB。乍看下，G130與G150的容量範圍相去不遠，不過G130的硬體核心規格都更精簡，記憶體容量只有32GB，主機端埠也只有4個，且只支援16Gb FC與10Gb iSCSI，而G150則擁有加倍的記憶體容量（64GB）與8個主機端埠，也能選購新的32Gb FC埠。因而G130也能提供更低的成本，將VSP G系列的應用擴展到更低階的環境。VSP G130是Hitachi Vantara VSP G混合儲存陣列入門級款式，搭載VSP家族標準的SVOS RF系統平臺，可提供96臺磁碟與1PB等級容量。 產品資訊：●原廠：Hitachi Vantara (02)2719-0077●建議售價：廠商未提供●機箱型式：2U●記憶體：32GB ●最大儲存容量：1200TB（3.5吋機箱型）,1444TB（2.5吋機箱型）●主機端埠：16Gb FC, 10GbE iSCSI（臺灣地區僅提供16Gb FC）●後端埠：12Gb SAS2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "虛擬主機供應商捕夢網驚傳磁碟陣列故障，造成用戶網站服務中斷 ": "提供雲端主機、虛擬主機與代管服務的捕夢網數位科技，在9月3日，傳出部分磁碟陣列設備異常，導致部分用戶服務中斷的情況。擷取自捕夢網官方網站國內的虛擬主機及主機代管服務商捕夢網數位科技，在9月3日傳出部分磁碟陣列設備異常，導致部分用戶服務中斷的情況，至9月4日中午，相關服務尚未復原。在3日下午，我們發現捕夢網在官方網站上發布公告，指出他們的伺服器磁碟陣列出現異常，工程師正儘速查明原因與排除障礙。而這項公告引發了社交網站IT相關社團的熱烈討論，也有一些網站在他們的臉書專頁上，張貼因為這個事故而導致網頁無法存取的公告。到了4日上午，補夢網的系統故障仍未排除。而在捕夢網的網站後續的公告與跑馬燈，也指出他們目前正處於客服電話滿線的狀況，建議用戶利用電子郵寄或線上客服與他們取得聯繫。對於這次嚴重的服務故障情形，我們在4日上午聯繫到捕夢網數位科技技術長趙永弘，他進一步說明了目前的前況。對於這次事件，他表示，並不是全部客戶都受到影響，此次毀損的磁碟陣列，主要影響他們自己管理的主機較多。而原本預計在今天早上就能恢復正常，但目前還在搶修，復原時間未定。對於客戶資料是否都有備份與保存，他提到，他們使用了Ceph分散式儲存系統架構，運用上百臺硬碟做磁碟陣列，目前客戶資料都有保存，現在希望能以資料不遺失的方式做到復原。不過，他也表示，目前已安排一些臨時處置方式，例如，像是他們的雲端主機客戶都提供7天備份，用戶可以透過前一天的備份來還原，作為不同的解決辦法。在此之前，國內也曾發生類似事件，例如，臺灣最大的電子布告欄批踢踢實業坊PTT在2017年10月也曾發生磁碟陣列故障，造成服務中斷超過三日未復原的情形。但此次事件發生的環境是在提供主機代管服務的業者，連帶影響的是多個他們所代管的網站服務。對於用戶關心這次磁碟陣列故障的問題，在捕夢網的官方網站上，除了張貼新聞公告頁面，並以跑馬燈方式，指出他們電話客服若滿載，可以利用電子郵件或線上客服來聯繫。國內的小說出版網站「小說頻道」，在9月3日也於Facebook粉絲專頁發出公告，受到捕夢網磁碟陣列故障影響，網站無法正常運作，我們在4日早上也仍然無法連上網站。關於這次磁碟陣列設備異常引發的災情，在9月4日中午之後，後續捕夢網公布了虛擬主機網頁的臨時方案，讓受影響的用戶能夠暫時網站上線，提供一種緩解的作法。他們指出將提供9月2日備份檔案，並將網站資料放置在暫時主機（不過僅限Linux主機），之後在請用戶將DNS指向至暫時主機。不過這個暫時讓網站上線的方式，不提供更新服務，等到正式主機修復完畢，在請用戶將DNS指回正式主機。在9月5日下午，已經看到網站上公布虛擬主機網站陸續恢復中的公告。（直到9月7日下午已完全修復）2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "【2019高階儲存系統：六強篇】IBM DS8800：兼顧大型主機與開放系統應用 ": "IBM目前的高階儲存陣列產品DS8000系列，已發展了6個世代，最新機型是2015年10月發表的DS8880。IBM雖然還沒有推出DS8880系列後繼機型，但在1年多前，為既有機型新增了搭配大型主機環境的zHyperLink傳輸技術，而zHyperLink介面的低延遲表現，已經超越當前大多數NVMe-oF介面高階儲存的鼻祖是IBM，在1990年代以前幾乎壟斷了這個領域，後來雖然面臨EMC、HDS等後進者的挑戰，但仍持續在這個領域占有重要地位。IBM目前的高階儲存陣列產品，依然是2004年12月問世的DS8000系列，目前已發展了6個世代，最新機型是2015年10月發表的DS8880。從第一代DS8000起，這系列產品便以採用基於IBM Power處理器的核心架構，在當前普遍採用Intel x86處理器作為核心的儲存主流架構中，獨樹一格。第一代DS8000採用的是Power 5，上一代DS8870則採用Power 7+，最新的DS8880則升級為Power 8。比起其他廠商的高階機型，DS8000系列的系統規模相對較小，發展到最新一代的 DS8880，仍然只支援雙控制器組態，最大容量為1,536臺磁碟（混合組態）或768臺Flash儲存裝置（全快閃組態），不過在搭配大型主機應用上有獨特的優勢，而IBM在DS8800發表迄今的近3年時間內，也提供了數次重要更新。    搭配大型主機的zHyperLink傳輸介面IBM雖然還沒有推出DS8880系列後繼機型，但在1年多前，為既有機型新增了搭配大型主機環境的zHyperLink傳輸技術。左為zHyperLink架構圖解，是一種直連z System主機與DS8800儲存陣列的低延遲傳輸介面：右為DS8800 I/O Bay機箱的zHyperLink埠配置。圖片來源／IBM首先，是在2016年5月，推出了該系列的第一個全快閃化版本DS8888。緊接著，又在2017年1月，又發表新一代的全快閃機型DS8800F系列，並新增支援搭配大型主機的zHyperLink傳輸架構。DS8800F取代了原本的全快閃機型DS8888，不僅有更多款式可供選擇（4款機型對2款機型），後端還採用了IBM新的第2代高效能Flash機箱（High-Performance Flash Enclosure，HPFE），可提供更高的傳輸效能與擴充能力。DS8888採用的第1代HPFE機箱，為1U規格，使用1.8吋規格的Flash卡模組，每臺機箱可安裝16或30組Flash卡，然後透過4GB/s PCIe 2.0×8介面直連I/O Bay機箱，再介接CPC控制器機箱。第2代HPFE機箱則改用2U規格，Flash卡模組也改用更普遍的2.5吋SSD形式，每臺機箱可安裝最多24組Flash卡模組，部署時以2組HPFE機箱成對配置，並透過8GB/s的 PCIe 3.0×8介面，直連I/O Bay機箱。雖然第2代HPFE機箱容納的Flash卡數量較少，但藉由容量密度更高的2.5吋Flash模組，每臺HPFE機箱的容量從第1代的12TB提高到76TB，後端傳輸介面的頻寬也高出一倍。在推出DS8880F的同時，IBM也為DS8880系列，升級了支援zHyperLink傳輸技術的能力。zHyperLink是搭配IBM Z System大型主機的點對點低延遲傳輸技術，採用專屬I/O介面卡與專屬OM4光纖纜線，可以讓Z System大型主機的CEC中央處理器組，透過zHyperLink埠直連DS8880儲存系統的I/O Bay機箱。比起大型主機常用的FICON傳輸介面，zHyperLink介面可提供改善10倍的低延遲效能，FICON介面的典型延遲表現是140～170μs，而zHyperLink則可將延遲縮減到20～30μs，傳輸頻寬為8GB/s，可以用來加速DB2 for Z/OS的交易處理，以及活動日誌的吞吐率。每套DS8880系統最多可配置16組zHyperLink埠，限制是傳輸距離不能超過150公尺，另外也只有較高規格的DS8880機型才能啟用這種介面，要求擁有12核以上的處理器規格，所以，最低階、只有6核心處理器的DS8882F，並無法啟用zHyperLink。憑藉zHyperLink介面的低延遲存取能力，IBM迄今仍無意在DS8880系列引進NVMe-oF介面，事實上，zHyperLink介面的低延遲表現，已經超越當前大多數NVMe-oF。而依照IBM過去的DS8000系列更新週期，我們可以預期，最快在今年年底或明年年初，新一代的DS8000系列很可能就會問世。 相關報導  2019高階儲存系統總覽2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "【2019高階儲存系統：新創篇】此消彼長的新興高階儲存系統 ": "在主流高階儲存大廠之外，還有數個新興參與者也積極拓展高階儲存應用，但面對激烈競爭，個別廠商的發展情況有很大落差除了6大主流的高階儲存設備供應商外，還有幾款新創儲存產品，基於獨特架構與性能特性，在特定面向的高階儲存應用領域占有一席之地，也可列入高階儲存產品。在2015年的《高階儲存設備大反擊》封面故事中，我們曾列出5款新創高階儲存產品，包括IBM XIV、NetApp FAS 6000/8000、DDN SFA12KX、Oracle Pillar Axiom與Infinidat InfiniBox，另外Oracle的FS1也能列入這個範圍。而經過4年的時間推移後，如今只剩下NetApp、DDN與Infinidat這3家，仍繼續在市場上活躍中，也顯示高階儲存領域競爭的激烈。消失的IBM XIV2007年時，IBM併購EMC Symmetrix創始者Moshe Yanai創辦的公司XIV，成為IBM旗下XIV Storage System產品線，以獨特的網格式Scale-Out架構與分散式RAID技術著稱，但是在2011年9月推出XIV Gen3以後，就未再提供重要硬體更新，但仍持續修補更新軟體。而且，IBM已於2018年8月宣布停止供應硬體，並訂於2020年終止支援11.5.2版本以前的軟體，我們可把這系列產品視為已經終止發展。但XIV核心技術並未消失，其網格式控制器架構與系統軟體，被沿用到2016年4月發表的FlashSystem A9000/A9000R快閃儲存陣列，持續在IBM儲存產品中發揮作用。全面退出市場的Oracle儲存系統Oracle旗下的Pillar Axiom與FS1兩款高接儲存產品，系統規模相對比較小，但各自具有獨特的架構與功能。Pillar Axiom來自新創廠商Pillar Data System，2011年6月併入Oracle成為Flash Storage部門，擁有獨特的系統控制器與磁碟控制器分離的Scale-Out架構、專屬的分散式RAID技術，以及精細的QoS效能管理與分層儲存功能，還支援Oracle資料庫混合列壓縮（HCC）獨門功能。然而，自從2008年7月發表的Pillar Axiom 600之後，這系列產品就沒有重要硬體更新，軟體部份在2013年初更新到5.4版後也沒有重要更新，已沉寂多年。至於FS1，則是Oracle Flash Storage部門於2014年9月發表的快閃儲存系統，分為全快閃版與混合陣列版本，採用常見的雙控制器架構，軟體核心移植了源自Pillar Axiom的精細QoS效能管理功能，以及支援Oracle資料庫HCC功能，可視為Pillar Axiom後繼衍生產品。不過，FS1硬體規格遲遲沒有獲得重要升級，系統軟體在2015年底的6.2版之後，就只剩下小修補，發展陷入停滯。在Pillar Axiom與FS1兩個產品線都已停滯數年後，今年8月中旬，包括The Register、Channelnomics、Blocks and Files等外電紛紛傳出消息，指出Oracle再度大規模裁員，整個Flash Storage部門實際上已遭到裁撤，此後Oracle將專注於公有雲業務，而將停止本地端儲存軟硬體發展。Oracle官方目前則只表示，他們正在平衡資源、調整團隊結構。非典型架構的NetApp高階儲存NetApp雖然歷史悠久（1992年成立），但到2012年推出Cluster模式後，其產品才算真正具備承擔高階儲存應用能力，在高階儲存算是新興參與者。目前NetApp的FAS系列高階機型，已更新為2016年9月發表的FAS 8200與FAS 9000，另外，全快閃AFF系列的高階機型也同步更新，包括2016年9月推出A700、2017年2月推出A700s，然後，在2018年5月發表當前旗艦機型AFF A800，又於2018年底，為AFF A800引進NVMe SSD與NVMe/FC傳輸架構。FAS與AFF系列都可透Cluster模式支援大型環境應用，但如同我們在4年前提過的，NetApp的Cluster架構，是利用虛擬層提供的跨系統統一命名空間，將多個雙節點系統的磁碟區「接合」在一起，本質上是多個雙節點系統的鬆散集合，有別於其他高階儲存產品的叢集架構、任何控制器都可存取任何儲存裝置的分散式架構，雖然廣義上也算是高階儲存，但不屬於傳統的高階儲存之列。更新迅速的DDN SFA家族成立於1998年的DataDirect Networks（DDN），是高效能運算領域的重要儲存設備供應商，基本產品是SFA系列儲存陣列，可搭配DDN的叢集式儲存應用伺服器，組成平行檔案服務儲存系統，專供能源、醫療研究、科學運算等領域使用，而憑藉這個有別於一般企業IT應用的市場，加上近年來大數據分析、AI應用，顯著帶動了高效能運算市場，也讓DDN持續保有活力。我們4年前報導時，DDN旗艦產品是2013年底推出的SFA12KX。而在這段時間內，先後推出SFA14KX與SFA18K兩個世代旗艦機型，產品更新相當迅速。DDN先於2016年9月發表SFA14KX系列，接著於兩年的2018年11月，在SC18大會發表目前的旗艦產品SFA18K系列，系統組態與SFA14KX相近，都是雙控制器與最大1,872臺磁碟，最大容量略為提升到25.2PB，最大變革是引進了NVMe介面SSD，以及新版的作業系統。SFA18K控制器機箱可安裝最多72臺NVMe SSD，外加擴充櫃1,800臺SAS SSD或硬碟。控制器核心換成Intel Purley處理器。後端介面仍是12Gb SAS，主機端則不再支援FC，只保留InfiniBand EDR、40/100GbE與Intel Omni-Path。在作業系統方面，SFA18K是以SFA OS 11.x版，取代原有SFA OS 3.x版，引進Declustered RAID分散式RAID架構，可支援更大型的LUN、改善LUN的效能，並大幅縮減RAID重建時間。SFA14KX系列也能升級這個OS版本。穩步發展的Infinidat InfiniboxInfinidat是以色列新創儲存廠商，旗下產品InfiniBox，是高階儲存傳奇人物Moshe Yanai，繼Symmetrix與XIV之後，領導開發的第三款高階儲存產品。比起其他同級產品，InfiniBox特點是堅持混合式架構，以及極高的可用性。Infinidat宣稱透過大容量的DRAM與Flash快取記憶體配置，再結合專屬的neural caching神經快取演算法，也就是一種基於AI技術預測快取的技術，可以將讀取快取命中率提高到98%以上，因而Infinibox無須全快閃組態，就能提供比擬全快閃陣列的效能，更能兼顧效能與成本；在可用性方面，多數產品都是6個9（99.9999%），而InfiniBox透過三控制器可提供N+2系統備援架構，擁有7個9的超高可用性（99.99999%）。InfiniBox在2014年問世之初，只有高階機型F6000，2015～2016年將產品線擴展中階範圍。接著在2018年3月推出新高階機型F6212。不久前的2019年5月，Infinidat又發表了最新產品，訂於第2季推出新一代InfiniBox家族Fx300，系統軟體也將於第3季更新到R5版。其中高階款式F6300，算是InfiniBox家族的第3代高階產品，可用實體容量與上一代F6200同樣是4PB，DRAM維持最大3TB的配置，但Flash快取記憶體則從最大207TB提高到307TB，搭配新的處理器，吞吐率從15GB/s提高到25GB/s，IOPS效能則從130萬提高到200萬。新一代InfiniBox家族，還引進新的I/O介面，上一代只提供8Gb FC與10GbE，新機型則預設配置16Gb FC與10GbE，並能選購32Gb FC與25GbE等新規格，還備妥低延遲的NVMe-oF傳輸架構。 相關報導  2019高階儲存系統總覽2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "【2019高階儲存系統：六強篇】HPE Primera融合3PAR與Nimble兩家之長，提供100%可用性 ": "HPE在Discover 2019大會中，推出全新高階儲存產品線Primera 600系列，有別於多數企業級中、高階儲存設備的可用性是每年停機31.6秒，少數產品還能達到每年停機時間僅3.16秒，而HPE則在Primera上提出了空前100%的可用性，換言之就是完全不停機就HPE與其前身HP而言，原本沒有自身的高階儲存產品線，長期都是OEM HDS的高階儲存產品，來填補自身在這領域的不足。直到HP於2010年併購3PAR之後，才終於取得獨立的高階儲存產品。當3PAR於2010年9月併入HP後，HP在2011年8月在3PAR產品線下推出一個新的高階系列P10000，內含V400與V800兩個系列。而後在2012年底的HP儲存產品線大調整中，3PAR P10000系列更名為3PAR StoreServ 10000系列，時隔2年半後，HP在2015年6月發表新的3PAR StoreServ 20000系列。接下來相隔了4年，HPE在Discover 2019大會中，並未發表新一代的3PAR StoreServ機型，反而推出一個全新的高階儲存產品線Primera 600系列。兼用SAS與NVMe雙重介面Primera兼容了舊的SAS與新的NVMe兩種介面，以Primera 630與650兩款機型的控制器來說，機箱有16個磁碟槽可以混用SAS或NVMe的SSD，另32個磁碟槽則使用SAS介面。圖片來源／HPEPrimera 600系列目前包含630、650與670等3個不同位階的款式，各自又有兩種版本，分別是全快閃儲存組態的A600，以及採用融合式Flash（converged flash）的C600混合陣列。從規格來看，Primera系列的位階，介於3PAR StoreServ家族中階的8000系列，以及高階20000系列之間，橫跨了中階到高階的範圍，其最高階機型Primera 670可提供4控制器組態、960臺磁碟或576臺SSD，與3PAR StoreServ 20000系列的入門機型20840相當。而最低階的Primera 630，則與3PAR StoreServ 8000系列入門款8400相近。從系統特性來看，Primera則融合了3PAR與Nimble的特性。首先，Primera採用了類似3PAR的通用處理器+ASIC晶片的核心架構，透過ASIC晶片來處理XOR與資料壓縮等運算，以及節點間通信、資料搬移等功能，讓系統不會因這些作業而影響效能。其ASIC則是3PAR ASIC的後繼者，3PAR StoreServ目前搭載的是第5代ASIC，而Primera則是第6代ASIC。其次，Primera也支援了源自Nimble的InfoSight雲端AI管理平臺，可利用這個平臺的AI管理機制，提供主動式監控、分析，與故障、升級預測服務。Primera的I/O介面則引進了新一代規格，後端介面同時混用了舊的SAS與新的NVMe，控制器機箱的磁碟槽可支援SAS與NVMe雙重介面，搭配SAS介面的外接擴充櫃。除了SAS或NVMe SSD以外，Primera接下來也會支援儲存級記憶體（SCM），來作為快取記憶體使用。在主機端介面方面，除了既有的16Gb FC與10GbE規格，也採用25GbE與32Gb FC等兩種新規格，但目前在NVMe-oF傳輸架構方面尚無消息。Primera的Primera OS作業系統軟體也有重要的變革，透過Container技術，將功能與服務機制「微服務化」，使得更新升級更為簡便。相比於Dell EMC的PowerMax，HPE在Primera上的更新相對比較折衷，既引進了新規格（如32Gb FC、NVMe），但也保留了舊介面（如SAS）。空前的100%可用性保證比起規格更新，Primera更引人注目之處，是空前的100%可用性保證。多數企業級中、高階儲存設備的可用性是「6個9」等級，即99.9999%，相當於每年停機31.6秒，少數產品還能達到「7個9」，也就是99.99999%，每年停機時間僅3.16秒，而HPE則在Primera上提出了空前100%的可用性，換言之就是完全不停機。這項保證是以用戶購買HPE Proactive Care等服務合約，並同意啟用InfoSight為前提，還要求當InfoSight的主動式監控與故障預測功能提示升級或更新之際，用戶需在設定時間內完成相對應的更新作業。雖然Primera的核心架構類似3PAR StoreServ，但HPE表示，兩者之間並無替代關係，未來將會持續並存，不過，從StoreServ系列遲遲沒有推出新機型的現實情況，我們認為，長期來看，Primera最終很有可能會取代StoreServ系列，日後HPE或許會推出更高階8控制器版本的Primera，以便涵蓋StoreServ 20000系列的範圍。 相關報導  2019高階儲存系統總覽2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "【2019高階儲存系統：六強篇】富士通DX8900 S4：SPC": "2019年3月，富士通以24組控制器、18TB快取記憶體與576臺SSD的DX8900 S4滿載組態，締造了SPC-1儲存效能基準測試史上，第1個突破1,000萬IOPS紀錄。這個數字目前仍是SPC-1的最高效能紀錄，顯示DX8900 S4即使依靠較保守的架構，也足以提升當前高階儲存領域最高水準的效能表現圖片來源：https://blog.de.fujitsu.com/produkte-services-loesungen/storage/rechenze...以大型主機與超級電腦著稱的富士通（Fujitsu），2006年發表Eternus DX8000系列進入高階儲存市場，2011年11月推出第二世代產品DX8700 S2，接著在2015年7月發改款為DX8700 S3，同時衍生出更高規格的DX8900 S3，是當時高階儲存領域最高規格的產品之一，特別是後者最大可達到24組控制器的擴充能力，迄今仍無出其右，另外最大4,608臺磁碟的容量，以及384個主機端埠的擴充能力，在同時期產品中，也僅次於華為的OceanStor 18000 V3，而超過其餘廠商的產品。實證1千萬IOPS效能的富士通旗艦不久前的2019年3月，DX8900 S4在SPC-1效能實測中，締造了第1個突破1,000萬IOPS的效能紀錄，也是SPC-1目前的效能紀錄保持者。圖片來源／富士通硬體規格全面升級不久前的2018年10月，富士通推出了Eternus DX8000系列的第4代機型DX8000 S4，包含DX8100 S4與DX8900 S4兩款機型，前者是DX8000 S4的入門款，僅在日本提供，後者則是旗艦款式，可在全球供應。與上一代旗艦機型DX8900 S3相比，DX8900 S4的最大控制器數量仍是24組，但升級了控制器核心硬體規格，引進了新的12核Intel Xeon處理器、DDR4記憶體，以及用於即時壓縮的專用晶片，快取記憶體最大容量則從6TB大幅增加到18TB。憑藉升級的核心硬體規格，富士通宣稱DX8900 S4的效能比上一代機型提高了1.3倍，可達到1,000萬IOPS等級。DX8900 S4的最大系統容量，也從DX8900 S3的4,608臺磁碟，提高到6,912臺，還能支援新款的30.2TB超大容量SSD，擴展能力是當前高階儲存領域的最高水準，只略低於華為的OceanStor 18000系列。在I/O介面方面，DX8900 S4前端介面引進了新一代的32Gb FC，後端儲存介面仍然是12Gb SAS，儲存媒體則是傳統的SAS硬碟與SAS SSD，尚未支援作為儲存媒體使用的NVMe SSD，但提供以快取記憶體型式應用的NVMe SSD，可透過稱作Extreme Cache的功能，以NVMe SSD構成的第2層快取記憶體。每組DX8900 S4控制器可安裝最多8臺雙埠NVMe SSD，搭配Extreme Cache功能，作為輔助DRAM的快取記憶體使用。比起Dell EMC PowerMax與HPE Primera等兩款新一代高階儲存設備，富士通DX8900 S4在新技術與新I/O介面規格的引進上，相對比較保守，如NVMe-oF傳輸架構或儲存級記憶體（SCM）等，均尚無著墨，不過擴展能力更勝前兩者一籌，可擴展的控制器數量、磁碟機數量與最大容量等規格，都較前兩者更高。特別值得一提的是，不久前的2019年3月，富士通以24組控制器、18TB快取記憶體與576臺SSD的DX8900 S4滿載組態，締造了SPC-1儲存效能基準測試史上，第1個突破1,000萬IOPS紀錄。這個數字目前仍是SPC-1的最高效能紀錄，顯示DX8900 S4即使依靠較保守的架構，也足以提升當前高階儲存領域最高水準的效能表現。透過專用晶片支援資料壓縮DX8900 S4的每組控制器除了通用處理的Xeon處理器外，另含有1顆用於即時壓縮功能的專用晶片，可幫助減輕處理器負擔，提高整體效能。圖片來源／富士通 相關報導  2019高階儲存系統總覽2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "活用資料洗滌機制　確保系統運行無礙 ": "熱門搜尋 : 熱門搜尋 : 整合Data Scrubbing技術　防制無聲資料毀損 資料洗滌（Data Scrubbing）為檢查資料量及修正資料不一致的過程。隨著時間推移，有些資料可能會因為硬體因素或其他原因，因而傷害資料完整性（Data Integrity），更甚者，會在沒有示警的狀況下默默產生資料毀損。舉例來說，圖1中的兩張圖片，就是原檔和出現位元衰減毀損檔的比較，僅僅幾個位元的改動，也可能發生嚴重的資料損毀。接著所要分享的，即是以Synology的機制為例，說明如何利用Data Scrubbing防止資料毀損。在Synology Data Scrubbing機制中，包含以下兩件事情：RAID Scrubbing和Btrfs Scrubbing。在介紹什麼是RAID Scrubbing之前，先說明何謂RAID。RAID的全名是「獨立磁碟冗餘陣列」（Redundant Array of Independent Disks），簡單來說，就是結合多塊獨立的硬碟，組合成一個硬碟組，用於容錯和進行資料冗餘。RAID有多種形態，RAID Scrubbing則在RAID 5/RAID 6系列的RAID上支援，以下簡短介紹RAID 5。了解RAID 5運作RAID 5的基本機制仰賴至少三個硬碟，並利用資料區塊的奇偶校驗（Parity Striping）進行寫入與讀取。如圖2所示，當寫入一塊序列型資料到陣列時，RAID 5會依序寫入A1、A2、A3、B1、B2和B3。同理，RAID也會依序讀取數據。那Pa、Pb和Pc又是做什麼的呢？它們是分布在硬碟的奇偶校驗塊。當寫入A1、A2和A3時，RAID 5會使用下列的XOR位元運算子計算Pa，並寫入對應的區塊：Pa = A1 (XOR) A2 (XOR) A3 (函數1)假設其中一個硬碟毀損，RAID 5可以藉由使用Pa和其他兩個硬碟的內容，修復消失的資料。假設包含A2資料的硬碟毀損，那麼可透過下列的XOR計算加以重建資料：A2 = A1 (XOR) A3 (XOR) Pa (函數2)這就是RAID 5透過冗餘功能，所提供最多一顆硬碟損毀而資料不受影響的保護。認識RAID Scrubbing在初步了解RAID 5的特性後，接著介紹什麼是RAID Scrubbing。RAID Scrubbing可掃描陣列中的所有內容，以確保所有Parity Stripe滿足函數1；若不滿足的話，則會利用函數2予以修復，直到所有的值都達成一致。「但如果我定時進行RAID Data Scrubbing，我的資料就可以永保完整嗎？」遺憾的是，答案是否定的。因為，無法確保寫入硬碟的資料永遠正確。有些資料毀損會在不知不覺中發生，稱之為無聲資料毀損，亦即某些資料有可能會存在於硬碟上，卻莫名地產生位元組資料改變。這種狀況可能肇因於諸多原因，包括硬碟錯誤和電磁干擾等等。RAID Scrubbing雖能確保存入的資料一致性，但卻無法防禦無聲資料損毀。假設今天要透過A1、A2和A3（如果圖2的函數1所示）重建Pa，但是如果A1、A2和A3其中一筆毀損，那麼運作函數就會出錯，只會讀取到錯誤的內容，導致整個過程每況愈下。善用Btrfs Data Scrubbing首先，Btrfs檔案系統可以將兩份中繼資料儲存於一個儲存空間，並計算其相關的檢查碼，而Btrfs Data Scrubbing正是利用這個特性來做到自動的資料修復。Btrfs Data Scrubbing利用檢查碼機制（Checksum Mechanism）檢查儲存在Btrfs檔案系統的資料量。如果監測到任何資料和檢查碼不一致，系統便會試圖使用冗餘備份修復資料。此項功能僅需要使用者在建立新的共用資料夾時開啟資料檢查碼功能，如圖3所示，Btrfs檔案系統就會為每個寫入的檔案計算資料檢查碼，並用另一組總和檢查碼（Metadata Checksum）保護資料檢查碼。遏止資料毀損的風險若使用者無法決定要使用哪一套Data Scrubbing系統也不用太擔心，Synology的Data Scrubbing系統整合Btrfs Data Scrubbing和RAID Scrubbing以確保資料完整性。在Btrfs環境執行Data Scrubbing時，會先執行Btrfs Data Scrubbing，在保障資料正確性後，接著執行RAID Data Scrubbing，進一步確保資料一致性。這兩項系統的攜手合作，可以降低無聲資料毀損的風險，並確保儲存系統運作無礙。＜本文作者：蔡孟儒，群暉科技產品經理，2014年加入Synology，負責Synology企業儲存技術、檔案協定、Docker技術以及虛擬化產品與解決方案之開發管理。＞\r\n 呼叫專業服務機器人！豹小秘神救援零接觸測溫老字號 IT 網管監控神器　大秀自動流程與智慧分析用多雲策略建構災備善用5G三大獨特性　生態系結盟創新模式應用阿里雲推馳雲計劃　為全球中小企提供援助並加快雲端科技應用電子簽名導入區塊鏈　實現最高的資料安全性防疫也防駭！企業遠端工作 4 大重點助持續營運數位鑑識須在不疑處有疑　僅靠靜態分析易陷盲點軟協新任理事長沈柏延上任　力助產業數位轉型兆勤科技聯手 McAfee　打造全面零死角資安解決方案搞懂ICMP協定及工具 抵擋「死亡之Ping」攻擊網路設備入門新手必讀 Cisco IOS最基礎教學建立VLAN邏輯分割網段  詳解交換器Trunk設定人臉辨識拓展金融市場　技術高下實測見分曉NAT穿透技術 從外部直接溝通私有IP路由協定基礎知識入門 詳解路由特性與分類從STP到RSTP　認識多重生成樹協定無類別區隔路由CIDR技術 依需求善用有限IP位址深入了解IP位址與子網路遮罩開源OpenKM文管系統 立即打造知識管理平台第171期2020年4月任意雲端、單一體驗，釋放資料價值之新IT儲存架構解析Dell Technologies儲存創新　引領轉型旅程高階儲存較勁　NVMe全面來襲追蹤我們Featrue us本站使用cookie及相關技術分析來改善使用者體驗。瞭解更多",
        "Synology發表包括DSM 7.0與新款企業級硬體的全新資料管理方案 ": "群暉科技 Synology宣布推出多款新硬體以及更新軟體，以賦能使用者、智慧洞察及串聯雲端三大主軸，推出資料管理新產品與解決方案。以網路儲存裝置(NAS)為產品主力的群暉科技(Synology)，宣布推出多款軟、硬體產品，包括個人適用的入門級4 Bay NAS、企業級高密度 NAS、全快閃儲存機種，而軟體方面最受人矚目當屬 DSM 7.0、應用程式更新以及新的應用，即環繞在賦能使用者、智慧洞察及串聯雲端三大主軸發展新的資料管理產品與解決方案。群暉NAS系統軟體DSM向來擁有簡單方便且直覺的特性，讓管理者／使用者都能輕鬆完成 NAS各項設定與管理工作。這次DSM正式進入 7.0版，從外觀到內部功能都有不少改變。進入 DSM 7.0後，可以立即發現預設的背景圖片、選單，連應用程式的圖示都改變許多，這也是最容易看到的變化。使用滑鼠點擊應用程式時，也能發現執行／反應速度明顯加快不少。除此之外，多個功能設計或選單也重新設計與安排，例如磁碟管理，過去可能比較熟悉的管理者才能快速的在儲存區、磁碟陣列、硬碟等選單中找到相關的裝置。現在新版本改成階層式項目呈現，很容易就找到裝置做管理。因應快速成長的 SSD快取應用，Synology大幅更新 DSM針對 SSD快取的支援，全新的 SSD快取建議將以更精準的方式分析 I/O模式，根據實際使用狀況提供用戶最符合成本效益的 SSD容量。支援將中繼資料鎖定至 SSD來大幅提升牽涉到冷中繼資料的系統操作執行效率。 Synology Active Insight讓用戶透過雲端集中即時監測所有管理中的NAS資源與效能狀態在管理 NAS時，許多人應該都有遇到陣列因為硬碟故障而降階，但對使用者來說卻是可以正常使用而不知系統已經有問題，管理者也可能一時沒有看到通知訊息而無法立即處理，等到系統無法使用才發現故障就為時已晚。群暉這次特別推出Active Insight，讓用戶透過雲端集中即時監測所有管理中的 Synology NAS資源與效能狀態，並透過視覺化的監測儀表呈現資訊。當伺服器發生異常狀態時主動預警用戶並提供詳細的操作建議，在潛在風險造成實際損失前便能有效控制狀況。使用者可以自行決定這項功能是否開啟，而開啟後主要利用Synology Account帳戶來識別，而傳送到雲端的資料也僅以系統運作狀態為主，並不會將系統中的內容上傳。幾年前Synology推出自建的公有雲服務 C2，目前全球已有超過兩萬戶使用做為雲端備份，現在Synology將進一步將它拓展至生產環境中，推出原生的混合雲儲存與檔案共享服務「Hybrid Share」，使用者可利用本地端的 NAS掛載Hybrid Share 快速擴充儲存空間，並可設定本地部分空間做為快取，提升性能。而且 DSM設定檔亦可利用此功能將系統組態自動備份至雲端，當災難發生時可以快速地還原系統設定，大幅減少服務中斷時間。 Synology Hybrid Share結合C2打造方便快速的混合雲儲存方案不同據點的 Synology NAS亦可共同掛載 Hybrid Share達成檔案同步與共享，並根據各據點需求設定快取大小，大幅降低跨據點檔案共享與交換所需要的對外頻寬需求。 Synology Photos將Photo Station與 Moments功能合而為一過去群暉提供了Photo Station與 Moments二種照片管理及分享功能，此二種應用各有其優缺點，現在群暉將他們合而為一，不論是專業或是一般使用者都能擁有原本的便利功能。新的Synology Photos讓使用者運用單一套件即可運用所有相片管理的功能，無論是從上傳、智慧分類、管理、搜尋或分享相片，甚至多人協作，精細的管理功能可滿足攝影愛好者到專業攝影師的需求。 DS420j是一款入門級機種 DS420j有一組乙太網路連接埠 DS420j硬碟用螺絲固定在機構上在硬體新產品方面，主要以企業級應用為主，並有一款DS420j適合個人使用的入門級產品。DS420j採用ARM架構的處理器，具有四個硬碟安裝空間，硬碟是直接使用螺絲直接鎖在機體內，網路連接埠也僅有一組。預計群暉在近期內還會再發表包括 Plus系列在內的新產品上市。 FS3600為一款中階全快閃儲存伺服器FS3600為一款超過 161K IOPS 的中階全快閃儲存伺服器，採用 Intel Xeon D-1527 12核心處理器，內建 16GB DDR4 ECC記憶體，並可擴充至 128GB，搭配 RX1217sas/RX2417sas，最多可擴充至 48/72 顆硬碟。 SA3200D搭載DSM作業系統的主被動儲存伺服器 SA3200D具有二個節點 SA3200D採用SATA DOM在儲存作業系統SA3200D是群暉首款搭載 DSM作業系統，支援完整套件的主被動儲存伺服器，可以把它想像成二台NAS組成的高可用性系統，其主被動控制器架構，可全方位保護企業關鍵資料與服務。SA3200D每個節點採用 Intel Xeon D-1521四核心處理器，內建 8GB DDR4 ECC記憶體，並可擴充至 64GB。每個節點也都採用在 SATA DOM單獨儲存 DSM作業系統，讓作業與資料能完全獨立分開。 HD6400為一款4U的高密度儲存伺服器 後方有二個硬碟安裝空間用來儲存作業系統 HD6400有高達60個硬碟安裝空間HD6400是是群暉首款 4U可安裝高達 60顆硬碟的高儲存密度伺服器，若全部使用16TB的硬碟，單一系統就能擁有接近 1PB的容量。系統採用 Intel Xeon Silver 4110 八核心處理器，支援 32GB DDR4 ECC記憶體，並可擴充至 512GB。除了60顆硬碟做為資料儲存之用，機體後方還有二個硬碟空間，可用RAID 1組態來安裝作業系統。在科技媒體多年，為Xfastest News網站科技產品發表會或是記者會採訪記者，也是Xfastest採訪文撰寫編輯。  Remember Me Lost your password?",
        "【雲端儲存服務：Cloud Volumes ONTAP】NetApp老牌ONTAP儲存平臺原生移植公有雲環境 ": "利用公有雲運算與儲存資源運行ONTAP平臺，讓NetApp儲存陣列化身雲端虛擬化儲存裝置如何因應公有雲來勢洶洶的挑戰，是當前所有傳統儲存設備廠商的一大課題，其中一種應對的思路是「打不過他，那就加入他」，既然難以抵擋公有雲勢力的逐漸擴張，那就反過來利用公有雲，將將儲存設備移植到公有雲平臺上，化身為公有雲服務的一部份，從而沿續儲存設備平臺的發展。NetApp的Cloud Volumes ONTAP（CVO）服務，便是這種移植到公有雲的儲存陣列平臺代表性產品。CVO本身是運行於AWS或Azure平臺上的虛擬化版本ONTAP儲存設備，利用公有雲的虛擬機器扮演儲存控制器角色，運行NetApp的ONTAP儲存作業系統，並掛載公有雲的儲存空間，作為控制器後端儲存空間，然後再透過NFS、SMB或iSCSI協定，將儲存空間掛載給公有雲上的其他虛擬機器使用。透過CVO，既能向用戶提供與公有雲原生儲存服務相同多種效益，如按需訂購、管理負擔輕等，也擁有ONTAP儲存平臺的特性與豐富資料服務功能，還具備軟體定義儲存的組態彈性優點。Cloud Volumes ONTAP的基本概念NetApp在AWS與Azure提供的Cloud Volume ONTAP服務，其實，就是在公有雲上運行的虛擬化ONTAP儲存設備，可透過iSCSI或NFS/SMB協定，將儲存空間提供給公有雲上的其他運算單元使用，並擁有HA高可用性功能，以及完整的ONTAP資料服務功能。虛擬化與公有雲儲存的結合從產品型式來看，CVO可以看作是NetApp ONTAP Select軟體定義儲存系統，移植到公有雲上的延伸發展版本，兩者都是實體ONTAP儲存陣列的虛擬化版本，只是ONTAP Select是運行於VMware vSphere，或是KVM等本地端的虛擬化平臺，而CVO則是運行於AWS或Azure的公有雲虛擬化平臺而已。包括NetApp在內，現今的傳統儲存陣列產品，大多都是基於x86架構通用硬體設備的軟體定義型式，完全依靠儲存作業系統的軟體功能，在通用硬體上建構與提供儲存服務，所以，除了透過傳統的實體儲存陣列方式來提供產品外，也能透過虛擬化方式，將儲存作業系統部署到虛擬化平臺上，從而成為建構出「虛擬化儲存陣列」產品。如ONTAP Select便是NetApp FAS系列儲存陣列，移植到vSphere與KVM平臺上的虛擬化版本，利用虛擬機器來構成儲存控制器，搭配Hypervisor主機本身或介接的儲存空間，組成虛擬化的儲存陣列。除了一些限制，如每節點的容量上限400TB、不支援NetApp原有的底層RAID架構，以及只支援基於乙太網路的儲存協定（NFS/SMB與iSCSI），ONTAP Select的儲存功能與特性，與實體的FAS系列儲存陣列是大致相同的。更進一步來看，由於公有雲平臺的底層環境，也是一種虛擬化平臺，所以也能依循相同的模式，將儲存系統移植到公有雲平臺上，CVO便是這樣的產品。也就是說，CVO是利用公有雲平臺的虛擬機器或執行個體，來運行ONTAP儲存作業系統軟體，然後掛載公有雲儲存空間，組成一臺在公有雲上運行「軟體版雲端儲存陣列」，進而為其他公有雲虛擬機器提供儲存服務。比起實體儲存陣列，或是ONTAP Select這類本地端的虛擬化儲存陣列，CVO這種軟體定義架構的雲端儲存陣列，最大優點是成本低與架構彈性。首先，CVO完全依靠公有雲的運算與儲存資源來構成儲存陣列，用戶只需支付租用公有雲資源，以及購買CVO軟體授權的費用即可；其次，用戶也可以依照自身需求，選擇不同等級的公有雲資源來建構雲端儲存陣列，不需要使用時，也能將其關閉，擁有與公有雲原生服務一樣的按需購買靈活性。而比起公有雲原生的儲存服務，CVO的優點則是在於採用了久經考驗的ONTAP儲存系統，且提供了高可用性組態選項，以及豐富的資料服務功能。CVO目前的版本，與最新的ONTAP系統都是9.6版，並有雙節點高可用性（High Availability，HA）版本可選，比起一般的公有雲原生儲存服務，多了一層可用性保障。CVO也保有幾乎全部的ONTAP資料服務功能，包括：可幫助節省雲端儲存空間耗用量的Thin Provisioning、壓縮與重複資料刪除等功能，以及用於資料保護的Snapshot、SnapMirror、SnapVault，還有FlexClone等。亦能透過SnapMirror遠端複製功能，讓CVO直接與本地端實體ONTAP儲存設備連結，構成混合雲儲存架構。用戶也可透過Fabric Pool的功能，與AWS S3或Azure Blob等低價位公有雲儲存區，組成雲端上的分層儲存架構。（CVO只有少數ONTAP功能無法使用，如Metrocluster、RAID-DP、FlashCache/FlashPool等。）相較之下，一般公有雲原生儲存服務提供的資料服務功能，仍只在基本層次，大多只有快照、遠端複製與加密等少數幾種。持續延伸的平臺與組態彈性CVO的前身，是2014年底發表的ONTAP Cloud，已有4年以上歷史。ONTAP Cloud雖然開創儲存陣列移植公有雲的先河，不過，當時只能搭配AWS一種平臺，組態的限制也較多，例如，儲存區一開始只支援EBS的gp2型式。後來NetApp在2018年時，將ONTAP Cloud更名為Cloud Volume ONTAP（CVO），並大幅擴張了支援範圍，除了AWS以外，也提供Azure平臺上的服務，部署的組態也有更多的選擇彈性。另外，NetApp在2019年6月發表ONTAP 9.6版系統時，也推出了搭配Google GCP平臺的Private Preview版，預期不久之後，就能將CVO服務範圍正式擴展到GCP平臺上。開啟雲端儲存新類型從先前的ONTAP Cloud，到現在的CVO，經過4年多的時間發展下來，NetApp目前已能在全球20個AWS服務區域，以及33個Azure服務區域，提供CVO服務，另外，他們也推出了Google GCP的CVO預覽版，顯示這種產品型式的初步成功。依循NetApp的腳步，近一年多來，也開始有其他廠商跟進，推出類似CVO的雲端儲存服務。例如：Pure Storage的Cloud Block Store，以及Dell EMC的UnityVSA Cloud Edition等，分別是Pure Storage旗下FlashArray全快閃儲存陣列，以及Dell EMC旗下Unity儲存陣列的公有雲軟體化版本。市面上，多了這些廠商的投入，也讓這種將傳統儲存陣列平臺移植雲端而成的服務，形成了一種新的雲端儲存類型。Cloud Volumes ONTAP的版本與授權等級目前NetApp在AWS與Azure兩個雲端平臺上，提供了Cloud Volumes ONTAP（CVO）服務，無論在哪個平臺，都有單節點與HA雙節點兩種CVO版本。用戶訂購CVO時，有兩種模式可選：一為直接向公有雲服務商訂購的隨用隨付Pay-As-You-Go模式，由公有雲服務商提供所有服務；另一為向NetApp購買授權，然後再於公有雲上註冊的BYOL（Bring Your Own License）模式，CVO授權由NetApp或經銷商提供，公有雲服務商只提供運行CVO所需的運算與儲存資源授權。在Pay-As-You-Go模式下，用戶能以每小時為單位，彈性選擇合約時間長度，只有CVO運行時才計價，並有Explore、Standard與Premium等3種授權層級，分別提供不同的虛擬控制器組態，與可用容量上限的選擇。至於BYOL授權模式的合約時間則為6或12個月，但軟體授權不受特定公有雲服務商綑綁，且虛擬控制器的組態選擇也更多。由於不同公有雲平臺的虛擬機器與儲存服務規格、架構，均有所別，在AWS與Azure上的CVO控制器與磁碟規格，也略有差異，如在AWS上，CVO的單一磁碟區（Volume）最大容量是16TB，而在Azure上，則可允許最大32TB的單一磁碟區，詳細規格詳見原廠文件說明。從AWS或Azure市集訂購CVO服務CVO分為單節點與雙節點HA高可用性兩種版本，以及兩種訂購模式，一為直接向公有雲服務商訂購的Pay-As-You-Go模式，其下有Explore、Standard與Premium等3種授權層級可選；另一為向NetApp購買授權，然後再於公有雲上註冊的BYOL模式。圖片來源／NetAppCloud Volumes ONTAP的部署與管理當用戶訂購了Cloud Volumes ONTAP（CVO）服務授權後，便可下載CVO的映像檔，然後部署到公有雲的虛擬機器上。CVO是一種以虛擬化與軟體定義型式，部署在公有雲平臺上的「軟體版儲存陣列」，利用公有雲的運算單元（AWS的EC2執行個體或Azure的虛擬機器），來扮演儲存控制器角色，負責運行NetApp的ONTAP儲存作業系統。然後再將公有雲的儲存空間（AWS的EBS或Azure的LRS），掛載給這臺虛擬的儲存控制器，充當控制器後端的儲存空間。用戶可選擇將CVO部署在既有或新建的AWS虛擬私有雲端（VPC）環境內，或Azure虛擬私人雲端（VNet）環境內，從而為VPC或VNet環境的其他執行個體或虛擬機器，提供區塊或檔案儲存服務。依用戶選購的授權等級（Explore、Standard、Premium或BYOL），可選擇不同規格的執行個體或虛擬機器，用來部署成為CVO的虛擬儲存控制器。值得一提的是，為了確保CVO擁有類似實體ONTAP儲存設備的寫入效能，配置給執行個體或虛擬機器的一部分記憶體，將被作為儲存控制器的虛擬化NVRAM使用。而在CVO配置的儲存空間方面，無論在AWS還是Azure上，都有3種主要磁碟機類型可選——通用型SSD、效能型SSD與通用型硬碟。CVO先將AWS或Azure配置的磁碟機（disk）構成Aggregate群組，然後從Aggregate群組上建立磁碟區（volume），再透過iSCSI或NFS/SMB協定，將磁碟區掛載給其他虛擬機器使用。至於CVO的部署作業與維運管理，都是透過NetApp提供的OnCommand Cloud Manager管理軟體來執行，這套管理軟體是由公有雲上的一臺虛擬機器來執行。，本身不需要授權費用，用戶只需支付運行Cloud Manager的虛擬機器資源費用。Cloud Volumes ONTAP的運作架構以AWS上的CVO為例，CVO是在用戶指定AWS虛擬私有雲端（VPC）環境內運作的服務，包含4個主要元件：① ​一臺運行ONTAP儲存作業系統的AWS執行個體，扮演儲存控制器角色。② ​ 配置給ONTAP執行個體的EBS公有雲儲存空間，作為ONTAP的儲存區。③ ​一臺運行OnCommand Cloud Manager系統的執行個體，作為CVO管理平臺。④ ​使用CVO儲存服務的其他執行個體。扮演儲存控制器的ONTAP執行個體，可以將後端配置的EBS磁碟機，架構為自身的磁碟區，然後透過NFS/SMB或iSCSI協定，掛載給同一個VPC環境內的其他執行個體使用。用戶端的管理者可以透過閘道器的介接，登入Cloud Manager，從而執行CVO環境的部署與儲存管理。圖片來源／NetAppCloud Volumes ONTAP的HA高可用性功能標準的企業級儲存設備，都會採用雙控制器架構，以備任一控制器失效時，具有自動切換的高可用性能力（High Availability，HA）。而對於在公有雲上運行的Cloud Volumes ONTAP（CVO），除了基本的單節點版本外，也提供了具備高可用性能力的雙節點HA版本，用戶可以部署2臺CVO節點組成HA群組，當任一臺CVO節點失效時，可透過另一個CVO節點接手維持存取服務，比起一般的公有雲原生儲存服務，多了一層可用性保障。不過，在AWS與Azure上，CVO的HA架構運作方式略有差異。AWS上的CVO高可用性架構兩個CVO節點可以位於同一個或不同的可用性區域（AZ），後端各自掛載著自身的EBS磁碟機，但兩個節點需設定在同一個VPC環境內，彼此間透過鏡像複製維持資料同步，另外，還有一個負責連繫兩個CVO節點與提供仲裁功能的Mediator節點（本身是位於第3方可用性區域的一臺Linux執行個體）。當任一CVO節點或其後端EBS儲存區失效時，可透過Mediator節點啟動I/O路徑切換，將存取負載轉給另一CVO節點承擔。圖片來源／NetAppAzure上的CVO高可用性架構在相同的VNet與Subnet環境內，將兩個CVO節點組成一個可用性群組（Availiability Set），兩個節點共同存取相同的Azure Page Blob儲存體磁碟機群組，透過一臺扮演ILB（Internet Load Balance）的虛擬機器連繫兩個節點。當任一CVO節點失效時，透過ILB將存取負載切換到另一CVO節點。要特別注意的是，在Azure上，單節點版本的CVO使用的磁碟機，是Azure的受控（Managed）LRS儲存體，而HA版本的CVO則改用Azure非受控的Page Blob儲存體。從NetApp提供的架構圖上，我們可以看出，比起AWS上的CVO HA架構，Azure上的CVO HA架構比較簡單，兩個CVO節點是存取同一個Page Blob儲存體，所以不需要跨節點同步鏡像，不過無法應付後端儲存體失效的情況。圖片來源／NetAppNetApp兩種Cloud Volumes對比：CVO vs. CVS資料來源：iThome整理，2019年7月除了Cloud Volumes ONTAP（CVO）外，NetApp還有一款稱作Cloud Volumes Service（CVS）的公有雲儲存產品，CVO與CVS兩個產品不僅名稱類似，也同樣都是架構在公有雲平臺上、基於NetApp ONTAP平臺的儲存服務，十分容易混淆，但兩者的底層架構完全不同，我們這裡特地作一對比。● 儲存設備：CVS是部署在公有雲資料中心的「實體NetApp AFF儲存陣列」，提供儲存服務，儲存陣列就有HA高可用性能力；CVO是由公有雲運算與儲存資源建構的「虛擬化儲存陣列」，來提供儲存服務，而HA的功能需額外選購。● 系統部署：CVS底層的實體AFF儲存陣列，由NetApp負責部署，無需用戶介入：CVO則需由用戶自行下載映像檔，並部署到公有雲的虛擬機器上。● 系統管理：CVS底層的實體AFF儲存陣列，由NetApp負責設定與管理，用戶只能設定需要的Volume磁碟區大小，以及快照排程；CVO底層的虛擬控制器及磁碟區，都由用戶自行管理，用戶擁有完整的控制權。● 維運模式：CVS向用戶提供的是儲存空間使用權，用戶可隨用隨付或定期定購；CVO提供的是一整臺虛擬儲存設備與其儲存空間的授權，用戶可隨用隨付或定期定購。● 儲存應用範圍：CVS只支援NAS檔案共享存取應用，只支援NFS與SMB協定，資料服務功能較少，但憑藉底層實體AFF儲存陣列，可適用從小型到超大型工作負載；CVO支援SAN與NAS應用，能支援基於NFS與SMB協定的檔案存取，也支援基於iSCSI的資料存取，但由於底層是虛擬儲存裝置，只支援小型與中型工作負載。● 適用公有雲平臺：CVS目前可支援AWS、Azure與GCP等3個公有雲平臺；CVO目前只支援AWS與Azure，GCP版本仍在測試中。● 服務區域涵蓋：CVS由於須將實體設備部署進公有雲資料中心，所以，在公有雲服務區域的部署速度，比起軟體定義部署的CVO慢了許多。以AWS來說，目前已有20個服務區域可提供CVO，但其中只有8個服務區域有CVS；類似的，目前已有33個Azure服務區域提供CVO服務，其中，只有8個區域，提供Azure NetApp Files服務（CVS在Azure上的名稱）。2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "Google修完漏洞，但網站仍可用檔案系統API偵測出Chrome無痕模式 ": "檔案系統API在無痕模式會將資料寫入記憶體，其速度比一般模式寫入磁碟還快得多，因此可被用來偵測瀏覽器模式Google為了讓網站無法偵測用戶是否以無痕進行瀏覽，在Chrome 76修正檔案系統（FileSystem）API的漏洞，但現在有研究人員發現，Chrome 76的檔案系統API的寫入速度，在無痕模式比一般模式還要快，因此網站還是能用寫入的速度差異，來偵測使用無痕模式的訪客，達成時序攻擊（Timing Attack）。Chrome 75以前的版本，無痕模式會禁用檔案系統API，以避免在裝置留下任何活動痕跡，而檔案系統API的漏洞，會讓網站在檢查檔案系統API的可用性時，回傳錯誤訊息，因此網站便能得知用戶正在使用無痕模式，Google提到，由於不少媒體網站採用計次付費牆（Paywall）收費模式，當用戶瀏覽超過一定數目的文章，才會要求登入付費帳號，因此為避免用戶使用無痕模式規避計次付費牆機制，網站便會使用檔案系統API的漏洞，偵測用戶是否正使用無痕模式，決定給予相對應的用戶體驗。而在7月的時候，Google宣布要落實無痕模式隱私原則，會在Chrome 76中，修正檔案系統API的漏洞，但現在研究人員Jesse Li發現，即便是最新的Chrome 76，仍然可以透過量測API寫入儲存中介的速度，來偵測瀏覽器的無痕模式，而Jesse Li也在GitHub中發表了概念性驗證實作。Chrome 76為了避免網站根據檔案系統API的可用與否偵測無痕模式，因此即便在無痕模式，Chrome仍然會寫入API的資料，只是資料寫入的目標是記憶體而非磁碟，如此便不會在磁碟上留下操作痕跡，對網站來說，檔案系統API都一致可用，那就不存在之前以API可用與否，判斷瀏覽器無痕模式的問題，不過這卻產生另一個問題，由於記憶體寫入速度比磁碟更快，兩者仍存在差異。利用這樣的差異，網站就能推測出用戶是否使用無痕模式。由於記憶體比磁碟快上許多，網站只要重複寫入大量的字串，量測檔案系統需要時間，建立出基準測試，就能用來判斷訪客是否使用無痕模式。Jesse Li進行了一百次的迭代，共花費數分鐘做出基準測試。基準測試結果顯示，在一般模式下的檔案系統，寫入磁碟的尖峰時間約落在3,000到4,000毫秒之間，相較於無痕模式寫入記憶體，尖峰落在1,000毫秒，時間只有三分之一到四分之一而已，無痕模式平均耗費792毫秒，而一般模式平均則要2,281毫秒，是前者的2.8倍。Jesse Li解釋這種偵測無痕模式與一般模式的時序攻擊有其限制，除了需要花上數分鐘或是數十秒的時間，才能獲得有用的資料之外。偵測的結果跟使用者裝置的配置有關，行動裝置與桌上型電腦的記憶體和磁碟速度都不一樣，也會跟裝置同時執行的工作有關，而對統計資料產生雜訊。這種方法並非直接偵測無痕模式，而是偵測檔案系統的第二儲存中介，進而推斷使用者瀏覽器正在執行的模式，但當磁碟即是記憶體的時候，便會產生誤判。不過，Jesse Li提到，這種方法相對難以修補，因為其攻擊的手段是漏洞修補的技術基礎，因此用戶要完全避免被偵測出使用無痕模式，必須要在兩種裝置使用相同的儲存中介，寫入速度相同也就沒有被偵測的疑慮。iThome Security2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29"
    },
    "Q4": {
        "【SaaS型公有雲儲存1】備份與災難備援服務 ": "當用戶的公有雲應用同時涉及不同儲存或應用軟體服務，便需要統一的備份管理工具，這裡介紹公有雲平臺自身的備份工具：AWS Backup與Azure Backup【AWS CloudEndure Disaster Recovery架構】透過安裝在實體、虛擬或雲端主機上的代理程式，在來源端主機與AWS雲端備援主機間維持同步，當來源端失效時，切換由備援主機接手服務。（圖片來源／AWS）透過內含的快照複本與資料分散複製功能，公有雲儲存原則上可降低傳統備份的需要，不過若用戶的公有雲應用同時涉及不同儲存或應用軟體服務，還是需要統一的備份管理工具。這裡介紹的是公有雲平臺自身的備份工具——AWS Backup與Azure Backup。AWS Backup是整合不同AWS應用環境備份應用的集中管理平臺，可以統一管理不同AWS服務既有的備份功能，包括EBS與Storage Gateway磁碟區快照，以及RDS資料庫與DynamoDB資料庫快照等，並為EFS提供備份功能，透過主控臺即可設定自動化的備份政策，免除手動指令的需求。Azure Backup是Azure內含備份功能，支援Azure自身的VM，或安裝MARS代理程式的用戶端主機與Windows VM，可以LRS本地或GRS異地備援儲存體，作為備份儲存區。備份只提供基本的資料保護，要求更高可用性的用戶，需要災難備援工具，來提供「服務」層級保護能力。我們這裡介紹的是公有雲自身的災難備援服務，包括AWS的CloudEndure Disaster Recovery，以及Azure的Site Recovery。AWS的CloudEndure Disaster Recovery，可支援本地端主機、VM與公有雲上的執行個體，先在主機或執行個體上安裝代理程式，然後透過AWS上的CloudEndure伺服器作為中介，在公有雲上建立備援的伺服器與執行個體複本，並透過複製維持兩端點的資料同步。當來源端失效時，藉由CloudEndure伺服器的中介，手動或自動將服務切換到備援系統上。Azure Site Recovery可支援本地端實體主機、vSphere與Hyper-V VM，以及雲端的Azure VM，將資料複製與同步到Azure上的備援VM，當來源端系統失效時，將服務移轉到備援系統。 相關報導  雲端儲存的多元化面貌2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "儲存龍頭主力中階儲存陣列推出全新世代機型款式 ": "Unity XT是Unity儲存陣列家族最新一代機型，透過升級硬體核心與系統軟體平臺，效能提升2倍，最大容量也從1000臺磁碟，提升到1500臺這兩年來Dell EMC動作頻頻，全面更新旗下主力產品線。先是在去年Dell Technologies World大會，發表新一代高階儲存產品PowerMax，接著又於今年大會，推出Unity中階儲存陣列的全新改款Unity XT。儘管身為中階產品的Unity XT，在架構與規格方面的革新程度，不如高階的PowerMax那樣搶眼，但用戶群與應用面向更廣，特別是對中階用戶占了80%的臺灣市場來說，Unity XT實際上是更重要的產品線。Unity是Dell EMC發表於2016年的新一代中階產品，但問世之初卻顯得有些創新不足，仍採用雙控制器Scale-Up架構與傳統RAID技術，軟體功能也還不完整。不過經過2、3年來的發展，不僅軟體功能逐漸成熟，到了最新的Unity XT系列，又進一步翻新了硬體規格，並結合引進了了新式RAID架構的軟體平臺，以及改進的遠端同步與雲端應用功能。比起最初的Unity，Unity XT無論效能、容量、儲存空間效率、系統組態彈性與可用性都有顯著增長，並能透過新的遠端同步功能，搭配Unity VSA虛擬化儲存系統的雲端版本，提供整合的混合雲應用架構，這也讓Dell EMC特地在產品名稱後加縋「XT」字樣，彰顯這系列產品有別於過往Unity系列的全新特性。源遠流長的Dell EMC中階儲存Unity XT是EMC歷史悠久的中階儲存陣列產品最新一員，這個家族最早可以追溯到早期著名電腦製造商Data General，該公司於1991年發展的HADA儲存陣列，擁有快取RAID架構與熱插拔機構等新發明，HADA與其改良版HADA II，最初是搭配Data General自身Aviion迷你主機使用，後來在1994年時，演變為搭配開放環境的CLARiiON儲存陣列。CLARiiON首創了導軌熱插拔磁碟、雙主動控制器、鏡像寫入快取、完整的系統熱備援等設計，並在1997年推出的FC5000系列上率先支援FC介面，這些功能都成為日後業界標準，在市場上大獲成功，Sun、HP與SGI都曾OEM這款產品。當EMC於1999年併購Data General後，也只保留CLARiiON這條產品線繼續發展。EMC原本只有自身發展的高階儲存產品Symmetrix，此後則透過CLARiiON進入中階領域，先後推出了4個世代，包括2001年的FC4000與IP4000系列，2002年的CX系列、2006年的CX3系列與2008年的CX4系列，並延伸出入門級的AX系列。到了2011年，EMC推出新一代中階儲存陣列產品VNX系列，與入門級的VNXe系列，同時取代了CLARiiON系列SAN儲存陣列，以及Celerra系列NAS，不過，CLARiiON核心的FLARE作業系統平臺，仍保留在VNX與VNXe系列中。VNX是一種通用儲存設備，同時含有提供SAN服務的儲存處理器，與提供NAS服務的Data Mover模組，其中，SAN儲存處理器模組運行的OE for Block系統，便是CLARiiON的FLARE系統，而Data Mover模組運行的OE for File系統，則是Celerra的DART作業系統。而在VNXe上，則是透過虛擬化架構，以VM來分別運行FLARE與DART作業系統。值得一提的是，EMC另外還提供了VM化的軟體版VNX VSA，能以軟體定義形式來部署VNX儲存設備。後來，EMC又在2013年發展了第2代VNX系列，強化了對Flash儲存媒體與多核心處理器的支援。時隔3年後，EMC於2016年5月推出VNX的後繼者Unity系列，引進了全新的Container化軟體架構，並能提供全快閃組態款式，也有軟體定義化的Unity VSA版本。至於剛在2019年5月發表的Unity XT，則是Unity系列的第3代產品，若從CLARiiON起算，則是EMC的第8代中階儲存產品。Unity家族的統一更新前面提到，Unity XT是Unity系列的第3代產品，這是從全快閃機型的角度來看，若從混合陣列機型來看，Unity XT算是Unity的第2代產品。Unity系列最初於2016年發表的第1代產品，包含混合陣列的Unity 300、400、500與600，以及全快閃的Unity 300F、400F、500F與600F。不過，接下來2017年6月發表的第2代Unity，只包含全快閃X50F系列，包括Unity 350F、450F、550F與650F，混合陣列版本則沒有更新，這也讓Unity系列的混合陣列與全快閃陣列機型，不再彼此對應。而在這次發表的第3代Unity機型，也就是Unity XT，則一併將混合陣列與全快閃陣列都更新為X80系列，讓兩個系列恢復彼此對應，包含混合陣列的Unity 380、480、680與880，以及全快閃的Unity 380F、480F、680F與880F。更成熟完整的產品平臺相較於先前的Unity系列，Unity XT系列的特點是更新了控制器硬體核心，並一舉補充先前Unity家族在機型涵蓋面，以及軟體功能方面的不足。控制器硬體核心升級第一代Unity的控制器，搭載的處理器是Intel Xeon Haswell架構，第2代Unity X50F系列則升級為Xeon Broadwell-EP架構。而新推出的Unity XT系列中，除了最低階的380/380F仍沿用Broadwell-EP處理器外，其餘機型都升級為新的Xeon Skylake架構處理器。原廠宣稱，藉由控制器處理器升級，以及系統軟體的最佳化，可擁有兩倍於上一代機型的效能。擴展機型涵蓋範圍在Unity系列發表之初，較大的缺憾之一，是未能完整涵蓋上一代VNX與VNXe系列機型的容量範圍。當時的Unity系列，涵蓋了100～200臺磁碟容量的入門級領域，與500～1,000臺磁碟容量的中階應用領域，但最高階的Unity 600/650只達到1,000臺磁碟的擴充能力，無法對應VNX系列最高階VNX8000的1,500臺磁碟擴充能力，這個問題在新的Unity XT上終於獲得解決。Unity XT取消了中階的5X0/5X0F系列，另增加新的高階機型880與880F，擁有最大1,500臺磁碟擴充能力，終於達到先前VNX系列的容量範圍。Unity XT也大幅提高了低階機型的擴充能力。即使是380/380F也擁有500臺磁碟的擴充性，遠超過以前3X0/3X0F系列的150臺磁碟；而480/480F的擴充能力，也從先前4X0/4X0F的250臺磁碟，提高到750臺磁碟。大幅翻新的軟體核心一般來說，新的SAN儲存平臺至少得經過3～5年的發展，才能成熟，而現在Unity家族的軟體平臺，正進入成熟期。Unity系列在3年前問世之初，讓人最為詬病之處，便是儲存服務架構「新瓶裝舊酒」，較缺乏創新，另外像是即時壓縮、重複資料刪除等新一代儲存設備必備的功能，也都付之闕如。不過，在這兩年來的更新中，Unity系列逐步補足了即時壓縮與重複資料刪除等功能，並伴隨新推出的Unity XT，推出了構成整合混合雲架構的新應用──可讓實體Unity儲存設備，與雲端上的Unity VSA虛擬儲存設備之間，執行遠端同步。不僅讓Unity家族的軟體功能更完整，也引進了嶄新的混合雲應用架構。 Dell Unity XT的儲存組態如同先前的Unity系列，Unity XT的硬體，也是由作為控制器的DPE（Disk Processor Enclosure）磁碟處理器機箱，與DAE（Disk Array Enclosure）擴充磁碟櫃所組成。DPE控制器機箱的正面，含有提供基本儲存空間的磁碟槽，其中前4臺磁碟是系統用，不可移動到其他位置，另外還需1臺磁碟作為這4臺磁碟的熱備援，所以，系統基本需耗用5臺磁碟。機箱背面則容納了2組儲存處理器（Storage Processor，SP）控制器。DPE機箱可透過SP控制器的12Gb SAS規格mini-SAS HD埠，串接DAE磁碟櫃來擴充容量。最初Unity只有基於2.5吋磁碟的2U/25Bay DAE磁碟櫃，以及基於3.5吋磁碟的3U/15Bay DAE磁碟櫃可用，2017年中時，新增了3U/80Bay高密度DAE磁碟櫃──這種磁碟櫃是基於2.5吋磁碟規格，但透過垂直抽取機構來大幅提高儲存密度。如表格所示，Unity XT的擴充能力比起舊的Unity大幅提高，最低階的380/380F就擁有500臺磁碟擴充能力，最高階的880/880F則達到1,500臺磁碟，比舊的Unity高階機型高出50%，但最大原生儲存容量仍然是16PB。在磁碟介面方面，Unity XT仍沿用12Gb SAS，不過，480/480F以上機型的DPE機箱都備妥了NVMe介面，預定年底就能正式支援NVMe SSD。 圖示1  外接DAE磁碟櫃擴充容量Unity XT可支援2U/25Bay、3U/80Bay與3U/15Bay等3種DAE擴充磁碟櫃，都是透過mini-SAS HD介面來連接DPE機箱，其中前兩者是基於2.5吋磁碟規格，可供全快閃或混合陣列機型使用，3U/15Bay則是基於3.5吋磁碟規格，專供混合陣列機型使用。 圖示2  12Gb SAS介面SSD與硬碟Unity XT仍沿用12Gb SAS作為後端磁碟介面，可支援800GB、1.92TB、3.84TB、7.68TB與15.36TB容量的SSD，混合陣列機型另可支援600GB到12TB容量的SAS硬碟。 圖示3  NVMe Ready從480/480F以上的Unity XT機型，都備妥了NVMe介面SSD的支援，DPE機箱最右邊的8個磁碟槽，日後可用於安裝NVMe SSD。 Dell EMC Unity XT硬體解剖Unity XT系列的硬體，其實分為兩種，380/380F仍沿用上一代350F的硬體核心與機箱設計，480/480F以上機型才引進了新的硬體核心與機箱。最低階的x380/380F，SP儲存處理器模組為單處理器架構，搭載了1顆與上一代350F相同的6核心、1.7GHz Xeon E5-2603 v4處理器，但記憶體從350F的48GB提高為64GB；480/480F以上機型的SP處理器模組，均為雙處理器架構，其中480/480F為2顆8核心、1.8GHz的Xeon Silver 4108處理器，搭配96GB記憶體；680/680F為2顆12核心、2.1GHz的Xeon Silver 4116處理器，搭配192GB記憶體；最高階的880/880F為2顆16核心、2.1GHz的Xeon Silver 6130處理器，搭配384GB記憶體。380/380F與480/480F以上機型的另一個主要差別，是備援與開機媒體不同。380/380F是透過1組SSD來提供快取寫入備援與開機映像保存；480/480F則是把快取寫入備援與開機映像，分別透過1組NVMe SSD與1組SATA SSD來提供。在I/O介面方面，380/380F與480/480F以上機型的提供方式也有異。380/380F含有控制器內建I/O埠，以及透過I/O模組提供的I/O埠兩種形式，每組SP儲存控制器含有內建的2組12Gb SAS埠，以及2組10GbE埠，另可選裝2組I/O模組。至於480/480F以上機型，則沒有控制器內建I/O埠，而是透過Mezzanine卡模組與I/O模組，來提供對外連接介面。每組SP儲存控制器基本配置1組Mezzanine卡模組，另可選裝最多2組I/O模組。每組DPE磁碟處理器機箱都含有2組SP儲存處理器模組，以及2組電源供應器，構成熱備援的高可用性架構。 儲存處理器模組DAE機箱內的2組SP儲存處理器構成Active-Active高可用架構，每組SP儲存處理器可以選裝Mezzanine卡模組，以及I/O模組，來提供對外連接介面。  圖示1  Mezzanine卡模組：有3種版本，均含有2組管理埠與 SAS埠，搭配不同前端I/O埠，包括4埠10GbE（BASE-T或SFP+）、或4埠25GbE，均同時支援區塊儲存與檔案儲存。 圖示２  I/O模組：Unity XT的I/O模組有4種款式，分別為4埠16Gb FC，4埠10GbE、4埠25GbE，以及4埠12Gb SAS。 I/O埠配置：480/480F以上機型是透過Mezzanine卡與I/O模組來提供I/O埠，照片中的展示機已安裝了1組Mezzanine卡模組，以及2組I/O模組。Mezzanine卡模組含有2組RJ-45管理埠（圖示1）、2組12Gb SAS擴充埠（圖示2），與4組兼用於iSCSI埠或NAS存取的10GbE埠（圖示3）。I/O模組插槽各含4個16Gb FC埠（圖示4）。SP儲存處理器解剖：480/480F以上機型的SP處理器均為雙處理器（圖示1），搭配96～384GB記憶體（圖示2），重要元件還包括備援電池，M.2 SATA SSD與M.2 NVMe SSD，供快取備援與開機。 Dell EMC Unity XT系統軟體與管理功能提供本地端與雲端集中管理介面Unity XT的管理介面分為3種，包括本地端的Unisphere GUI、Unisphere CLI文字命令列界面，以及Cloud IQ雲端管理平臺。如同先前的Unity，Unity XT也沿用了稱作「作業系統環境（Operating Environment）」的系統軟體平臺，這是一套基於Container架構，可同時支援區塊與檔案存取服務的儲存作業系統，最初版本是OE 4.0，目前最新版本是OE 5.0。相較於早期版本，目前的新版本OE已有多項重要改進，其中最重要是下列這3點：動態儲存池OE系統最初只有傳統RAID架構，而在2017年的OE 4.2版中，新增稱作動態儲存池（Dynamic Pool）的嶄新RAID架構。這是ㄧ種適用Unity XT全快閃機型的新一代RAID技術，類似HPE 3PAR的FAST RAID、NetApp的Dynamic Disk Pool，以及IBM的Distributed RAID技術，可以跨最多64臺磁碟，建立統一儲存池，先在磁碟底層構成GB等級的Extents小區塊，然後再跨整個磁碟群組建立RAID，不需要指定Hot Spare磁碟，可解決傳統RAID架構因重建負載集中於Hot Spare磁碟，而導致重建速度緩慢的問題。完整的資料縮減技術支援完整資料縮減功能目前OE作業系統已能提供完整的資料縮減功能，用戶建立LUN或檔案系統時，在屬性欄位中勾選即可使用。缺乏資料縮減功能，是Unity發表之初，外界一大疑慮所在，不過OE系統已在歷次更新中，補上了這方面的功能。先是在OE 4.1版，提供針對LUN區塊服務的即時壓縮，到了OE 4.2，又加入針對檔案服務（檔案系統與VMWare Datastore）的即時壓縮，均只適用於全快閃儲存池，用戶建立LUN或檔案系統時勾選即可啟用。接著在OE 4.3中，則以Data Reduction功能取代原有壓縮功能，同時整合了壓縮與重複資料刪除演算法。而在OE 4.5版，又引進了In-line Dynamic Pattern偵測功能，進一步改善了區塊與檔案儲存服務的空間縮減效率。更彈性的遠端複製架構OE系統的遠端同步複製最初只提供針對區塊服務，而在OE 4.4版時，則新增了檔案層級的遠端同步複製，可為Unity的檔案存取服務，提供基於Metrosync技術的遠端同步鏡像保護，OE 4.5又新增Metrosync Manager幫助管理這項功能。值得一提的是，目前新的OE系統還可透過檔案層級的遠端非同步複製，建立跨遠端的HA架構，無需借助閘道器等額外設備，就能讓遠端的兩臺Unity構成HA備援群組，並適用於雲端上的Unity Cloud儲存裝置，這也為用戶提供了簡便的整合式混合雲架構，利用雲端上的虛擬化Unity儲存裝置，來作為本地端Unity的低成本備援環境。 產品資訊Dell EMC Unity XT●建議售價：廠商未提供●原廠：Dell EMC 0080-160-256●機箱型式：處理器機箱2U、磁碟櫃2U或3U●儲存容量：最大擴充500～1500臺磁碟, 原生容量2.4～16PB●處理器：Intel Broadwell（380/380F）, Skylake（480/480F以上機型）●記憶體：64～384GB●主機端介面：16Gb FC,10/25GbE（iSCSI或NAS）●後端介面：12Gb SAS【註：規格與價格由廠商提供，因時有異動，正確資訊請洽廠商。】2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "針對新式儲存裝置最佳化，UL PCMark 10 Storage 測試功能來了 ": "PCMark 8 Storage 早已經老朽，寄望 PCMark 10 Storage 能理想呈現出磁碟性能差異。電腦系統綜合基準測試軟體 PCMark 10，推出當時也強調內建儲存裝置測試模式，除了測試選項更豐富還支援 Optane 等新式儲存裝置，得以完美取代 PCMark 8。然而這只是發行公司 UL Benchmarks 的目標而已，因為儲存基準測試項目一直從缺，直到日前新釋出 v2.1.2153.64 版本才補上，而且僅限專業版本才有提供。PCMark 10 Storage Benchmark 具有 4 種測試模式，Full System Drive Benchmark 利用模擬真實工作負載，測試評估固態硬碟、Optane 等新式儲存裝置的日常應用表現。而 Quick System Drive Benchmark 模擬工作負載較輕且相對省時，並且涵蓋支援硬碟機、低階系統，Data Drive Benchmark 則以測試儲存裝置本質性能為主，亦適用於 USB、Thunderbolt 等介面外接裝置。至於 Drive Performance Consistency Test 是頗為耗時的性能一致性測試，以更繁複的模擬工作負載等條件來進行，相當程度上可作為髒碟模擬測試的手段之一。PCMark 10 專業版參考價格為 1495 美元 / 年，大家當然沒必要花這大錢購買來玩耍，我們日後接獲廠商送測的固態硬碟等樣品時，會斟酌將 PCMark 10 Storage Benchmark 列為基本執行項目。 自由自在的寫作。[email protected]Comments are closed.半導體到各種終端裝置，測試（Bench）與考驗一直在我們人生（Life）來來回回，網站名稱起源就是如此而來。聯絡我們：[email protected] Copyright © 2020 — BenchLife. All Rights Reserved Designed by WPZOOM",
        "【IaaS型公有雲儲存的進階服務2】公有雲的長期資料儲存服務 ": "利用公有雲無限擴展的特性，再結合大容量磁碟裝置，可為用戶提供低成本的雲端儲存空間，作為傳統磁帶與低成本磁碟陣列設備的替代，用於長期保存資料，以符合法遵要求不需經常存取、但需長期保存的冷資料（Cold Data）儲存應用，也就是資料歸檔或封存（Archive），是公有雲儲存服務一大發展重點，利用公有雲近乎無限擴展的特性，再結合大容量磁碟裝置，可為用戶提供低成本的雲端儲存空間，作為傳統磁帶與低成本磁碟陣列設備的替代，用於長期保存資料，以符合特定行業的法規遵循要求。目前的公有雲長期儲存服務，都是由物件儲存服務延伸而來的低成本版本，利用物件儲存系統的擴展能力、高耐久性、可靠性、可用性，以及存取管制能力，為用戶資料的長期儲存提供安全、耐久、且具備彈性擴充能力的儲存空間。同時為了降低成本，歸檔儲存服務會再搭配限制的傳輸能力，以及有限的存取頻率，例如，歸檔儲存服務的資料取回（retrieved） 所需等待時間，一般會從標準型物件儲存服務的毫秒等級延遲，降到小時等級的延遲，存取頻率也限定為每年只存取1、2次，不過在平均月租費上，通常只有標準型物件儲存服務的1/5甚至1/10以下。在標準型物件儲存與歸檔型物件儲存之間，由於具有不同的效能與成本特性，可讓兩者構成分層儲存架構，更有效率的管理雲端上的資料儲存。不過要注意的是，針對長期儲存應用的歸檔儲存服務，持續儲存時間門檻要求較高，例如最少需持續儲存90天或180天，不像標準型物件儲存服務般可以隨時停止訂購，用戶每次從封存儲存區域讀取與回傳資料，也需額外收取費用。此外，有些服務商的長期歸檔儲存服務為離線型式，收到請求時才能連接存取，而不是隨時可用。至於當用戶需要從歸檔儲存區取回資料時，發出取回、還原歸檔資料需求後所需等待的延遲時間，各服務商提供的規格也有很大差異，多數都需要數小時等級的延遲，但也少部份服務商的歸檔儲存服務，可提供秒到分鐘等級的延遲（如Google的Archival Cloud與阿里雲的Object Storage Archive）。 相關報導  雲端儲存的多元化面貌2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "Dell EMC ECS物件儲存系統推出中階節點EX500 ": "ECS物件儲存系統新款中階節點機箱，搭配最新3.4版系統軟體提供更彈性管理架構沿續一年多以來，對於Elastic Cloud Storage（ECS）物件儲存系統的密集更新，Dell EMC日前又發表了ECS新款節點EX500，以及3.4版作業系統。ECS是EMC尚未與Dell合併前，於2014年發表的軟體定義架構物件儲存系統，透過運行ECS作業系統的x86伺服器構成節點，來提供便於擴展的分散式物件儲存環境，可支援S3、Swift、EMC本身的Atmos與CAS等物件儲存協定，以及NFS與HDFS等檔案儲存協定。這次新推出的EX500節點，填補了ECS原有EX300與EX3000系列兩款節點之間的產品間隙。原先的EX300是入門級節點，採用2U/12Bay機箱，硬體核心是1顆8核心處理器與64GB記憶體，每節點可提供12～96TB容量。EX3000是高階節點，採用4U/60Bay機箱，硬體核心是2顆8核心處理器與64GB記憶體，每節點可提供360～8640TB容量。我們可以發現，這兩款之間存在著巨大的規格落差——EX300顯得過低，而EX3000卻又過高。而新的EX500的容量則介於EX300與EX3000之間，採用2U/24Bay規格機箱，每節點容量為96～288TB，提供了一個較適切的容量選擇，也讓整個ECS增加了擴充彈性。此外，EX500還擁有規格更高的雙10核心處理器硬體核心，以及與EX3000相同的25GbE傳輸介面，效能直追高階的EX3000節點。至於新的ECS 3.4版系統，則新增了幾項關於儲存空間效率與網路管理架構的改進。首先是透過減少每個物件所產生的metadata，從而增加了實際可用空間。其次，ECS叢集節點的前端與後端網路都開始支援交換器管理架構，以前只有前端網路支援交換器管理，而從3.4版起，節點與節點之間互連的後端網路，也能透過專門的後端交換器來管理。另外，3.4版也改進了資安功能。EX500是ECS物件儲存系統新推出的中階節點，可提供每機箱96～288TB容量，並組成每機櫃480TB～4.6PB容量的叢集儲存空間。產品資訊：●原廠：Dell EMC 0080-160-256●建議售價：廠商未提供●機箱尺寸：2U（每節點）●處理器：10核心處理器×2●記憶體：64GB●儲存容量：12或24臺磁碟／96～288TB（每節點原生容量），480TB～4.6PB（每機櫃原生容量）●叢集規模：最小5節點，最大無限制●傳輸介面：25GbE2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "美國空軍通訊系統的8吋磁碟機終於退休 ": "一名指揮官透露美國空軍在今年中旬進行系統升級時，淘汰了指揮控制系統中運作40多年的8吋磁碟機，升級成固態硬碟，但仍決定保留骨董級的IBM Series/1電腦，因為它沒有IP位址駭客無法入侵https://twitter.com/GenDaveGoldfein/status/1184144779279585280你見過8吋磁碟片嗎？事實上，它還在今天地球某個角落運作直到今年。美國空軍近日系統升級，將一個從1970年代使用迄今的8吋磁碟機正式除役。這個磁碟機是美國空軍策略自動化指揮控制系統（Strategic Automated Command and Controls System，SACCS）的一部份。這套系統主要作為美國戰略司令部從核子指揮中心發布緊急行動通訊到前線空軍，跑在1970年代安裝的IBM Series/1電腦上，以8吋磁碟片作為資料儲存媒體，這套系統由美國空軍595策略通訊中隊負責維護。2016年美國國防部推動資訊系統更新計畫，欲更新其「資料儲存解決方案、傳輸埠擴充處理器、可攜式終端及桌面終端機。」美國國防部原本計畫是2017年底完成，不過是否如期進行不得而知，但美國空軍595策略通訊中隊指揮官Jason Rossi上周接受媒體訪問時指出，SACCS已經在6月間淘汰8吋磁碟機，升級到「極堅穩的固態硬碟數位儲存系統」，但他並未透露詳情。不過IBM Series/1電腦目前仍然繼續服役，理由是安全又穩定。Rossi指出，一個沒有IP位址的系統是駭不成的，這是套很獨特的系統，雖然老、但很好用。唯一，且一個很大的缺點是維修不易，許多零件已經找不到備品，只能靠修理來維續。至於SACCS其他硬體是否還會更新也不得而知。2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "全球網路很快「儲存空間不足」，未來要把數據存在哪裡？ ": "如今智慧手機的儲存空間越來越大，可全球的數據儲存很快就會亮出「儲存空間不足」的預警。根據軟體公司 Domo 的報告，2018 年人們每分鐘在 Google 進行 383 萬次搜尋，在 YouTube 觀看 433 萬段影片，發送 159,362,760 封電子郵件、473,000 條 Twitter 和 49,000 張 Instagram 照片。而在中國，每天在微信發出的訊息就超過 450 億條。Domo 預計到 2020 年全球人均每秒將產生 1.7 MB 的數據，以全球人口 78 億計算，那麼一年就會產生 418 ZB 的數據，大約需要 4,180 億個 1TB 硬碟才能裝下。這還沒考慮到人口的增長趨勢，聯合國預計世界人口在 2050 年就能突破 97 億。這意味著現有的數據儲存系統撐不到下個世紀了。（Source：聯合國）數據的爆炸式增長，迫使人類尋找更好的數據儲存技術。有人嘗試用 1 公斤 DNA 儲存全球數據，微軟則研發出可以號稱可以使用上千年的「玻璃光碟」，然而技術最先進的科技公司還在使用磁帶儲存數據。人類文明狂奔五千多年，但現在可用的儲存介質最長的壽命最多才約 60 年，數據儲存的未來到底在哪裡？在很多人印像中，磁帶彷彿是上個世紀的古董了。不少 80 後 90 後當年還是以買磁帶來支持自己的偶像，任賢齊 1996 年發行的專輯《心太軟》錄音帶銷量就突破了千萬。然而隨著 CD、MP3、智慧手機相繼在音樂市場上各領風騷，磁帶也成了一代人的回憶，在生活中難覓踪影。可磁帶並沒有死，反而在大數據時代成了最具競爭力的儲存介質。目前包括 Google 、亞馬遜和微軟等科技巨頭其實也還在使用磁帶來備份海量數據。為什麼放著機械硬碟（HDD）和固態硬碟（SSD）不用，反而去用磁帶儲存數據呢？最重要的原因還是便宜，這些科技公司的用戶數以億計，需要儲存的數據量十分龐大。儘管雲計算是未來趨勢，但對於提供互聯網服務的公司來說，依然需要將數據儲存到本地，這將是一筆不菲的成本。儘管與硬碟和半導體儲存器相比，磁帶的讀取速度要慢得多。但成本卻也低得多，1 TB 容量的移動硬碟售價約為 50 美元，相同容量的磁帶的價格僅需 5 美元。▲ 1951 年磁帶首次用於電腦數據儲存。而且磁帶比硬碟要耐用，一般硬碟的壽命不超過 10 年，每隔幾年就要復製到新硬碟中，海量數據複製不止耗時，而且還容易丟失數據，而磁帶則可以保存數十年。此外在使用過程中磁帶只需要插在機械磁帶庫的插槽中，不需要耗電，也節省了不少電力成本，要知道 2025 年全球數據中心的電費將會超過百億美元。對於很多公司來說，數據儲存的安全性往往是重要的。因為磁帶不安裝驅動就無法訪問，這種離線狀態隔絕了駭客和網路攻擊，不容易丟失和被篡改。2011 年，Google 的 Gmail 因為一次更新中的 Bug 意外刪除了四萬多個帳戶的郵件，雖然 Google 一直有在多個數據中心用硬碟儲存數據副本，但仍有部分數據無法恢復。所幸這些數據同時也有備份到磁碟裡，才得以恢復所有數據。（Source：pixabay）因此除了科技公司，不少對於數據安全性有較高要求的企業和機構其實也還在用磁碟儲存數據。比如銀行、保險公司、國家檔案館，以及科研機構，其中就包括美國國家航空航天局（NASA）。但磁帶並不是因為安全和成本而犧牲效率的數據儲存載體，磁帶技術的發展已經超出很多人的想像。Sony 在 2014 年利用自主開發的濺射薄層沉積技術，將 7.7 奈米的極細磁顆粒鋪設在磁帶上，實現了高密度磁儲存，儲存容量可以達到 185TB。▲ IBM 容量 330TB 的磁帶。IBM 在瑞士蘇黎世有一個專門的研究團隊來負責推進磁帶技術，據團隊科學家 Mark A. Lantz 介紹，IBM 在 2017 解決了每平方英寸（1 平方英寸 = 0.00064516 平方米）儲存 201 千兆字節的難題，並透過引進 Sony 的濺射薄層沉積技術，將單盒磁帶的容量提升至 330 TB。更重要的是，磁帶的儲存容量已經以每年 33% 的速度增長了多年，而且並沒有放緩的跡象。訊息儲存行業協會（INSIC）預測 2025 年磁帶儲存密度能達到每平方英寸 91 GB，到 2028 年將突破每平方英寸 200 GB。而硬碟的磁錄密度增長速度卻已經降到了 10~15%，因為當硬碟的儲存密度達到一定極限後，要再縮小磁性顆粒大小，就難以保持磁性穩定，這就是所謂的超順磁極限（superparamagnetic limit）。根據 IDC 的數據，網路上的大數據正以每年 30%~40% 的速度增長，而目前硬碟容量增長的速度不到大數據增長速度的一半，磁帶卻可能成為遵循摩爾定律的最後一種資訊技術。正如上文所述，企業級的數據儲存設備至少要兼顧下面這些因素：成本、安全、耐用和儲存密度。那麼除了磁帶，我們真的沒有別的選擇嗎？只能說，現階段磁帶是性價比最高的大數據儲存介質之一，但很多廠商也一直在研究新的儲存技術。比如硬碟廠商希捷科技和威騰電子開發出的熱輔助磁記錄技術（HAMR）和微波輔助磁記錄技術（MAMR），就有望讓硬碟打破超順磁極限。這兩種技術分別透過雷射和微波來降低介質的矯頑力，在超高密度的數據存儲中時保證足夠的穩定性。但這兩種技術都還未完全成熟，需要更多時間才能完全商用。另外一種可能像磁帶一樣被忽略的就是光儲存技術，CD 和 DVD 都是光儲存介質的一種。但過去的 CD 容易老化，同時由於衍射極限的限制（可以看做光碟裡的超順磁極限），儲存密度也十分有限。（Source：pixabay）但藍光光碟改變了這一切，據華錄光存儲研究院行銷中心副總經理胡冰介紹，藍光光碟同樣具有可靠穩定和使用壽命長的特點，使用壽命能達到約 50 年，單張藍光光碟的容量已達 500 GB，未來有望突破 TB 級。▲圖片來自：ssdfans同時藍光儲存對溫度等環境溫度要求較低，不需要空調冷卻系統，這大大降低了成本。Facebook 的數據中心就採用了藍光儲存，與硬碟相比節省了超過一半的成本，耗電量則降低了 80% 以上。微軟最近曝光的 Project Silica 專案其實也基於光儲存技術，是透過飛秒激光技術（一種以脈衝形式發射的雷射，常用於近視矯正手術）在一塊玻璃上形成一個奈米尺度光柵層結構，並產生不同深度和角度的變形，有點像刻錄光碟，不過密度更高也更複雜，一塊 2 毫米厚的玻璃可以包含一百多個數據層。目前微軟已經和華納兄弟公司合作，成功將 1978 年的《超人》電影母帶儲存在一塊 75×75×2mm 的玻璃中，並透過機器學習對於玻璃中的數據進行了非順序的讀取，只不過讀取速度還有待提升。跟光碟不一樣的是， Project Silica 的數據是儲存在玻璃內部而非表面，因此數據不會因為玻璃磨損而丟失。研究人員將這種「玻璃光碟」放進攝氏 500 度的烤箱、用微波爐加熱、廢水煮泡，甚至用鋼絲擦洗後，數據依然能順利讀取。雖然這項技術仍處於初期階段，但英國微軟劍橋研究院的實驗室副主任表示，這種「玻璃光碟」可以持續使用上千年。此外玻璃對溫度和濕度也沒什麼要求，這能大幅降低數據儲存的成本。實際上「玻璃光碟」並不是微軟的首創，早在 2016 年英國南安普敦大學成功用類似的技術將數據編碼到玻璃中，可以承受攝氏 1000 度高溫，號稱在常溫下壽命接近無限，即便在攝氏 190 度下也可使用 138 億年，要知道地球的歷史也才大約 46 億年。值得一提的是，微軟的 Project Silica 專案正是和南安普敦大學合作開發的，這種玻璃光碟又被稱為 5 維光碟，由奈米結構的三維，再加上整體尺寸和方向構成。同等尺寸的玻璃光碟儲存容量是藍光光碟的 3,000 倍。如果成功，真的可能像南安普敦大學研究人員所說的，開創一個數據永久儲存的新時代。數據儲存領域裡一個更大膽的設想，是生物質硬碟，就是將資訊儲存在 DNA 中。DNA 是如何儲存數據的？其實原理不算複雜，所有電腦數據都是以 0 和 1 組成的二進制數儲存和運算的，而 DNA 儲存技術則是用四種鹼基來代替 0 和 1 ，將數位信號轉化為化學信號。2017 年，哈佛大學醫學院就利用 CRISPR DNA 編輯技術，將一張賽馬的動圖錄入大腸桿菌的基因組中，並以超過 90% 的準確率讀取出來。近幾年也出現了不 少探索 DNA 儲存技術的創業公司，前段時間新創企業 Catalog 宣布將維基百科英文版一共 16G 的所有文本儲存在一個 DNA 分子中，透過一台超大型 DNA 書寫器完成，數據寫入速度能達到 4 MB / s 。▲ 裡面就是儲存了 16G 維基百科的 DNA。而另一家叫做 Twist Bioscience 的生物科技公司，是目前全球最大合成基因的供應商之一。據其創始人 Emily Leproust 介紹，該公司一粒膠囊中的 DNA 可以儲存相當於整個 Facebook 數據中心的數據。目前 Twist Bioscience 已經向客戶推出 DNA 儲存的服務，但價格卻很感人。儲存 12 MB 數據的價格就高達 10 萬美元，但 Emily Leproust 表示未來這一價格將降到 10 美分。2016 年哈佛大學在學術期刊 Nature Materials 發表了一項關於 DNA 儲存技術的研究成果，指出 DNA 的儲存密度遠超目前任何一種儲存介質，經過換算，1kg 的 DNA 就能儲存全球一年產生的數據。但 DNA 儲存目前還遠不是理想的數據儲存技術，除了昂貴的成本，由於 DNA 儲存的數據只能透過測序來讀取，讀寫速度非常緩慢。有人計算過如果要將 2017 年全球產生的 16 ZB 數據儲存到 DNA 中，需要花費 40 億年。今年年初微軟首次實現了全自動 DNA 訊息儲存，讓 DNA 儲存技術從實驗室邁向商業化更進了一步，但僅僅是編碼「hello」五個字母，從轉換到讀取就要花費 21 小時，同時讀取的準確度也有待提高。由此可見，雖然 DNA 儲存技術確實有可能徹底解決全球數據儲存的問題，但這個未來還有一段不短的距離。隨著各種技術成熟，人類正在追求訊息儲存在時間和空間兩個維度上的極致：超高的儲存密度和永恆的儲存時間。沒有人知道這能否實現，因為沒人能活到永遠，人類最早的文字紀錄，也只是 5,200 年前蘇美爾人留下的楔形文字，然而網路誕生僅僅 50 年，50 年前的數據有多少至今仍保存完整呢？在科幻小說《三體》中的未來世界裡，即便一粒米大小的量子儲存器就可以放下一座大型圖​​書館的數據，但最多也只能保存 2,000 年。最後人們發現把訊息儲存 1 億年的唯一可行方法，就是「把字刻在石頭上」。（本文由 愛范兒 授權轉載；首圖來源：shutterstock）科技新知，時時更新我的最愛趕快加入最愛頁面Facebook成為我們的小粉絲GOOGLE加入我們一起討論RSS即時更新新知\n\r\n© 2013-2019 TechNews Inc. All rights reserved.  | \n關於我們 |  使用條款 | 隱私權政策 | 著作權與授權轉載 | 語系： TW   EN ",
        "\n         現在就該為SAS、SATA敲喪鐘了嗎？ ": "首頁 » 儲存技術 » 現在就該為SAS、SATA敲喪鐘了嗎？NVMe介面由於獲得All-Flash儲存陣列採用而快速發展，但SAS和SATA也還能滿足許多SSD工作負載，如今就要宣告SAS和SATA終結還為時過早…根據最近的一份市場報告預測，NVM Express (NVMe)介面可望在全快閃(All-Flash)儲存陣列系統中佔據優勢，但這並不表示現在就該為SAS (序列式SCSI)和SATA (序列式ATA)硬碟互連技術敲響喪鐘。過去十年來，NVMe快速崛起並擴展成為標準，包括NVMe Over Fabric，最主要的原因在於它能夠充份地釋放NAND Flash固態硬碟(SSD)的性能。根據IHS Markit的《資料中心儲存設備市場追蹤》(Data Center Storage Equipment Market Tracker)報告，2019年第二季All-Flash陣列儲存市場較去年同期(QoQ)下滑，但基於All-Flash NVM硬碟的類別則有所增加。該研究公司的報告並指出，基於快閃記憶體(Flsah) NVMe硬碟的新類別——性能最佳化陣列(performance-optimized array)在該季的營收增加，而基於SAS硬碟的較大類別——All-Flash性能陣列的營收則下滑。\nAll-flash NVMe儲存陣列市場起飛：2019年第二季All-flash陣列儲存市場QoQ下滑，但基於NVMe硬碟的All-flash陣列市場持續成長。（來源：IHS Markit）\nAll-flash NVMe儲存陣列市場起飛：2019年第二季All-flash陣列儲存市場QoQ下滑，但基於NVMe硬碟的All-flash陣列市場持續成長。（來源：IHS Markit）那麼，SAS和SATA的長期發展前景如何？ IHS首席分析師Dennis Hahn在接受《EE Times》的電話採訪中表示，對於All-Flash儲存系統，由於NVMe介面標準已迅速在伺服器得到證實，因此，NVMe SSD正加速用於All-Flash陣列中。他說：「SAS實際上是基於旋轉磁碟而設計的。」然而，他說，那些旋轉磁碟也部份解釋了為什麼SAS繼續被用於伺服器中作為SSD的介面，因為許多客戶仍然想混搭使用。「客戶希望在同一系統中混合使用硬碟，而不必在其後添加不同的硬體。此外，還有許多人仍然對於NVMe的耐用性有所顧慮。」隨著時間的進展，NVMe當然會變得更穩健耐用，但Hahn表示，SAS仍然滿足許多用戶將其用於後端作為硬碟互連的性能需求。長遠來看，NVMe的吸引力在於其端對端的能力，可在後端和前端儲存系統互連中取代SAS和SATA，例如以NVMe Over Fabric和NVMe over TCP取代iSCSI和光纖通道(Fiber Channel)。他說， NVMe over TCP很快地將會完全取代iSCSI。同樣地，大多數人都認為SATA再過不久將會劃下句點。「現在它因為擁有很大的市場量而具有成本優勢。但是隨著時間的流逝，這種優勢似乎很快就會消失。因為它的確存在性能上的劣勢。以硬碟互連來看，其性能甚至低於SAS。」關於「SATA已死」的種種預測已經持續一段時間了，但是美光科技(Micron Technology)決定繼續支持這一互連介面。該公司最近推出了5300 3D TLC NAND企業級SATA硬碟，專為資料中心和雲端環境所需的讀取密集型混合用途而設計。美光科技SSD資深產品經理Matt Shaine說：「我們目前仍看到SATA的強大優勢，而且這項業務當然還不至於下滑。」儘管就整體市場位元成長而言，美光看好NVMe的未來前景，但SATA仍然滿足許多工作負載和預算的需要。\n藉由在全球部署數以百萬計的SATA插槽，美光科技推出了新型5300 3D TLC NAND企業級SATA硬碟，反映出客戶希望易於整合與熟悉度。（來源：Micron Technology）\n藉由在全球部署數以百萬計的SATA插槽，美光科技推出了新型5300 3D TLC NAND企業級SATA硬碟，反映出客戶希望易於整合與熟悉度。（來源：Micron Technology）他說，易於整合和熟悉度對於客戶而言同樣重要，美光也已在全球部署數百萬個SATA插槽了。「相較於針對NVMe的回應，我們並未聽到太多客戶質疑SATA的問題。」Shaine說，NVMe就像是路上閃閃發亮的法拉利新車。儘管有些客戶開始轉移至該新平台，但是SATA仍然是值得信賴的替代方案，因為它的規格提供了足夠的性能，因而可根據客戶的特定需求而涵蓋廣範的工作負載。即使大部分的儲存需求都轉移到NVMe了，開機部分最好還是保留在SATA上。「這是一個混合硬碟的概念。」Shaine說，企業客戶多半都有點保守，而且總是按照他們所熟知的去做。任何新技術在他們大瞻一試之前都需要得到驗證。他說：「但是，同樣地，總有一部份的市場並不一定需要更多性能，」例如，工業客戶就是其中之一。Shaine說，SATA客戶通常直接汰換產品，大多數情況下，美光並未收到對於新功能的要求。「如果是伺服器更新，那麼客戶期望新硬碟的性能至少要達到與其汰換掉的一樣好或盡可能與其接近。」然而，美光科技看到客戶對於硬碟的安全性越來越感興趣。因此，針對該公司最近推出的5300，即根據客戶的市場需求增加了對於TCG Opal的支援。同時，Shaine說，SATA硬碟的平均容量在一段時間內相對持平，美光科技的大多數客戶都希望持續看到這一介面標準的長期發展藍圖。「在可預見的未來，SATA還不至於消失。我們認為這一市場仍將在接下來的幾年保持穩定。」美光正專注於為SATA客戶提供服務並推動NVMe業務的發展，而Western Digital (WD)則持續看到對於SAS的大量市場需求。繼連續兩季發佈資料中心級96L NVMe SSD及其支援OpenFlex的NVMe over Fabrics平台後，該公司推出了第六代Ultrastar SAS SSD。Western Digital企業裝置部門總監Eric Pike表示，全球企業儲存客戶仍在使用SAS以加速其具任務關鍵性的工作負載，並支援不斷增加中的資料量。Ultrastar DC SS540 SAS SSD具有多種耐用性SKU，適用於Tier-0企業級儲存、高性能運算(HPC)以及軟體定義的儲存(SDS)環境。\nWestern Digital的第六代Ultrastar SAS SSD適用於仍希望以SAS加速其關鍵工作負載企業儲存客戶，同時支援不斷增加的資料量。（來源：Western Digital）\nWestern Digital的第六代Ultrastar SAS SSD適用於仍希望以SAS加速其關鍵工作負載企業儲存客戶，同時支援不斷增加的資料量。（來源：Western Digital）「大家都在開發NVMe產品，而且已經持續多年了。但是，眾所周知，在企業界，過渡到新世代通常需要經過一段相當長的時間。」在petabyte級容量的基礎上，仍然有一個非常健全的SAS市場，就像SATA市場仍然有發展空間一樣。儘管NVMe的成長速度更快，但Pike表示SAS的企業市場十分穩定，部分原因在於SAS對客戶而言已經夠用了。而當他們試著過渡到新介面時，也很擔心可能置關鍵資料於風險中¬¬——這些情況可能使管理大型資料中心和大型IT基礎架構的人員夜間也無法安心入睡。他說：「對於客戶來說，SAS一直是非常穩定且功能強大的解決方案，他們想要的是保有這種穩定性。」Pike表示，儘管許多組織都希望為NVMe (包括NVMe Over Fabric)做好準備，但有些工作負載真的不必要該介面標準所提供的更高效能或功能組合。例如，SAS仍用於附加伺服務器連接的環境中，而NVMe也還在為建構其基礎架構而奮鬥。他說：「我們看到客戶正開始導入NVMe系統，對於他們來說，這是擁有這些NVMe新系統的首要任務。我們絕對相信NVMe的未來前景，但是為了服務在SAS的更大部份業務，仍然必須不斷地為其推出具有新技術和可擴展性的新產品，而又不至於讓還沒打算跟進的客戶多付出任何成本。」IHS的Hahn表示，伺服器遲未能採用NVMe的原因在於用戶仍對其有所疑慮以及其習於SAS使用的舒適度，然而，諸如機器學習和人工智慧(AI)等新興的工作負載正推動NVMe市場以及更高的資料處理性能。「現在，儲存系統業界廠商們都希望積極投入這一領域，他們可不想這個快速崛起的市場排除在外。」編譯：Susan Hong(參考原文：SAS, SATA Still Satisfy Many SSD Workloads，by Gary Hilson)\n   You must Register or\n   Login to post a comment.\n",
        "美軍核武系統終於更新用了 55 年的 IBM 電腦、擺脫 8 吋磁碟片！ ": "\n隨時關注最新創業、科技、網路、工作訊息。\n你能相信嗎？美國很多政府單位仍在使用已經五十歲的古董級電腦，包括全世界最多核彈頭的美國核武部門！是的，跟好萊塢電影賦予的先進科技形象恰恰相反，事實上操作核彈的系統，也就是美國國防部所屬美國戰略司令部的「戰略自動化命令控制系統」（Strategic Automated Command and Control System，簡稱 SACCS），一直以來是在 1970 年代開發、 1976 年推出於市場的 IBM Series/1 電腦上運行（如本文首圖所示），並使用八吋軟碟片儲存資料，當時的美國總統是福特。SACCS 的作用是向核武部隊傳送、接收緊急行動訊息以及發射武器的指令，調控核武部隊的作戰功能，如洲際飛彈、核彈和支援空中加油的飛機。此消息最早在 2014 年由老牌深度新聞專題節目《60分鐘》（60 Minutes）完整揭露，此節目自 1968 年起由哥倫比亞廣播公司（CBS）製播至今，叫好叫座，更拿過 138 座艾美獎（Emmy Award）及 20 次皮博迪獎（Peabody Awards）。其後，2016 年 5 月美國政府責任署（US Government Accountability Office, GAO）發布「資訊科技」報告，在封面就指出「聯邦政府應正視老舊的大型資訊系統」（Federal Agencies Need to Address Aging Legacy Systems）。此報告中羅列出的老舊政府電腦系統，使用年次居然是從 56 年至 31 年不等！該報告顯示， 2015 年美國聯邦政府的資訊科技相關開支至少 800 億美元，用於電腦系統「操作與維護」費用比「開發、現代化和強化」經費的三倍還多，前者佔了 612 億美元、後者僅 192 億美元。美國財政部用的資訊系統，仍使用「組合語言」（assembly language），報告中直指「這是一種低階且相當難寫又難維護的程式語言」（assembly language code—a low-level computer code that is difficult to write and maintain）；社會安全主管機構使用的程式語言則是「COBOL」—— 1959 年問世的、世界上最早的高階程式語言，已被資訊界視為過時的語言多年。當時美國國防部就回應，該資料儲存系統及終端機等，預計會在 2017 財政年度的尾聲做升級（美國聯邦政府的 2017 財政年度是 2016 年 10 月 1 日至 2017 年 9 月 30 日），但直到今年 6 月才真正執行完畢。美國一家資訊專業的媒體《 C4ISRNET 》前幾天發出報導指，核武系統 SACCS 負責人 Jason Rossi 中校受訪說，「今年 6 月，戰略指揮部的 8 吋磁碟片已經被替換成了『高度安全的固態數位儲存解決方案』」，但沒有說明是哪種固態儲存方式，亦未說明其他電腦組件的更新狀態。Rossi 中校曾經在先前的訪問對媒體表示，「我常跟人開玩笑說，這是空軍最古老的 IT 系統。但是，資訊安全的時代已經到來。你不能破解沒有 IP 地址的東西。這是一個非常獨特的系統，它既舊又非常好。」此系統並不連接網際網路。但實際上，要維護五十幾歲的大型資訊系統並不容易，要使 SACCS 保持正常運行，大多數現役維護人員都太年輕且經驗不足，新時代的資訊相關訓練並不重要，需要的反而是課本上快速帶過的電路、二極管和電阻，以及幾乎沒有人會的焊接技術。一般來說電子產品都是以換代修，即使不是整機更換，也會是把壞掉的零件丟棄、換上新的，但 SACCS 備用零件已經都找不到了，所以它所有的零件都得修，比如說，維護人員得在顯微鏡下連續工作數小時，以更換遍及整個電路板的銅線。核稿編輯：Mia分享文章或觀看評論從事品牌形象與事業發展，對美感品味與規則的各種堅持來自空間設計背景的訓練。住過的城市有高雄、台南、台北、紐澤西、紐約（依順序），喜歡透過閱讀、生活與旅行來觀察城市和人，因此設有專頁「蜜雅的第一世界問題集」。VeryBuy非常勸敗\n臺北市.台灣Omlet Arcade 美商歐姆雷特\n臺北市.台灣奔騰網路科技有限公司\n臺北市.台灣© 2009-2020 INSIDE 硬塞的網路趨勢觀察 ",
        "【儲存管理平臺：NetApp Active IQ】結合雲端平臺與AI技術，降低用戶環境管理成本 ": "NetApp產品統一管理平臺，提供集中監控、自動診斷、儲存資源分析、預測與升級建議為求降低企業儲存環境的維運成本，改善管理效率，基於雲端環境、以AI技術為支撐的雲端儲存管理平臺，可說是近年來儲存管理領域的一大潮流，可以透過雲端提供無遠弗屆的用戶環境集中監控能力，以及自動診斷、自動通知異常狀態的自動化管理能力，還能在AI的幫助下，提供用戶使用狀況的分析、預測，與升級與組態調整的自動化諮詢與建議功能。這類平臺一開始是從Nimble Storage、SoldFire等新創廠商先行投入，到了現在，幾乎所有一線儲存大廠都擁有了這類服務，如Dell EMC的CloudIQ、HPE的InfoSight、IBM的Storage Insights，Hitachi的HIAA，Pure Storage的Pure 1，以及華為的eService等，我們這裡介紹的NetApp Active IQ也是其中之一。最初，Active IQ原是SolidFire為其SF系列全快閃儲存陣列，於2014年推出的雲端集中管理平臺，當NetApp於2015年併購SolidFire後，Active IQ也跟著轉到NetApp旗下，再結合NetApp自身的AutoSupport服務，擴展成為橫跨NetApp產品線的統一管理平臺。目前的Active IQ平臺可支援SolidFire SF全快閃儲存陣列、FAS/AFF系列儲存陣列、E/EF系列儲存陣列、StorageGRID物件儲存設備，也能支援軟體定義的ONTAP Select儲存裝置、雲端版Cloud Volumes儲存裝置、NetApp HCI超融合系統，以及先前稱為AltaVault的Cloud Backup等產品，幾乎涵蓋了NetApp旗下所有主要產品線。Active IQ是NetApp的雲端管理平臺，可以支援NetApp旗下所有主要產品線，提供雲端監控、資源分析分析，以及組態升級建議等服務。除了標準的網頁介面外，Active IQ也有手機App版本可用。從雲端管理NetApp全線產品只要用戶擁有NetApp的主動支援合約（Active Support），然後在儲存設備上啟用啟用AutoSupport功能，Active IQ平臺便能與用戶的儲存設備連結。其中FAS/AFF系列的AutoSupport功能，是透過ONTAP作業系統的CLI指令來設定；其餘NetApp產品，則直接透過網頁控制臺就能啟用AutoSupport功能。開始AutoSupport後，用戶儲存設備便會持續將設備組態、運行狀態、日誌與效能等資訊，上傳到NetApp的Active IQ雲端資料中心進行匯整，然後透過雲端管理控制臺，向用戶提供一系列服務，包括系統監控維運，以及分析預測與諮詢這兩大面向：（1）系統監控維運服務：藉由匯整與檢測用戶端儲存設備回傳的系統參數，提供雲端集中監控，自動化系統健康診斷、異常狀態通報等監控等功能，還能針對故障事件，自動開立備品更換報修案件，大幅簡化與加快報修流程。（2）分析預測與諮詢：利用持續累積的用戶端設備運行歷史資料，在AI技術的支援下，提供用戶儲存環境資源的使用分析與預測，以及軟、硬體組態升級調整建議等功能。另外Active IQ也提供了配合手機環境的App軟體版本，包含iOS與Android兩種平臺，管理者無論身在何處，都能透過手機登入Active IQ，隨時檢視自身儲存環境的狀態。Active IQ的3大效益藉由結合雲端平臺，以及基於AI技術的分析、預測功能，與自動化的管理與諮詢服務，Active IQ這類管理平臺可為用戶提供3大效益。首先，是透過雲端，提供不受環境限制、無遠弗屆的集中監控能力。用戶端的管理者無論身在何處，只要能連上雲端，就能藉由Active IQ監控自身儲存環境的狀態，大幅提高了用戶管理作業的彈性。其次，是提供自動化、主動式的儲存環境維運支援服務。Active IQ藉由7x24小時持續地收集用戶儲存環境的運行資訊，可從中診斷用戶端系統的健康狀態，並在發現異常時自動觸發維運支援服務，除了通報用戶外，也能主動建立對應的報修案件，並連繫NetApp原廠與協力廠商，幫助用戶及時處理異常現象，從而大幅加快問題的解決時間，提高用戶系統的正常可用時間。第三，透過Active IQ後臺系統的機器學習等AI技術，扮演類似專家系統的角色，利用收集到的用戶設備資訊，分析用戶使用行為，然後預測未來需求，從而為用戶的調整組態或軟、硬體升級需求，提供自動化的諮詢與指引，不僅可以降低對於儲存廠商人力諮詢的依賴，而且還更方便。 Active IQ儲存管理平臺的基本架構Active IQ的基本概念如同其他雲端AI儲存管理平臺，Active IQ運作也可分為3個階段：（1）收集資訊：利用AutoSupport功能，將儲存設備的組態、系統版本與運行日誌等資訊，上傳到NetApp資料中心。（2）匯整與分析：NetApp資料中心透過Active IQ資料庫收集用戶端資訊後，利用AI、機器學習等技術，彙整與分析用戶設備運行資料。（3）提供服務：透過雲端控制臺介面，向用戶提供設備監控，儲存資源分析預測、診斷與問題警示，並視用戶需求提供建議與指引。（資料來源：iThome整理，2019年9月）如Active IQ這類雲端儲存管理平臺，可以看作是phone home功能的進化發展。過去的phone home，只是在背景將用戶端設備的特定訊息發送給供應商，讓供應商可以掌握用戶端情況。而Active IQ這類平臺則在phone home的基礎上，進一步結合雲端平臺與AI技術，來為用戶提供加值的管理服務。Active IQ的基礎，是透過AutoSupport資料回傳機制，收集用戶端設備運行資料。視設備款式不同，AutoSupport收集的資料型式也有所差異，不過基本上都會包含設備型式（型號、系統版本等）、組態（磁碟區設定等）與運行日誌（系統服務日誌、容量與效能耗用統計等）這3大類。Active IQ資料中心收到AutoSupport回傳的用戶端設備資料後，便能視資料類型分別組織與處理，並套用AI與機器學習模型分析。而經由Active IQ處理後的資料，再透過雲端控制臺，為用戶提供狀態監控、檢視、異常警示與處理、資源使用分析與預測，以及組態調整或升級建議等一系列服務。Active IQ的資安防護措施由於Active IQ的基礎，是藉由AutoSupport上傳用戶端設備資料，由此衍生的疑慮，便是資料上傳的安全性，上傳的資料可能外洩，而資料上傳的通道也可能成為入侵的管道，所以NetApp也在不同環節採取了防護措施。首先，用戶可以選擇遮蔽部份AutoSupport上傳資訊，刪去其中的識別性資訊（如內部網址、裝置名稱等），只上傳非識別性的環境運作資訊（日誌與參數資料等）。其次，AutoSupport的資料上傳可使用加密的HTTPS協定。第三，NetApp用於Active IQ服務的資料中心，擁有ISO/IEC 27001認證的資安防護，有助於保護用戶上傳的資訊不至外洩。Active IQ的資料傳輸AutoSupport的資料上傳可支援HTTPS或SMTP協定，將訊息發送到NetApp的Active IQ資料庫、用戶端管理者，以及對應的協力廠商。為確保資料安全，NetApp建議採用加密的HTTPS協定。（圖片來源／NetApp） Active IQ的雲端控制臺總體儀表板提供了用戶端NetApp儲存環境的總體狀態，整個頁面由上到下分為4個欄位，最上面一排列出了高風險事件、警示與服務合約到期日等資訊；中間欄位左方是整個儲存環境的資產統計，右方是容量預測資訊；最下面2個欄位則提供支援合約更新、儲存效率統計、系統風險評估與建議、追蹤案件等資訊。雲端管理控制臺是用戶存取Active IQ所有應用功能的入口，Active IQ的所有服務，都是透過雲端控制臺向用戶提供。Active IQ經由AutoSupport所收集到的用戶端儲存設備資訊，經分析、彙整後，再透過雲端控制臺的網頁式介面，以圖形化儀表板方式呈現給用戶。而Active IQ後臺提供的各式分析與自動建議功能，也是透過雲端控制臺介面來操作。除了被動接收Active IQ的資訊外，用戶也能針對升級或其他需求，透過Active IQ雲端控制臺通報NetApp原廠。Active IQ提供了總體儀表板與系統儀表板兩種基本控制臺介面。登入後的Home首頁，便是總體儀表板，可以從這個單一檢視畫面，總覽整個用戶端的NetApp儲存環境狀態，包括系統健康狀態、容量預測與空間效率、效能與保謢狀態，以及支援服務合約的到期日，與系統升級建議訊息等資訊。用戶也能將這些資訊輸出為PDF或CSV格式的報表。若用戶想要得知個別儲存系統的狀態，則可切換到該系統的系統儀表板（System Level DashBoard），檢視個別系統的組態資訊、健康狀態與容量效率等訊息，不過Active IQ目前能檢視的資訊，還只有儲存設備層即，不像HPE與Pure Storage的同類平臺已能檢視到VM層級資訊。由於Active IQ可以橫跨支援NetApp旗下多個產品線，而不同產品的架構、規格與功能都有所差異。所以Active IQ在對應不同NetApp產品時，所提供的功能與畫面也有所區別。例如E與EF系列是傳統的雙控制器儲存陣列，也沒有重複資料刪除功能，所以在Active IQ的控制臺介面中，便沒有ONTAP系統的Cluster相關頁面，在計算容量效率時，也沒有考慮重複資料刪除功能。除了標準的網頁介面外，Active IQ也提供了iOS與Android兩種行動平臺下的行動App控制臺。行動App版的Active IQ控制臺，也提供了檢視整個儲存環境到個別系統的狀態資訊，以及分析、自動建議等功能，可以讓用戶更容易地使用Active IQ的服務。系統層級儀表板提供儲存環境中個別系統的資訊，由上到下分為3個欄位，最上面一欄是高風險事件、警示、升級建議與支援合約狀態；中間欄位左邊是系統組態資訊，右邊是容量預測資訊；下面欄位則是系統風險與儲存效率資訊。App行動儀表板行動App版的Active IQ主頁面，是總覽整個系統狀態的儀表板，包含了資產統計、高風險事件、升級狀況與已開立案件等資訊，可從中點選進入個別系統的頁面，並啟用升級分析建議等服務。 Active IQ的分析與自動建議服務多樣化的儲存資源分析工具Active IQ透過總體與系統層級儀表板介面，提供了容量預測、系統風險評估、以及升級建議等工具，可幫助用戶解決容量耗用、系統健康狀態與軟體升級等問題。類似其他同類平臺，藉由用戶端持續上傳的系統資訊，Active IQ能夠分析與預測用戶端的儲存資源使用狀態，並為用戶端提供升級建議。Active IQ可透過稱作Community Wisdom的AI輔助機制，每天從全球30萬臺設備上收集的超過200萬個資料點，在NetApp資料中心利用機器學習等分析方法，建立針對不同應用情境的最佳實作模型，為用戶提供諮詢。Active IQ的自動化分析與建議功能，可大致分為3個類型：（1）系統風險評估與建議：依據自動化診斷結果，在總體儀表板介面中提供了高風險事件警示，以及系統風險預測。Active IQ可針對診斷出的高風險事件，分別提出影響評估，以及解決辦法的建議。（2）容量預測：預測用戶的儲存容量使用情況，並列出已經達到90%容量耗用、或將在1～6個月內達到90%容量耗用的系統，用戶還可以在容量預測工具頁面中，向NetApp原廠發出擴充容量需求的申請。（3）系統擴展與升級建議：透過控制臺頁面的升級建議（Upgrade Advisor）功能，為個別系統產生系統軟體的升級計畫。針對NetApp HCI超融合系統，還能提供整個超融合應用環境的擴展升級規劃，包括具體的升級型號、數量等，然後向NetApp原廠與協力廠商發出需求申請。自動化系統擴展建議搭配NetApp HCI超融合系統時，Active IQ提供了自動化的擴展建議工具功能，可依照用戶設定的升級目標，產生具體的升級組態建議，包括擴展的超融合伺服器型號、數量等具體指引資訊。系統健康趨勢與風險分析與建議透過Active IQ控制臺的健康趨勢分析工具（Health Trend），可以追蹤關於系統健康、資安效能等方面的風險。而透過風險建議工具（Risk Advisor），則可針對風險事件逐議列出評估結果，以及解決方法的建議。 產品資訊NetApp Active IQ●原廠：NetApp(02)8729-5000●建議售價：廠商未提供●支援儲存產品：SolidFire SF系列快閃儲存陣列，FAS/AFF系列儲存陣列、E/EF系列儲存陣列、StorageGRID物件儲存系統，Cloud Backup、Cloud Volumes與NetApp HCI●主要服務：儲存設備雲端集中監控,自動化系統健康診斷,故障自動報修, 儲存資源使用分析與預測,自動化升級建議2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29"
    },
    "Q5": {
        "升級vCenter管理平台　無痛變更命名及網路組態 ": "熱門搜尋 : 熱門搜尋 : 盤點vSphere與vSAN最新6.7 Update 3功能 在2019年8月13日時，VMware官方正式發佈全新vSphere 6.7 Update 3版本，同時VMware SDDC軟體定義資料中心內，各項解決方案版本也同步推升至Update 3版本，例如vSphere ESXi 6.7 Update 3虛擬化平台、vCenter Server 6.7 Update 3管理平台、vSAN 6.7 Update 3超融合解決方案。值得注意的是，企業組織的資料中心倘若仍採用舊有的vSphere 6.0版本，例如vSphere ESXi 6.0、vCenter Server 6.0、vCenter Update Manager 6.0、vSphere Replication 6.0/6.1等等，以及對應到vSAN為6.0、6.1、6.2版本，都將於「2020年3月12日」正式進入EOGS結束標準支援階段，如表1所示。因此，企業應儘快準備版本升級程序至vSphere 6.5或6.7版本，倘若在2020年3月12日進入EOGS結束標準支援階段時仍無法升級版本的話，則應購買「延伸支援」（Extended Support）服務，最多可以延長支援服務至2022年3月12日。本文將深入剖析最新vSphere 6.7 Update 3和vSAN 6.7 Update 3版本亮眼新功能，以及實作演練vCenter Server 6.7 Update 3新增特色功能，變更vCenter Server FQDN和IP位址網路組態設定的部分。vSphere 6.7 Update 3新增特色功能接下來，介紹幾項vSphere 6.7 Update 3所新增的功能。VM虛擬主機支援多NVIDIA vGPU從最新的vSphere 6.7 Update 3版本開始，每台VM虛擬主機新增支援多個NVIDIA vGPU（GRID virtual GPU）特色功能，如圖1所示，以便因應VM虛擬主機處理圖形和運算密集的工作負載。舉例來說，採用這種類型的VM虛擬主機，將能夠最大化加快機器學習的運算速度。值得注意的是，如果採用vGPU技術的VM虛擬主機有vMotion遷移需求時，管理人員除了要確認vCenter Server和ESXi均採用最新的vSphere 6.7 Update 3版本之外，還必須在進階設定中加上「vgpu.hotmigrate.enabled = true」組態設定值，才能順利地針對採用vGPU技術的VM虛擬主機，進行vMotion線上遷移至別台ESXi虛擬化平台的動作。支援AMD EPYC Gen2處理器從最新的vSphere 6.7 Update 3版本開始，支援x86硬體伺服器採用新式AMD EPYC Gen2處理器，並且在後續的vSphere ESXi虛擬化平台版本中，針對AMD EPYC Gen2處理器的新式安全性，例如安全記憶體加密（Secure Memory Encryption，SME）、安全加密虛擬化（Secure Encrypted Virtualization，SEV），將有更全面的整合和支援。然而，目前企業和組織的資料中心內主流的x86硬體伺服器，大多採用Intel Xeon處理器，那麼管理人員該如何將原有運作於Intel Xeon處理器的VM虛擬主機，遷移至採用新式AMD EPYC Gen2處理器的VMware Cluster運作環境中呢？或許，有IT管理人員會說，可以嘗試啟用EVC（Enhanced vMotion Compatibility）機制為VM虛擬主機進行遷移，但事實上為VMware Cluster啟用EVC特色功能後，僅能針對「同一家廠商」，也就是僅能都是Intel或者都是AMD處理器的運作環境，如表2所示，並不支援Intel和AMD處理器混合運作環境。事實上，可以透過「冷遷移」（Cold Migration）的方式，如圖2所示，將原本運作於Intel Xeon處理器的VM虛擬主機，遷移至新式AMD EPYC Gen2處理器運作環境中繼續運作，並且透過冷遷移的特性，VM虛擬主機無須共享儲存資源，也可以將Datastore儲存資源進行遷移。下列便是採用冷遷移的執行步驟，分別加以說明：1. 在開始進行冷遷移執行步驟之前，先將來源端伺服器（Intel-Based）上欲進行遷移的VM虛擬主機「關機」（Powered Off）。2. 在準備執行冷遷移前，若VM虛擬主機採用64位元的作業系統版本，vCenter Server將透過CPU相容性機制，檢查目標伺服器是否支援64位元作業系統版本。3. 當遷移的VM虛擬主機包含儲存資源時，那麼vCenter Server會把該台VM虛擬主機的組態設定文件、NVRAM組態設定檔（BIOS設定）、vDisk虛擬磁碟等等，進行儲存資源遷移的動作。4. vCenter Server在目的端伺服器（AMD EPYC）中，註冊VM虛擬主機並執行「開機」（Powered On）的動作。5. 當冷遷移步驟執行完畢，vCenter Server會把來源端伺服器內的舊版本VM虛擬主機，執行刪除的動作。Skyline新式健康檢查機制在過去的版本中，管理人員透過vSphere Health和vSAN Helath健康檢查機制，除了能夠快速了解叢集的健康情況之外，在叢集發生問題時也能夠透過健康檢查機制快速排除故障。在後續的版本中，原有的vSphere Health和vSAN Helath健康檢查機制，將會併入新式的Skyline健康檢查機制中，並且推出更進階的Skyline Advisor健康檢查機制，以便支援更多的VMware產品，例如NSX-V網路虛擬化、Horizon虛擬桌面等等運作環境。如表3所示，簡要說明原有的vSphere Health和vSAN Helath，以及新式的Skyline健康檢查機制在功能性方面有何不同。可惜的是，由於新式Skyline Health健康檢查機制仍處於技術預覽階段，如圖3所示，所以在目前最新的vSphere 6.7 Update 3和vSAN 6.7 Update 3版本中仍未整合，VMware官方預計在下一個版本中才會提供整合。vSAN 6.7 Update 3新增特色功能在過去的vSAN超融合環境中，針對VM虛擬主機的工作負載和儲存資源部分，已經透過「儲存原則」（Storage Policy）的方式，輕鬆地幫助IT管理人員進行高可用和靈活管理。適用雲端原生環境的儲存資源針對新興的「容器」（Container）工作負載，在新版vSAN 6.7 Update 3運作環境中，已經透過vSphere CSI（Container Storage Interface）驅動程式與Kubernetes容器管理平台整合，如圖4所示，讓管理人員在管理容器的儲存資源的時候，就像過去管理VM虛擬主機的儲存資源一樣方便。因此，即使在vSAN超融合基礎架構環境中，同時運作VM虛擬主機和容器的混合型工作負載，在管理儲存資源方面，針對容器使用的「持續性磁碟區」（Persistent Volumes），管理人員仍然可以透過熟悉的vSphere HTML5 Client管理介面，為容器提供持續性的可用儲存資源，不會因為容器短暫的生命週期，而影響到重要資料的儲存，如圖5所示。增強和簡化儲存資源使用資訊在過去的vSAN超融合運作環境中，針對儲存資源使用率資訊的部分都是以VM虛擬主機為主軸，然而，企業和組織新興的應用方式已經改變，除了VM虛擬主機外，還會搭配容器等工作負載。所以，vSAN針對儲存資源使用率的呈現方式進行增強，如圖6所示，例如透過不同顏色的方式讓管理人員更容易識別，並針對不同工作負載和用途的使用量進行呈現，以便管理人員更容易掌握儲存資源的使用情況和剩餘空間。舉例來說，倘若管理人員忽略剩餘儲存空間，造成「磁碟群組」（Disk Group）儲存空間占滿，vSAN將會暫停重新同步作業，以避免VM虛擬主機發生I/O中斷的情況。因此，管理人員應隨時注意儲存空間使用情況，並視需求考量是否增加vSAN節點主機至vSAN叢集。更智慧的I/O管理機制有效提升效能在新版vSAN 6.7 Update 3版本中，針對資料I/O管理機制採用更智慧的運作方式，能夠在同樣的vSAN超融合基礎架構內提供更佳的儲存效能。舉例來說，當vSAN從快取層級的寫入緩衝區中，將資料寫入至容量層級的時候，提供能夠預測的應用程式效能，除了降低資料寫入的延遲時間外，還增加資料吞吐量，以便減少重建工作任務的時間，進而為VM虛擬主機和容器等工作負載提供更佳的儲存效能，如圖7所示。vSAN Stretched Cluster支援WSFC共享磁碟過去的vSAN版本已經透過iSCSI運作機制，提供VM虛擬主機快速建立「Windows容錯移轉叢集運作」（Windows Server Failover Clustering，WSFC）環境，到了新版vSAN 6.7 Update 3版本，更支援SCSI-3 PR（Persistent Reservations）機制，達到應用程式無須中斷，即可動態調整iSCSI LUN儲存空間大小的增強功能。除了更全面支援WSFC容錯移轉叢集運作環境外，對於其他無共享儲存資源的叢集架構，例如Exchange CCR（Cluster Continuous Replication）、DAG（Database Availability Group）也都已經支援。此外，在新版vSAN 6.7 Update 3版本中，vSAN Stretched Clusters延伸叢集運作架構，也已經全面支援WSFC容錯移轉叢集運作環境，如圖8所示，因此企業組織可以透過原有的vSphere HA和DRS機制，達成Host Level和VM Level的高可用性服務，搭配vSAN Stretched Clusters延伸叢集和WSFC容錯移轉叢集機制，達成Application Level的高可用性服務，讓企業正式營運服務的SLA提升至另一個層級。行動監控vSAN叢集運作資訊在過去的vSAN版本中，當管理人員需要查看vSAN超融合基礎架構運作資訊時，必須透過桌上型電腦或筆記型電腦連結至vSphere HTML5 Client管理介面，才能夠查看vSAN運作資源。然而，在行動商務的風潮中，如此傳統的管理方式已經漸漸顯得不合時宜，所以VMware官方推出「vSAN Live Mobile Client App」應用程式，讓管理人員透過智慧型手機就能夠隨時隨地輕鬆且快速地查看vSAN運作環境資訊，包括vSAN叢集、健康情況、運作效能、儲存空間使用率等等。目前的vSAN Live Mobile Client App為1.0版本，管理人員的智慧型手機必須先確保能夠以VPN的方式存取vSAN叢集，並且在安裝好App應用程式連接至vCenter Server後，將下載和安裝連線憑證至智慧型手機內即可。此外，VMware官方將會在後續App版本，提供無須使用VPN的安全性連接方式。當管理人員為智慧型手機安裝vSAN行動App應用程式後，只要VPN安全連線建立完成，並通過vCenter Server身分驗證程序後，即可順利連接至vSAN叢集查看相關運作資訊，包含Info、Health、Performance、Capacity等四大項目，如圖9所示，讓管理人員方便透過行動裝置隨時查看vSAN叢集運作資訊。實作演練vCenter Server變更PNID近來管理人員特別需要的功能是，vCenter Server要能夠「變更」FQDN（Full Qualified Domain Name）和IP位址，這並不是指vCenter Server的VM虛擬主機名稱，而是vCenter Server當中的「PNID（Primary Network ID）」名稱，最新的vCenter Server 6.7 Update 3版本已經正式支援。為何管理人員會需要重新命名vCenter Server的FQDN呢？主要原因在於，每當升級vCenter Server版本，或者是從Windows vCenter Server遷移至Linux vCenter Server Appliance時，由於舊版的vCenter Server並不支援重新命名vCenter Server的FQDN，所以只能沿用舊有的FQDN或主機名稱，因此便會出現vCenter Server命名標準不符合公司政策的情況，同時也會造成名稱識別度上的困難。變更vCenter Server FQDN的前置作業在開始執行變更vCenter Server FQDN的動作之前，必須先確認運作環境是否已經符合要求。首先，必須採用最新的vCenter Server 6.7 Update 3版本，才能夠支援變更FQDN也就是PNID的動作，同時必須擁有SSO網域管理者帳號和密碼，例如Administrator@vsphere.local，並且應考慮下列事項：‧目前變更vCenter Server FQDN機制，僅支援採用「Embedded」運作模式的vCenter Server。‧在變更vCenter Server FQDN以前，先執行SSO網域中所有的vCenter Server的備份作業，以避免在變更過程中發生不可預期的錯誤時，能夠透過備份進行還原作業。‧在變更vCenter Server FQDN以前，必須在vCenter Server中先取消註冊其他產品，待vCenter Server FQDN變更完成後，再重新進行產品註冊的動作。‧在變更vCenter Server FQDN以前，先將vCenter HA運作機制摧毀，待vCenter Server FQDN變更完成後，再重新組態設定和啟動vCenter HA高可用性機制。‧採用舊有vCenter Server FQDN產生的SSL憑證，待vCenter Server FQDN變更完成後，必須搭配新的FQDN重新產生新的SSL憑證。‧倘若有採用Hybrid Linked Mode機制時，待vCenter Server FQDN變更完成後，Cloud vCenter Server必須重新建立Hybrid Linked Mode機制。‧當vCenter Server FQDN變更完成後，vCenter Server必須重新加入Active Directory。‧必須確認新的vCenter Server FQDN，具備正確的DNS正向解析和反向解析記錄。確認目前vCenter Server的FQDN變更vCenter Server FQDN前置作業準備完成後，首先連結至vCenter Server的VAMI（Virtual Appliance Management Interface）管理介面，在本文實作環境中URL為「https://vcsa67.weithenn.org:5480」，並以vCenter Server管理者帳號「root」和密碼登入。通過身分驗證程序登入vCenter Server VAMI管理介面後，首先點選「Time」項目，確認目前vCenter Server時區設定，與Active Directory、DNS伺服器、ESXi虛擬化平台採用同一個時間，本文實作環境採用的時區為「Asia/Taipei」。緊接著，點選「Summary」項目，就可以看到目前vCenter Server FQDN的名稱為「vcsa67.weithenn.org」，畫面如圖10所示。變更vCenter Server的FQDN接著，確認vCenter Server指向的DNS伺服器，已經能夠正確解析新的vCenter Server FQDN，本文實作環境為「vcsa67u3.weithenn.org」，然後在vCenter Server VAMI管理介面中，依序點選「Networking > Edit」項目。在彈出的Edit Network Settings精靈互動視窗中，於Select Network Adapter頁面中，倘若vCenter Server有配置多張網路卡時，確認選擇至「NIC 0 （Management Network）」項目的網路卡，確認後按下〔Next〕按鈕。進入Edit Settings頁面後，先在Hostname and DNS欄位中填入新的vCenter Server FQDN名稱，本文實作環境為「vcsa67u3.weithenn.org」，如圖11所示，由於新的vCenter Server FQDN名稱同時搭配新的vCenter Server管理IP位址，在本文實作環境中，DNS伺服器正向解析已經新增對應的IP位址為「10.10.75.25」，因此展開NIC 0項目選擇「Obtain Ipv4 settings automatically」項目即可，確認後按下〔Next〕按鈕。在SSO Credentials頁面中，填入vCenter Server管理平台中SSO管理憑證，本文實作環境管理者帳號為「Administrator@weithenn.org」，如圖12所示，確認後按下〔Next〕按鈕繼續。在Ready to complete頁面中，再次檢視新的vCenter Server FQDN名稱是否正確，並勾選「I acknowledge」項目以及檢視Next Steps項目內容。確認無誤後按下〔Finish〕按鈕，便正式執行變更vCenter Server FQDN的動作。系統將會開始執行「Network update in progress」程序，先停止vCenter Server相關管理服務，再執行vCenter Server網路組態設定的變更作業，包括新的FQDN和IP位址等網路組態設定，當所有變更作業完成後，重新啟動相關管理服務。此時，系統將會提醒倒數10秒，之後自動重新導向至新的vCenter Server VAMI管理介面，本文實作環境為「https://vcsa67u3.weithenn.org:5480」，使用vCenter Server管理者帳號「root」和密碼登入後，點選Summary和Networking項目，如圖13所示，確認新的vCenter Server FQDN和IP位址已經套用生效。至此，變更vCenter Server FQDN作業順利完成。結語透過本文的深入剖析後，幫助大家快速了解新版vSphere 6.7 Update 3和vSAN 6.7 Update 3亮眼特色功能，並且實作演練vCenter Server Update 3新功能，也就是變更vCenter Server FQDN和IP位址，以便因應企業和組織升級版本或更換vCenter Server平台時，必須變更名稱和網路組態設定的需求。＜本文作者：王偉任，Microsoft MVP及VMware vExpert。早期主要研究Linux/FreeBSD各項整合應用，目前則專注於Microsoft及VMware虛擬化技術及混合雲運作架構，部落格weithenn.org。＞ 呼叫專業服務機器人！豹小秘神救援零接觸測溫老字號 IT 網管監控神器　大秀自動流程與智慧分析用多雲策略建構災備善用5G三大獨特性　生態系結盟創新模式應用阿里雲推馳雲計劃　為全球中小企提供援助並加快雲端科技應用電子簽名導入區塊鏈　實現最高的資料安全性防疫也防駭！企業遠端工作 4 大重點助持續營運數位鑑識須在不疑處有疑　僅靠靜態分析易陷盲點軟協新任理事長沈柏延上任　力助產業數位轉型兆勤科技聯手 McAfee　打造全面零死角資安解決方案搞懂ICMP協定及工具 抵擋「死亡之Ping」攻擊網路設備入門新手必讀 Cisco IOS最基礎教學建立VLAN邏輯分割網段  詳解交換器Trunk設定人臉辨識拓展金融市場　技術高下實測見分曉NAT穿透技術 從外部直接溝通私有IP路由協定基礎知識入門 詳解路由特性與分類從STP到RSTP　認識多重生成樹協定無類別區隔路由CIDR技術 依需求善用有限IP位址深入了解IP位址與子網路遮罩開源OpenKM文管系統 立即打造知識管理平台第171期2020年4月任意雲端、單一體驗，釋放資料價值之新IT儲存架構解析Dell Technologies儲存創新　引領轉型旅程高階儲存較勁　NVMe全面來襲追蹤我們Featrue us本站使用cookie及相關技術分析來改善使用者體驗。瞭解更多",
        "微軟推出支援叢集應用程式的共享雲端區塊儲存服務 ": "Azure Shared Disks可用在叢集應用程式的故障轉移配置，也能於機器學習的模型訓練叢集微軟推出了Azure Shared Disks預覽版，該公司提到，這是目前市場上第一個共享雲端區塊儲存（shared cloud block storage），用戶現在可以利用Azure Shared Disks，將Windows Server上的叢集環境都搬遷到Azure。Azure Shared Disks可以滿足像是叢集資料庫、平行檔案系統、永久性容器和機器學習等，這類要在企業內的SANs（Storage Area Networks）上運作的應用程式需求，並且能夠處理需要低延遲的工作負載，而不會破壞快速故障轉移和高可用性的部署模式。微軟表示，Azure Shared Disks目的就是要來支援，Windows Server上執行的SQL Server故障轉移叢集執行個體、橫向擴展檔案伺服器、遠端桌面伺服器和SAP ASCS/SCS等應用。任何使用SCSI持續保留（Persistent Reservations，PR）技術的應用程式，都能利用相關指令將叢集的節點註冊到磁碟中，然後應用程式可以為一個或是多個節點，挑選一種支援的存取方式，來讀取或寫入磁碟，這些應用程式不只能以高可用性配置部署，還可以獲得Azure磁碟的持久性保證。微軟拿兩叢集應用程式作為案例，分別是兩節點資料庫應用程式的故障轉移，以及機器學習分散式模型訓練的配置。在叢集故障轉移的配置上，叢集應用程式同時在Azure VM 1和Azure VM 2上執行，並且向磁碟註冊讀取和寫入權限，在Azure VM 1上的應用程式執行個體，具有排他保留寫入磁碟的權限，在Azure VM 1寫入的時候，Azure VM 2執行個體的寫入動作不會成功，而一旦Azure VM 1故障，則故障轉移程序啟動，Azure VM 2就能接手並獲得寫入磁碟的權限，而來自Azure VM 1的寫入動作將被拒絕。Azure Shared Disks也可被用在多節點上，處理像是機器學習訓練模型這類平行化的工作。在這個例子中，叢集應用程式使用了4臺虛擬機器，所有虛擬機器都需要向磁碟註冊，但只有Azure VM 1具有排他保留寫入磁碟的權限，其他虛擬機器則只有讀取權限，Azure VM 1會代表所有節點將結果寫入磁碟。Azure Shared Disk支援高階SSD，容量需要大於P15等級256 GB，Azure Shared Disk接下來還會支援Azure Ultra Disk。微軟提醒，Azure Shared Disk只能用作資料磁碟，不能是作業系統碟。2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "希捷科技於 CES 2020 推出 Lyve Drive 行動系統 推動資料領域發展 ": "\n\n科技快訊小天使\n發表於 2020年1月07日 18:04\n \n收藏此文\n\n 美國內華達州，拉斯維加斯— CES 2020 — 威尼斯人酒店 3 樓 San Polo 廳 — 全球資料解決方案領導供應商希捷科技 (NASDAQ：STX) 今日於 CES 2020 宣布推出革命性的模組化儲存解決方案，可加以管理急遽成長的企業、雲端與邊緣資料。希捷的 Lyve Drive™ 行動系統是一款簡單、安全且有效率的資料管理解決方案產品組合，旨在推動資料領域的發展。 在工業 4.0 ── IT領域第四波產業革新浪潮的帶動下，連網家庭、連網城市、AI 工廠、自駕車以及媒體娛樂內容，將帶來爆炸性的資料成長；根據希捷贊助的 IDC 研究報告指出，全球資料領域預計會從 2019 年的 41ZB 成長至 2025 年的 175ZB，且有將近 30% 的資料需要被即時處理。而希捷的 Lyve Drive 系統能夠使這些資料在企業、雲端和邊緣之間，以有效率且符合經濟效益的方式移動。希捷全球行銷副總裁 Jeff Fochtman 表示：「資料能夠為那些將其有效利用、活用的人帶來極大的效益。然而，現今的資料管理工具過於昂貴、效率不彰，因此企業無法善加運用資料的完整價值。希捷希望提供整合一致的資料使用體驗，而Lyve Drive 就是朝向這個目標邁出的第一步，可讓資料所具備的可能性轉化為全球各大產業的實質成長。」Lyve Drive 行動系統希捷的 Lyve Drive 行動系統集結了多種模組化儲存解決方案，以因應在端點、邊緣及核心之間大量移動資料的需求，有助於企業提升工作效率、蓬勃發展。於 CES 期間，希捷將會展出這款革命性的系統，並介紹本系列多種關鍵的產品概念，包括：Lyve Drive 記憶卡與 Lyve Drive 讀卡機高容量、高效能的 1TB CFexpress™ 記憶卡及可攜式讀卡機，可擷取來自端點的資料。Lyve Drive Shuttle一款自動化資料儲存及傳輸解決方案，可從直接附加 (direct-attached)、網路連接 (network-attached) 及其他類型的外接式儲存裝置輕鬆接收資料。根據 HDD 或 SSD 的配置差異，最高容量可達 16TB，且無需透過 PC，便能直接在電子墨水觸控螢幕上複製檔案。Lyve Drive行動陣列密封式的高效能 6 機槽陣列，經過強化處理、方便傳輸。於 CES 展出的行動陣列，會配備 6 台希捷的 18TB Exos HAMR（熱輔助磁記錄）硬碟，總容量高達 108TB。Lyve Drive模組化陣列高效能的 4 機槽陣列，採取彈性的配置方式，企業可配合個別工作流程的需求，建構出量身打造的配置。於 CES 展出的高容量模組化陣列，配備希捷的 Exos 2X14 企業級硬碟，該硬碟是首款整合希捷劃世代MACH.2雙磁頭驅動臂技術的硬碟。Lyve Drive 機架式接收器高效能的資料中心專用 4U 機架式接收集線器 (rackmount ingestion hub)，具備極高的資料傳輸速度，可接收兩台 Lyve Drive 陣列的資料，無需經由纜線，就能直接傳輸至資料中心架構。CES 2020 展覽希捷科技將於 CES 2020中詮釋資料的旅程 ── 從端點的源頭出發，在邊緣進行擷取以提供即時的分析，再前往核心長久儲存。隨著資料傳輸的腳步，希捷將會揭曉資料的下一步革命性進展，從靜態硬碟邁向各種系統、軟體和儲存裝置共同順暢運作的全新世界，將資料的潛能轉化為商業上的成長。參觀者可親身體驗多項強調發揮資料效能的實際使用案例，例如：通往未來的道路：自駕車全自動駕駛汽車在路上行駛的未來，已然不遠。為了加速實現未來展望，希捷將與合作夥伴 Renovo 一同建立平台，結合軟體、資料管理功能和自駕車等級安全系統，形成整合的解決方案，可供自駕車部署。百萬位元組：媒體與娛樂4K、8K 和HDR這類最新的影像品質標準，讓媒體娛樂產業資料的年複合成長率至 2025 年可望增加 25%。希捷將特別設置電影場景，展現次世代的資料管理解決方案將如何加速後製程序。連網城市到 2025 年，預計會有超過 25ZB 的資料是在邊緣被創造和複製。希捷在 CES 中的展出多數著重於各自獨立的資料端點，不過在我們客製的 LEGO® 連網城市裡，則會呈現出現實生活中的 AI 和視訊資料，如何在連網城市的各種日常活動和互動中穿梭往來，以及如何在協助政府機關處理緊急事件、進行執法、控管交通等任務中扮演重要角色。極致的遊戲體驗希捷對遊戲領域極為投入，而 CES 展會絕對是坐上客製化Imperator Works Zero Gravity Chair感受最佳遊戲體驗的絕佳場合。其配備曜越(Thermaltake) P5 電競 PC，搭載Seagate FireCuda® 520 NVMe PCIe Gen4 x4 SSD 、PS4 Pro 及 Xbox One，並附有最新的雷蛇(Razor) 週邊設備，還能以客製化層架收納電競科技產品、點心飲料，是遊戲玩家的夢幻逸品。連網家庭預計到 2023 年，智慧家庭的數量會超過 7,000 萬戶。希捷將會深入探討普及運算 (ambient computing)如何在居家用途上運用資料，讓日常生活更加便利且有效率。5G 的世界到 2024 年，5G 網路的覆蓋範圍預計會佔全世界的 40%，負責處理 25% 行動資料流量，速度可超越當前 4G 技術的 100 倍，且每平方英里可支援數百萬台裝置。5G 使裝置和資料的數量加速成長，使得電信架構成為採用邊緣技術的良好場域。希捷將展出 Vapor IO 的微型模組化邊緣資料中心，其可讓資料更為靠近端點，以達到更好的效率，有助於發掘出嶄新的使用方式、建立全新市場、促進產品創新，更會顛覆無數個垂直市場。連網工廠大量生產的企業逐漸轉向運用資料來達成目標，到 2025 年，製造業的年複合資料成長率估計會提升多達 30%3。希捷科技將以製造業者的角色，展示以提升作業效率為目標，運用 AI 等先進技術的未來工廠樣貌。海量資料：蒙特雷灣水族館希捷與蒙特雷灣水族館研究中心(Monterey Bay Aquarium Research Institute，MBARI)進行工程及科學領域的合作。該機構每年投入 7,000 萬美元的資金，並有超過 200 位全職員工，負責透過對深海的探索與發掘研究收集大量資料。MBARI 將與希捷一同展出最新資料解決方案，介紹各種方案是如何協助研究團隊迅速且有效率地擷取和傳輸所有資料。欲了解更多資訊，歡迎在 CES 2020 期間造訪希捷位於威尼斯人酒店 3 樓 San Polo 廳的展場參觀。關於希捷希捷以創新、設計精密的世界級資料管理解決方案形塑資料領域，協助發揮人類的最大潛能，且專注於能永續長存的合作關係。詳細資訊請參考 www.seagate.com。透過 Twitter, Facebook, LinkedIn, YouTube, blog了解Seagate。Shares\n      標籤：新聞稿\n\n請注意！留言要自負法律責任，相關案例層出不窮，請慎重發文！更多體驗試玩活動 »更多課程講座 »更多動態 »",
        "電腦達人養成計畫 7": "上一節談了一系列早期硬碟的發展之後，接下來是時候將目光移回現代硬碟上了，本節要介紹的是 1990 年代以後的硬碟與硬碟介面發展，特別是以曾經蔚為主流的 IDE/ATA 與曾稱霸企業市場二十年的 SCSI 為主 (目前仍是市場主流的 SATA 與最新的 NVMe 則留待介紹之後介紹)。一套完整的硬碟儲存系統可以概略分為儲存媒介 (包含磁碟或磁帶、讀寫頭等)、介面 (interface，負責接收來自控制器命令) 以及控制器 (controller，扮演磁碟與電腦本機之間的橋樑，用於將磁碟與電腦系統連結起來與控制讀寫頭與磁盤運作進行資料讀寫) 三個主要部分。而早期的硬碟介面並沒有一套標準規範可以依循，而是各自使用不同的專屬規格，因此早期的硬碟系統多半會隨其專用的控制器一同出貨，而不同廠商或型號硬碟所使用的控制器也多半不能隨意混用，甚至有些硬碟儲存系統是只能搭配特定的電腦系統使用的，例如上節曾提及的 IBM 3380 (相當於儲存媒介)，就必須透過 IBM 3880 儲存管理系統 (相當於介面) 與 IBM System/370 或 System/380 大型電腦系統中的控制器連接 (架構如下圖)。(註：在描述磁碟系統的時候，控制器與介面這兩個詞彙經常會被混用，主要係因現代的硬碟本身其實也整合了一組用於控制硬碟本身動作、負責接收來自電腦系統命令的控制器，而介面實際上也是同時存在於硬碟系統與電腦系統兩端，但本文中若無特別說明的話，文中所指的控制器主要是指「電腦系統端的控制器」，介面則主要是指「硬碟系統端的介面」。)在 1980 年，Shugart Technology 發表了 ST-506 這款個人電腦磁碟系統 (實際上由 ST-506 5.25 吋硬碟、ST-506 專用的控制器與 ST-506 專用的磁碟介面組成)。如同我在上一節當中曾經提及的，衍生自 ST-506 的 ST-412 在當年成功取得了 IBM PC XT (首款內建硬碟的 IBM 個人電腦) 的 OEM 供應訂單，因此 ST-506 與 ST-412 很快便成為了第一款在個人電腦領域中獲得廣泛應用的內建硬碟系統。ST-506 的磁碟介面與控制器之間一般以兩條訊號線連結 (分別是 34-pin 的控制線路與 20-pin 的資料傳輸線路)，每台硬碟都需要各自獨立的資料傳輸線路，而控制線路的部分則可以至多同時控制四台硬碟 (絕大多數控制器設計為僅能同時控制兩台硬碟)。此外，由於 Shugart Technology 在設計此款硬碟系統的控制器與介面時是以 Shugart Associates 的 SA1000 軟碟系統為基礎，因此相對而言在實作上簡單許多，又正好搭上當時許多電腦公司爭相投入設計與生產 IBM PC 的相容系統，因此 ST-506 與 ST-412 所使用的此款磁碟介面很快就成為個人電腦硬碟系統的主流非正式行業標準。ST-506 與 ST-412 所使用的磁碟界面都使用了 MFM (改進調頻編碼) 編碼技術，而隨後推出的改良版－ST-412HP 則是增加了對 RLL (運行長度有限編碼) 編碼技術的支援，分別可使儲存密度與資料傳輸速率增加至多 50%。隨後在 1980 年代上半，Maxtor 發表了增強型小型磁碟界面 (Enhanced Small Disk Interface，ESDI)，相較於已經成為主流的 ST-506 / ST-412 磁碟界面而言，ESDI 最大的改進是將部分以往放置在磁碟控制器上的資料分隔器 (Data Separator，主要功能為自電子訊號中將包含實體資料的部分與其他控制訊號分隔開來) 等晶片移入硬碟本體中，以換取更高的性能與更低的延遲。在傳輸速率方面，原先的 ST-506 介面最高只能支援 7.5 Mbps 的資料傳輸速路，而 ESDI 則是可以達到 10、15 Mbps 甚至是 20 Mbps。在傳輸介面方面，為了降低採用時的成本負擔，ESDI 使用了與 ST-506 / ST-412 相同的連接器規格 (同樣採用 34-pin 的控制線路與 20-pin 的資料傳輸線路)，此外，ESDI 介面在設計上也納入了對軟碟機、磁帶機的支援。ESDI 介面在 1980 年代中後期曾經流行過幾年的時間，但隨後 SCSI 與 IDE/ATA 介面相繼成熟之後很快就與 ST-506 / ST-412 一起被這兩款介面取代了。訂閱後當本站有新文章時便會發出通知。一起加入其他 3,268 位訂閱者的行列  E-mail        訂閱 ",
        "妙手做好資源監視優化　Exchange 2019效能回春 ": "熱門搜尋 : 熱門搜尋 : 望聞問切採取對症措施　活用系統內建工具調校 如果一個全新應用系統的部署，只要選擇使用更快的CPU、更多的記憶體以及更快的儲存設備，就能徹底解決運行時效能不彰的問題，那麼還需要系統工程師這個角色的資訊人員做什麼呢？其實，以筆者過去數以百計的專案經驗來說，在新系統導入與安裝時，若選用比預期更快與更大容量的伺服器設備，而非只是選擇適用或堪用的伺服器設備，肯定可以為用戶提供絕佳的運行體驗。不過必須注意的是，這樣往往只是剛開始不久的體驗，一旦上線的人數越來越多以及存放的資料越來越龐大時，日子一久，用戶對於速度變慢的抱怨便會陸續增加。此時，若只是一味地增添硬體資源，通常難以解決現況的問題。相信許多人都知道，中醫師診察病患疾病的方法是望、聞、問、切，唯有通過這四診才能對症下藥。這裡所說的中醫師就好比系統工程師，肯定得先找出生病的原因才能提供解決方案，而不是僅看到系統運行速度變慢，就開始動手升級CPU、擴充記憶體或是更換儲存設備，不然到頭來可能徒勞無功。就以Exchange Server 2019來說，當發現其運行的速度越來越慢時，首先應當從Windows Server作業系統來監視三大硬體資源的使用情形，以及進行Active Directory的健康診斷與調校，然後再來評估是否需要擴充或升級硬體設備。而在評估的過程中最重要的就是透過現有的工具，例如Windows Server和Exchange Server內建功能，找出可能影響效能的原因，進而在不需要擴充硬體資源的狀態下，完成運行效能的提升。監視Windows Server效能Windows Server內建的「Task Manager」肯定是IT系統人員最常使用的監視工具，因為可以隨時在桌面的工作列上按下滑鼠右鍵來選擇開啟。如圖1所示，在開啟後的「Performance」頁面中，先以整體使用率或邏輯處理方式檢視CPU的效能。一般來說，建議採用後者方式來檢視，因為可以知道每一個核心資源的負載情形。根據經驗，若系統人員發現有其中一個核心始終維持在100%的狀態下，通常可能的原因會是某裝置的驅動程式或韌體尚未更新，當然也有可能是因為特定的Windows更新程式所造成，只要移除後重新安裝，往往便能夠解決問題。如圖2所示，在「Details」頁面中，除了可以針對特定運行中的執行程序設定其優先順序（Set priority）外，還可以進一步配置其對於多核心CPU資源的親和性（Set affinity），有效避免某一些高負載的程序將所有CPU核心的資源用盡，而導致其他原本正常運行中的重要程序受到影響。圖3所示則是處理器親和性的配置頁面，可以讓某一些應用程式（例如EdgeTransport.exe）限定在特定CPU核心數的使用。如此一來，當同時有許多較重要的應用程式需要較多的CPU資源時，便不會讓一些執行程序因短缺資源而造成效能的運行大受影響。在「Task Manager」工具視窗的「Performance」頁面中，還有一個進階工具可以使用，那就是資源監視器，只要在該頁面中點選「Open Resource Monitor」超連結即可開啟。如圖4所示，在此可以分別在CPU、Memory、Disk以及Network子頁面內，針對所選定的執行中程序即時查看它們資源的使用情形。舉例來說，如果發現在「Disk」頁面中的「Highest Active Time」百分比持續維持在50%以上，就必須即時找出占用最多磁碟I/O資源的執行程序，並且在必要時更換速度更快的儲存設備。善用BPA工具找問題還記得前面已經強調過，Windows Server是所有Windows應用系統效能運行好或壞的根本因素，因此除了必須懂得用肉眼來查看影響系統效能的執行程式外，還必須學會善用內建提供的工具，來幫忙找出其他不易被察覺的潛在問題，而這些問題恰好可能是影響運行效能的因素之一。在此推薦所有管理人員都應該善用「最佳做法分析程式」（Best Practices Analyzer，BPA），它早內建於Windows Server 2012以上版本的伺服器管理員工具中，主要用途便是針對現行已安裝的伺服器角色進行掃描，找出任何已知可能影響穩定及效能的原因，並提供可行的線上解決方案讓管理人員參考。操作的方法很簡單，如圖5所示，只要在「Server Manager」介面中針對選定的伺服器，點選「BEST PRACTICES ANALYZER」窗格之中的【TASKS】→【Start BPA Scan】選項即可。當BPA掃描結束之後，如圖6所示便可以看到許多警告與錯誤的事件，而這些事件也都有關聯的伺服器與類別名稱，原則上都應該優先處理錯誤的事件，因為它可能是直接關係到伺服器的安全或正常運行。舉例來說，如果出現「Use SSL when you use Basic authentication」事件，就表示在該伺服器的IIS網站中已有網站設定採用了未加密的基本驗證功能，並且沒有配置伺服器的SSL憑證來保護連線的安全性。第二個是警告事件的例子，如果出現「Short file name creation should be disabled」事件時，表示系統提示最好能夠停用建立短檔名的功能，原因是此設定可能會造成被大量連線存取的檔案伺服器服務增加了相當大的效能負擔，因此除非在公司的網路中仍有其他應用系統只能夠唯一存取短檔名的檔案，否則只有關閉描述中的建立短檔名功能，才能有效避開此問題的發生。只是要如何停用建立短檔名的功能呢？其實，凡是經由BPA診斷出來的每一個問題說明，其內容下方都會有一個超連結，點選後將會開啟Microsoft線上的解決方案，依據此線上說明的指引，先到「開始」→「執行」方塊中輸入「regedit」，然後從「登錄編輯程式」介面中切換至「HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\File System」節點下，就可以看到許多檔案系統有關的參數設定，包括了對於NTFS檔案系統的壓縮、加密以及配額通知頻率設定等等，這些預設值都可以根據實際檔案系統運行的需要進行調整。然後，開啟「NtfsDisable8dot3NameCreation」，再將「NtfsDisable8dot3NameCreation」修改為1即可。成功關閉預設建立短檔名的功能後，後續系統便不會再為每一個經由各種途徑所儲存的長檔名檔案，特別建立一個相對八個字元的主檔名與三個字元的副檔名，解除了可能嚴重降低檔案伺服器效能的第一個頭號隱患。監視Exchange Server效能無庸置疑地，CPU的效能與記憶體的大小，是決定Exchange Server是否能夠快速運行的基礎。在CPU相關的計數器部分，如圖7所示，考量Exchange Server正常運行的效能表現，最基本的整體CPU負載狀態（「Processor(_Total)\\ % Processor Time」）最好不要持續超過75%。此外，也可以考慮同時加入「Processor(_Total)\\ % User Time」以及「Processor(_Total)\\ % Privileged Time」計數器的監視。同樣地，這些平均值都必須小於75%，才能夠保證CPU的基礎效能沒有問題。在多核心的分配中，如果有配置Exchange Server的相關程式，僅能使用選定的核心來運行，那麼對於「System\\ Processor Queue Length (all instances)」的監視，就必須針對選定的處理器核心來進行，並且每一個核心持續回報的處理器佇列長度不能大於6，否則就表示處理器在準備以及等到執行佇列中資料的時間過長，肯定會影響CPU在處理Exchange Server各項服務運行的正常表現。最後，建議也加入「Processor Information(_Total)\\% of Maximum Frequency」計數器的監視，用以確定目前主機是處於100%高效能的運行模式，尤其針對實體主機而言此監視更是重要。至於如何讓Windows Server 2019主機運行在高效能的模式之下呢？其實只要開啟「Control Panel」頁面中的「Power Options」管理功能，如圖8所示即可查看與修改。在此必須選擇「High performance」設定，才能讓CPU以100%的效能全速運行，除非要降低耗能，才改選「Balanced」或「Power saver」設定。在記憶體方面，與Exchange Server運行效能相關的主要有兩部分，如圖9所示，在.NET Framework部分主要有「.NET CLR Memory\\% Time in GC」及「.NET CLR Memory\\Allocated Bytes/sec」，前者必須持續小於10%，而後者則須持續小於50MB才屬於健康狀態。其中垃圾回收功能（Garbage Collection，GC）是.NET中的自動記憶體管理器，負責釋放不需要的虛擬記憶體以確保包含Exchange在內執行程序的運行。無論如何，盡可能讓.NET Framework維持在最新版本，是優化Exchange Server記憶體效能的必備作為。在記憶體使用狀況的監視方面，則有兩大計數器的監視需要特別留意，分別是「\\Memory\\%Committed Bytes in Use」和「\\Memory\\Available Mbytes」。前者主要用來監視已完成提交的執行程序所使用的百分比，此值建議不要持續超過80%，後者則是目前可用記憶體的大小，必須維持在總記憶體大小的5%以上，若長時間低於此值，請盡速擴充記憶體，否則會影響Exchange整體架構的效能表現。至於記憶體分頁檔案（Page file）的配置，則採用固定大小並且設定與現行記憶體容量10M的大小即可，不過最大值不要超過32GB。除了CPU與記憶體外，影響Exchange Server運行效能最重要的關鍵資源，肯定就是存放區I/O效能的表現。如圖10所示，建議在「Performance Monitor」的「Add Counter」設定頁面中，分別將「MSExchange Database Instances」類別下的「I/O Database Reads (Attached) Average Latency」、「I/O Database Reads (Recovery) Average Latency」、「I/O Database Writes (Attached) Average Latency」、「I/O Log Writes Average Latency」計數器一一加入，並且加入對於所有Exchange信箱伺服器的監視。如圖11所示，在報表的頁面中，便可以看到剛剛所加入四個有關於Exchange資料庫的I/O計數器，每一個計數器將會即時監視所有系統資料庫與信箱資料庫的數據，而它們持續運行的理想數值，依序為針對每個資料庫讀取操作的平均時間長度必須小於20毫秒（ms）、被動資料庫讀取操作的平均時間長度必須小於200毫秒、每個資料庫寫入操作的平均時間長度須小於50毫秒，最後則是對於每個紀錄檔案寫入操作的平均時間長度必須小於10毫秒。也唯有如此，才能夠確保資料庫在I/O方面的運行效能沒有問題。相反地，如果發現某個信箱資料庫的運行長時間大於標準值，那麼可能需要減少該信箱資料庫的信箱數量，或是將它轉移到更快儲存設備的資料存放區內，效能問題才有機會獲得明顯地改善。收集主機運行效能數據建立不同階段的效能基準線的優點在於，未來一旦在相同系統條件下，有效能低落的情況發生時，便能夠透過再一次建立新的效能紀錄，來與前一次效能基準線做比較，快速找出真正影響效能表現的主要原因。建立的方法很簡單，如圖12所示，只要在「Performance Monitor」工具頁面的「User Defined」節點上按下滑鼠右鍵，然後依序點選【New】→【Data Collector Set】即可。完成新名稱並選擇手動建立的設定之後，在如圖13所示的頁面中按下〔Add〕按鈕，接著挑選所有想要監視的效能物件，並且設定想要的抽樣時間。請注意！每一次建立的效能基準線，其所監視的物件清單與抽樣時間務必相同，如此才有辦法進行前後效能數據的比較。設定完畢，按下〔Next〕按鈕繼續。然後，決定是否要以特定的帳戶來執行此資料收集器。最後，便可以決定是否要立即啟動這個資料收集器，或是想要開啟此資料收集器的內容，以便設定自動執行的排程等設定。完成建立效能基準線收集器後，在執行一段時間之後，如圖14所示，在該設定項按下滑鼠右鍵，並點選快速選單中的【Latest Report】功能，即可查看最近一次的效能分析報告。如圖15所示，便是效能收集後的圖表報告檢視，若只想檢視某個區間資料，例如針對CPU與記憶體使用率較高的時間區段，則在選取後按下滑鼠右鍵並點選快速選單中的【Zoom to】，然後進行該區間資料的放大檢視即可。善用ReFS提升信箱資料庫效能復原檔案系統（Resilient File System，ReFS）是Microsoft打從Windows Server 2012版本開始，就已經推出的新型檔案系統，它有兩大主要特色，一是能夠比傳統NTFS（New Technology File System）更有效率地處理大型檔案的存取，二是自動探測磁碟的壞軌以及修復資料的錯誤，讓資料不至於存放於有問題的磁軌中。更棒的是，ReFS會在處理多數無法修正的損毀問題時，持續讓有問題的磁碟區維持在上線狀態，僅有在極少數的情況下需要讓該磁碟進入離線狀態。而在單一磁碟分割區的大小與單一檔案大小部分，則紛紛支援了35PB（petabytes），遠大於傳統NTFS所支援的256TB。在效能方面，可以選擇將ReFS檔案系統建立在Storage Spaces Direct的階層式儲存架構中，讓系統自動地將經常存取的檔案與資料存放在效能層（Flash），而把那些沒有經常被異動的檔案存放於需要大空間的儲存層（HDD）內。而常見的做法是，規劃鏡像加速之同位檢查（Mirror-accelerated Parity）的磁碟部署，來同時兼顧效能、容量、安全以及成本的需求。採用ReFS檔案系統來存放Exchange資料庫、交易紀錄檔案、內容索引檔案是最佳的選擇，不過，它並不適合用來做為系統的磁碟分割區，或是當作存放Exchange的執行程式。建立的方法很簡單，只要在「Disk Manager」操作介面中執行「New Simple Volume」功能，並且在「Format Partition」頁面中選擇【ReFS】類型的「File system」即可，如圖16所示。值得注意的是，它在「Allocation unit size」部分支援4K與64K，在此建議若後續Exchange Server也將建立DAG的複寫備援架構，選擇採用64K的配置大小，將可以獲得更好的存取效能。最後按下〔Next〕按鈕，完成ReFS檔案系統分割區的建立。如圖17所示，就可以看見剛剛建立的Disk 2磁碟分割區，所顯示的檔案系統便是類型便是ReFS。除此之外，根據官方的說法，建議關閉Exchange Server檔案在ReFS檔案系統中的資料一致性功能（Integrity Streams），可以選擇在最初就執行「Format-Volume -DriveLetter 磁碟代號 -FileSystem ReFS -SetIntegrityStreams $False」命令來完成ReFS磁碟格式化的整體設定，或是事後再透過執行「Set-FileIntegrity -FileName 檔案名稱 -Enable $False」命令，針對選定的Exchange檔案進行設定。如果要查看目前的設定值，則執行「Get-FileIntegrity -FileName 檔案名稱」命令。也可以透過執行「Get-Volume -DriveLetter C,E,X」命令，如圖18所示查看這些磁碟目前所採用的檔案系統類型，以及它們各自的磁碟類型、健康狀態、剩餘空間、總磁碟大小等資訊。倘若打算採用Windows Server 2019所內建的Hyper-V虛擬化平台來部署Exchange Server 2019的虛擬機器，那麼便可以選擇將這些虛擬機器部署在ReFS檔案系統中，來大幅提升Exchange虛擬機器在後續維護管理上的效能，因為它具備了兩項在NTFS檔案系統中所沒有的特性，分別是Block Cloning以及Sparse VDL，前者可解決快速複製虛擬機器以及加速完成檢查點合併（Checkpoint Merge）的作業時間，而後者則可透過ReFS將檔案快速歸零（Zero-fill）的特性，讓原本需要花費十幾分鐘以上來建立固定虛擬磁碟的時間，轉而僅需要幾秒鐘就能夠完成建立。儘管ReFS檔案系統提供了許多新的特色，非常適合用來運行Exchange Server 2019和Hyper-V虛擬機器，不過對於一般檔案的儲存與存取需求，可能就不是那樣適合了，因為相較於傳統NTFS，它有以下這些功能是不支援的，需要系統管理人員特別留意，分別有檔案系統壓縮、檔案系統加密、交易、永久連結、物件識別碼、卸載資料傳輸（ODX）、簡短名稱、擴充屬性、磁碟配額、可用來開機、分頁檔案（Page File）支援，以及卸除式儲存媒體支援。優化Active Directory運行Exchange Server的架構與一般Mail Server最大的不同之一，在於它是完全相依在Active Directory的基礎建設運行。換句話說，一旦Active Directory發生故障或效能不彰時，Exchange Server肯定也會無法正常運行，或是連線存取的速度明顯變慢。因此，在正式生產環境的部署中，除了要讓擔任網域控制站（DC）的伺服器使用64位元的硬體設備和作業系統，以提升Exchange連線存取目錄服務的效能表現外，還必須確認以下幾個重點：‧網域五大伺服器角色的運作必須正常，在大型的架構中可以考慮將這些角色分開在不同主機中運行。‧相依DNS的運行必須正常，且最好能夠定期維護紀錄，清除已不在使用的紀錄。‧站台與站台之間的複寫必須正常，必要時可能需要調整複寫的排程或是複寫的方式。‧定期執行Active Directory資料庫離線重組與資料庫壓縮，以便讓資料庫檔案始終維持在最佳狀態。首先，可以透過執行「netdom query fsmo」命令參數的方式，查看目前Active Directory五大角色主機的分布狀況，如圖19所示。原則上，在部署規劃中如果因應效能的考量需要分拆五大角色的主機，必須優先將Domain Naming Master與Global Catalog配置在同一台伺服器內，而PDC、RID Pool Manager及Infrastructure Master則配置在一台效能更好的伺服器中。想要確認Active Directory的整體運行是否健康，可以善用內建的DCDiag命令工具，來協助分析樹系之中單一網域控制站或所有網域控制站的健康狀態。常見的做法是透過執行DCDiag命令搭配/s參數，來指定所要診斷的網域控制站主機名稱，如此便可以立即診斷出此網域控制站的各項基本健康狀態，包括DNS的基本測試、轉向測試、委派測試、動態紀錄更新測試、記錄註冊測試以及各個DNS區域的測試。若要查看更加完整的延伸診斷資訊，則如圖20所示改為執行「DCDiag /v」命令參數，這樣一來，除了會顯示錯誤及警告的資訊外，也將一併呈現各項成功測試的結果資訊。如果只是想要診斷Active Directory所相依的DNS服務，則分別執行「DCDIAG /DnsBasic」和「DCDiag /test:dns」兩個命令參數。前者能夠測試網路的連接、DNS用戶端配置、服務可用性以及區域的存在性，而後者可以僅針對選定DNS健康狀態的診斷，若想要一次針對樹系中所有網域控制站的運行進行測試，則再增加/e參數，不過，這在大型的網域架構中可能會花費漫長的時間來完成。當測試的結果資訊相當多時，可能會只想查看有關錯誤的資訊部分，此時只要增加/q參數即可。最後，如果想要將任何的診斷結果輸入成一個紀錄檔案，只要增加/f參數設定就可以，例如透過執行「DCDiag /s:DC01 /f:C:\\Logs\\dcdiag_dc01.txt」命令，將針對DC01的基本診斷紀錄寫入至dcdiag_dc01.txt檔案內。善用BPA診斷網域控制站前面曾介紹過藉由內建的BPA功能，來找出Windows Server現行配置的潛在問題，並且透過官方所提供的線上技術知識庫，來完成優化調校與問題排除的需求。然而，相同的做法也可以運用在擔任網域控制站的伺服器角色。如圖21所示，便是在一台名為「DC01」的網域控制站上執行「Start BPA Scan」操作後的結果頁面，可以看到許多警告以及一個錯誤的事件報告，在此同樣必須以處理錯誤的事件為優先。這裡看到第一個錯誤事件就是系統提示Ethernet0的網卡已設定了Loopback位址（127.0.0.1），不過並非是設定在第一順位，這樣的結果可能會影響本機的網域控制站對於其他網域控制站，以及相關伺服器名稱的解析，因此必須立即開啟此網卡的屬性來完成修正。接下來看看另一個警示的事件，它出現了「MSMQ is installed on a domain controller」標題，這表示MSMQ（Microsoft Message Queue Server）服務已被安裝此系統中，一旦該服務所連接的應用程式產生大量的訊息需要處理的時候，便可能直接影響到網域控制站目錄服務的效能。想要解除這一項警示事件，只要到「Server Manager」介面中，從「Manage」選單中開啟「Remove Role and Features」，然後在如圖22所示的「Features」頁面內取消對於「Message Queuing」功能的選取。接著，按下〔Next〕按鈕完成移除即可。必須注意的是，這項操作會影正在使用這項功能的應用程式之正常運行。再來看看另一項警示事件的標題是「Scavenging is disabled on the DNS server」，這表示尚未將DNS伺服器配置中自動清除過時資源紀錄的功能打開。啟用這項功能的優點在於，可以讓DNS的資料庫不至於成長太大，而導致降低了DNS服務進行資料存取的效能。啟用的方法是，先在「Server Manager」介面的「Tools」選單中點選開啟【DNS】，如圖23所示，然後於「Action」選單中點選【Set Aging/Scavenging for All Zones】。然後，在「Server Aging/Scavenging Properties」頁面中，將「Scavenge stale resource records」選項打勾，並設定不重新整理的間隔時間以及重新整理的間隔時間，如圖24所示。此兩項設定的系統預設值皆為7天，不建議設定小於6小時或大於28天。最後，按下〔OK〕按鈕。定期維護Active Directory資料庫在Active Directory的運作中，也有它自己專屬格式的資料庫來儲存相關資料，因此對於其資料庫定期進行相關維護作業肯定是必要的，而這一些在平日就應該進行的維護任務，包括了資料庫的備份、壓縮、重組、校驗以及一致性檢查等等。想要對這個資料庫進行維護，必須是在離線狀態才行，因此在每一個站台中至少有兩台網域控制站，就顯得非常重要，如此才能夠在維護期間讓Active Directory持續正常運作，進而不會影響到用戶持續對於Exchange Server的連線存取需求。如何讓Active Directory資料庫進入離線狀態下，並且開始執行各項維護任務呢？很簡單！在選定的網域控制站主機上執行「shutdown -o -r」命令，讓系統重新啟動至Windows Server 2019的開機選單頁面。接著，點選「Troubleshoot」選項來開啟如圖25所示的「Advanced options」頁面。在點選「Startup Settings」選項後，於下一個頁面中按下〔Restart〕按鈕。再次重新啟動後，將會開啟如圖26所示的開機選單，選取「Directory services Repair Mode」並按下〔Enter〕鍵，準備進入到作業系統的安全模式。必須注意的是，在登入的畫面中，一般可能習慣直接輸入網域管理員的密碼進行登入，然後會看到無法登入的原因說明。其實，必須改成切換至輸入本機的管理員帳號（例如DC01\\Administrator）與密碼來登入即可成功，因為目前的網域服務並沒有在啟動狀態下，這也是接下來所需要的Active Directory資料庫離線模式。成功登入後，以系統管理員身分在Windows開始選單按下滑鼠右鍵，來開啟Windows PowerShell (Admin)命令視窗，執行「ntdsutil」命令後，將會進入到ntdsutil的提示字元，執行「activate instance ntds」命令，準備開始存取相關資料庫檔案。接著，執行「Files」命令進入到Files的提示字元，然後輸入「info」命令來查看有關於NTDS資料庫與紀錄檔的儲存資訊，這些資訊包括了資料庫與紀錄檔案的存放路徑、檔案大小、工作目錄、備份目錄。如果發現資料庫檔案大小已經成長到很大，可以考慮如圖27所示輸入「compact to c:\\NTDS」將它進行壓縮，並且指定將壓縮後的檔案存放到指定的不同資料夾中（例如C:\\NTDS），等完成壓縮後再將檔案複製到原來的資料夾路徑中，並且刪除舊的紀錄檔案。此外，如果想要檢查NTDS資料庫的完整性，則同樣在Files的提示字元下，如圖28所示執行「checksum」命令進行校驗。接著，可以執行「Integrity」命令進行一致性的檢查。如果目前已準備了高速的磁碟儲存空間，而想要變更目前NTDS資料庫與紀錄檔的存放路徑，可以執行「Set path DB 資料夾路徑」命令，以及「Set path Logs 資料夾路徑」命令來完成變更。如果是要進行資料庫與紀錄檔的移動，則必須變成執行「Move DB to 資料夾路徑」命令，以及「Move Logs to 資料夾路徑」命令。優化網域控制站複寫配置在多點營運的企業網路架構，Active Directory站台與站台之間的網域控制站複寫，便是經由跨WAN的網路連線來完成，在網路頻寬極為有限與站台主機數量相當多的情況下，配置適當的複寫排程時間與複寫方式來改善複寫的網路流量是絕對需要的。從開始選單的「Windows Administrative Tools」選單中開啟「Active Directory Sites and Services」介面，接著展開至任一站台項目節點下的伺服器，便可以看到每一個不同伺服器下都會有一個「NTDS Settings」，在選取後都會看到在右方的窗格中會有複寫的來源伺服器清單。如果清單中沒有出現任何伺服器，那麼複寫的運作肯定是會有問題的，這時候在「NTDS Settings」項目上按下滑鼠右鍵，然後點選【All Tasks】子選單下的【Check Replication Topology】功能，在等待幾秒鐘之後，就會自動產生伺服器清單。可以針對清單中任一伺服器項目按下滑鼠右鍵，並點選快速選單中的【Properties】，然後在所開啟的頁面中按下〔Change Schedule〕按鈕，這時候將會開啟排程設定頁面，在此可以根據實際需求，使用滑鼠拖拉的方式來決定複寫的時間區間，並且決定每一小時複寫的次數。除此之外，還可以配置在每一個站台中負責提供橋接的伺服器（Bridgehead），以提升跨站台之間網域控制站主機複寫的效率。做法很簡單，只要針對選定的伺服器按下滑鼠右鍵，並點選快速選單中的【Properties】，然後在左方的「Transports available for inter-site data transfer」窗格內，把預設採用的「IP」項目新增至右方的窗格內，即可完成設定。結語想要全天候24小時監視Exchange Server的運行，不一定要使用Windows Server或Exchange Server內建的工具，如果想要做法更簡單些，並且讓它幫忙產出更多精美的報表，則可以考慮安裝其他第三方的付費方案，知名的包括PRTG、ManageEngine、SolarWinds等等，而這些解決方案的共同特色就是主動監視Exchange Server的服務狀態、信箱狀態、DAG運行狀態、流量分析，並且在所自定義的閾值到達時，自動發送E-mail警示通知給管理人員。儘管使用這一類的付費工具可以節省不少的人力成本，但IT管理員仍應該優先熟悉並學會使用各種的內建工具，畢竟這些經驗才能夠真正成為自己在技能上的成長，有助於未來在IT生涯的發展上加分。＜本文作者：顧武雄， Microsoft MVP 2004-2016、MCITP與MCTS認證專家、台灣微軟Technet、TechDays、Webcast、MVA特約資深顧問講師、VMware vExpert 2016-217、IBM Unified Communications/Notes/Domino/Connections Certified。＞ 呼叫專業服務機器人！豹小秘神救援零接觸測溫老字號 IT 網管監控神器　大秀自動流程與智慧分析用多雲策略建構災備善用5G三大獨特性　生態系結盟創新模式應用阿里雲推馳雲計劃　為全球中小企提供援助並加快雲端科技應用電子簽名導入區塊鏈　實現最高的資料安全性防疫也防駭！企業遠端工作 4 大重點助持續營運數位鑑識須在不疑處有疑　僅靠靜態分析易陷盲點軟協新任理事長沈柏延上任　力助產業數位轉型兆勤科技聯手 McAfee　打造全面零死角資安解決方案搞懂ICMP協定及工具 抵擋「死亡之Ping」攻擊網路設備入門新手必讀 Cisco IOS最基礎教學建立VLAN邏輯分割網段  詳解交換器Trunk設定人臉辨識拓展金融市場　技術高下實測見分曉NAT穿透技術 從外部直接溝通私有IP路由協定基礎知識入門 詳解路由特性與分類從STP到RSTP　認識多重生成樹協定無類別區隔路由CIDR技術 依需求善用有限IP位址深入了解IP位址與子網路遮罩開源OpenKM文管系統 立即打造知識管理平台第171期2020年4月任意雲端、單一體驗，釋放資料價值之新IT儲存架構解析Dell Technologies儲存創新　引領轉型旅程高階儲存較勁　NVMe全面來襲追蹤我們Featrue us本站使用cookie及相關技術分析來改善使用者體驗。瞭解更多",
        "【防止未授權存取與資料外洩】公有雲區塊儲存的加密功能 ": "目前幾乎所有公有雲服務商，都能為旗下區塊儲存服務提供免費的加密功能，且不會影響存取效能，但用戶仍需注意幾個面向資料來源：iThome除了快照，加密是公有雲區塊儲存服務另一重要的資料服務功能，可以防止區塊磁碟區遭到未授權的存取。目前幾乎所有公有雲服務商，都能為旗下區塊儲存服務提供免費的加密功能，且不會影響存取效能，用戶需注意的重點，包括這幾個面向：● 加密涵蓋的範圍：有些服務商的加密功能，可以涵蓋包括開機系統磁碟區、資料磁碟區與快照在內的所有儲存區（如AWS與Azure），有些則只能加密資料磁碟區與其快照，而不能加密系統磁碟區（如阿里雲）。● 加密技術：所有公有雲服務商的加密功能，都是基於AES 256位元加密技術，這也是當前業界的標準● 靜態加密（Encryption at rest）：加密區塊磁碟區中的靜態資料，這是最基本的加密功能，所有公有雲服務商都能提供。● 傳輸中加密（Encryption in transit）：也就是執行個體/虛擬機器與區塊磁碟區之間傳輸資料時的加密，對於公有雲環境來說，執行個體/虛擬機器與區塊磁碟區是各自獨立，分別位於不同實體環境中，因此，執行個體存取區塊磁碟區時，涉及了一系列傳輸環節與過程，連帶也形成了安全上的隱患，而透過「傳輸中加密」功能，將可防止傳輸過程中的資料外洩。目前除了IBM Cloud以外，其他主要公有雲服務商都為區塊儲存服務，提供了傳輸中加密功能。● 金鑰的管理：公有雲區塊儲存加密功能的金鑰管理，包括由公有雲服務商管理金鑰、用戶自行管理金鑰，以及獨立的金鑰管理服務（Key Management Service，KMS）等3類，目前除IBM Cloud外，其他主要公有雲服務商的區塊儲存加密功能，都能支援這3類金鑰管理方式，有一些服務商自身還能提供專門的KMS托管服務，可以與區塊儲存服務的加密功能相互配合（如AWS的KMS，以及阿里雲的KMS等），簡化用戶的金鑰管理。 相關報導  透視公有雲區塊儲存服務2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "解讀2020企業儲存大趨勢　邊緣核心雲端全面驅動 ": "熱門搜尋 : 熱門搜尋 : 人工智慧、物聯網帶動需求　新型態消費模式引領採購變革 過去一年，企業儲存加速發展腳步，儲存即服務（Storage as a Service）的新型態消費模式開始紮根；更快以及更大容量的快閃儲存陣列不斷推陳出新；因應企業混合雲操作，雲端供應商開始將公有雲搬進企業內部環境；軟體定義儲存需求不斷增長，連帶也推升超融合基礎架構（HCI）增長力道；不少業界專家認為，這些發展中的趨勢都可望在2020年持續發光發熱，除此之外，5G與物聯網（IoT）也將促使邊緣運算（Edge Computing）日益重要，而容器、區塊鏈以及物件儲存都值得在2020年持續加以觀察。NVMe佈局加速HCI拓展邊緣運算有望IDC亞太區資深市場分析師卓莉云便提到，延續2019年的發展，全快閃儲存陣列（AFA）、超融合基礎架構以及NVMe的應用都將持續蓬勃發展。過去有不少企業因每GB的成本價格較高而對全快閃儲存陣列抱以觀望的態度，但是隨著每GB成本的下降，AFA的採用率不斷攀升，不只是金融業、製造業，幾乎各個行業都開始採購，企業已然意識到全快閃儲存陣列可為業務帶來更高的效率、節省電力以及冷卻成本，而這樣的思維也反映在台灣儲存市場的表現上，AFA需求持續成長。在此同時，NVMe也在加速應用中，目前各大品牌業者已推出NVMe Ready的產品，Pure Storage FlashArray//X已全系列就緒，去年Dell也發表PowerMax，最高可達1,000萬IOPS效能，Hitachi Vantara VSP 5000 Series系列已支援NVMe介面，IBM FlashSystem 9100也是一款NVMe儲存系統，顯然愈來愈多的原廠投入，並且將其應用在主流的企業儲存產品之中。由於NVMe的低延遲優勢，預期會用在Tier 0、Tier 1的應用服務，而且會持續地成長。「預期，明年可能會看到更多人工智慧（AI）使用案例，例如製造業希望知道生產線上的運作是否順利，若是能提早發現故障，就能避免停機與材料的浪費；零售業者也會進行資料分析，觀察客戶的消費行為，如果企業希望運用AI來進行推論，全快閃架構也是必要的選項。」卓莉云繼續說明，但這並不意謂企業會捨棄混合式快閃儲存陣列（HFA），對於那些沒有延遲疑慮或非關鍵應用，混合式快閃儲存依然有較好的性價比，若不是非常要求效能，HFA已能滿足需求。另外，超融合基礎架構態勢依舊看好，甚至隱隱已取代部分低階或中階的儲存方案，對於資金不是那麼充裕、IT專業人力較為缺乏的中小企業或新創公司來說，採用HCI不僅容易部署，應用服務也能快速上線。她指出，在歐美市場，HCI很早便應用在邊緣運算市場，這也是未來HCI能擴大的應用領域。「現今企業採用HCI方案多半是為了整合傳統架構環境，但並沒有充份應用HCI的全部效益，目前亞太地區主要都是應用在虛擬化平台、VDI或是資料庫集中化的應用，某個程度來看，這拘束了HCI的市場潛力。」而邊緣運算不只需要存放資料，還需要運算力來處理資料，例如Google Home智慧音箱，使用者詢問問題後就能得到答案便是一個很典型的例子，未來企業將需要更多類似這樣的處理能力，而且這也會遠比企業在邊緣部署NVIDIA解決方案或其他儲存設備更具有成本效益。儲存即服務需求擴大物件儲存重新崛起Pure Storage則認為2020年儲存領域的趨勢包括：儲存即服務的訂閱模式、現代化分析技術將更創新且蓬勃、AI在企業決策中扮演更重要的角色、物件儲存將擺脫既有「冷儲存（Cold Storage）」印象重新崛起、快閃儲存技術將藉由儲存級記憶體及QLC快閃記憶體等固態技術在2020年有所突破，以及容器的應用將在穩定儲存技術支持下成為主流。Pure Storage台灣技術總監何與暉解釋，隨著資料量爆增，企業對於儲存的需求逐漸提升，為了避免投資上的浪費，如何將資源做最有效的運用，是現今企業面臨新增的儲存需求時所遭遇的挑戰。近年來，儲存訂閱式服務的概念興起，使用者開始透過訂閱的方式來取得創新的服務，「隨著雲端服務日漸成熟，企業希望在地端也能擁有雲端依需計價的方便性，但同時兼顧安全性。預期在2020年，這樣的思維也將使儲存即服務的需求增大。」另外，在一般人印象中多半作為歷史資料或者是冷資料存放的物件儲存，將扮演另外一個重要角色－用來儲存雲端服務與應用的相關資料。由於物件儲存能支援大量平行處理，也能作為混合雲的分享池讓應用取得資源以提高效能，包含Splunk以及Vertica，都已將資料存放在物件儲存，以節省成本提高效能。而隨著科技發展，智慧家庭、工業物聯網及車聯網等智能設備的成長，可使用與分析的資料來源大量增加；數位轉型以及AI蓬勃發展，也使得資料分析、應用的需求劇增。在資料量來源、分析應用的需求及規模都急速上升的環境背景下，有更多的基礎架構選擇出現，更多元的分析技術也隨之而生，例如愈來愈多人正在使用不同的開源處理平台，如Apache Flink、Apache Beam和Spark Streaming，以及商業方案如Splunk DSP來取代傳統的資料分析平台，藉由無狀態伺服器、容器以及高效能的S3組成的架構，應付更大量的分析，而且速度將會更快。「全快閃儲存進入市場的時候，就被定位在Tier 1或是以效能為取向的目標市場，隨著儲存級記憶體（Storage Class Memory，SCM）與QLC等新技術加入，未來會各自分工來處理各種應用，以滿足不同的業務需求。在高階儲存的應用方面，結合SCM與NVMe-oF等高速協議，將能夠得到趨近於DAS的架構環境。」他認為，QLC進入儲存市場後，將會對傳統磁碟陣列造成更大的震撼，非常適合針對Tier 2或部份Tier 1應用，除了感受到效能加速外，還能節省資料中心的功耗與樓地板面積。 此外，AI會從諮詢的角色變成主動式的決策，愈來愈多的企業會以開放的心態讓人工智慧進行決策分析，也會用來預測模型以及偵測問題。最後，由於有愈來愈多的應用或核心系統部署在容器上，企業需要一個持續可靠的儲存效能來支持資料庫與應用程式，這在2020年也會是一個關鍵的發展趨勢。邊緣運算與區塊鏈均值得觀察NetApp策略長Atish Gude最近也發佈2020年的儲存趨勢預測，他提到，基礎架構現代化已成企業的巨大壓力，為此，企業組織正從內部環境部署移轉到公有雲服務、建立私有雲，或將資料中心的硬碟存取轉移到快閃儲存，有些組織甚至同步進行上述所有轉型。這些變革雖然開啟了通往無窮潛力的大門，卻也帶來更高的IT複雜度。「預期簡易性和自訂能力的需求，將成為引領IT採購決策最首要的因素。」Atish Gude認為解決方案供應商除了向企業提供靈活的現代化技術，也須讓企業能夠自訂使用與運用這些技術，以滿足不斷演變的商業模式。在IT部門均設法減輕維護與硬體設備成本，並採取隨用隨付的方式以減少例行性開銷之下，簡易性和選擇性將成為考量關鍵。除了採購模式的改變之外，在技術趨勢部份，包含邊緣運算、區塊鏈的發展都不容小覷。Atish Gude首先提到，隨著5G問世，由AI驅動的物聯網得以成真，邊緣運算環境的顛覆性將更甚於雲端技術。為了實現5G無所不在的普及度，必須採用成本更低廉的感測器以及AI應用程式，來打造運算密集的邊緣環境做為營運基礎，這也將帶動許多技術廠商與相關業者投入邊緣運算市場，以實現AI導向物聯網（AIoT）。不過，由AI驅動的物聯網革命需要大量判定邊緣運算任務的優先順序，進而也會顛覆IT基礎架構和資料管理的優先順序。由於邊緣裝置不再侷限於家用設備（例如連網的恆溫空調和音箱），觸及範圍變得更遠（例如連網的太陽能發電廠），更多的資料中心將被建置在邊緣環境，因此也會需要AIOps軟體來監控從邊緣、核心至雲端的複雜環境。另外，Atish Gude也提到了區塊鏈的發展，預期在2020年之後，將引爆更大範圍的實作。「從區塊鏈角度來看，加密貨幣熱潮仍是眾人關注焦點，但產業中多數廠商都瞭解，此技術的發展局勢和應用潛力其實更加廣大深遠，企業將進一步採用無法被竄改的帳本或超級帳本（Hyperledger），這意味著區塊鏈技術更趨成熟，能適用於更多種使用案例。」他預期，區塊鏈將開始變成「主流」，例如用來協助醫療產業建立全面通用的病歷，改善製藥流程等的監管鏈。 呼叫專業服務機器人！豹小秘神救援零接觸測溫老字號 IT 網管監控神器　大秀自動流程與智慧分析用多雲策略建構災備善用5G三大獨特性　生態系結盟創新模式應用阿里雲推馳雲計劃　為全球中小企提供援助並加快雲端科技應用電子簽名導入區塊鏈　實現最高的資料安全性防疫也防駭！企業遠端工作 4 大重點助持續營運數位鑑識須在不疑處有疑　僅靠靜態分析易陷盲點軟協新任理事長沈柏延上任　力助產業數位轉型兆勤科技聯手 McAfee　打造全面零死角資安解決方案搞懂ICMP協定及工具 抵擋「死亡之Ping」攻擊網路設備入門新手必讀 Cisco IOS最基礎教學建立VLAN邏輯分割網段  詳解交換器Trunk設定人臉辨識拓展金融市場　技術高下實測見分曉NAT穿透技術 從外部直接溝通私有IP路由協定基礎知識入門 詳解路由特性與分類從STP到RSTP　認識多重生成樹協定無類別區隔路由CIDR技術 依需求善用有限IP位址深入了解IP位址與子網路遮罩開源OpenKM文管系統 立即打造知識管理平台第171期2020年4月任意雲端、單一體驗，釋放資料價值之新IT儲存架構解析Dell Technologies儲存創新　引領轉型旅程高階儲存較勁　NVMe全面來襲追蹤我們Featrue us本站使用cookie及相關技術分析來改善使用者體驗。瞭解更多",
        "Google Compute Engine用戶現可用機器映像檔創建執行個體 ": "機器映像檔與普通映像檔不一樣的地方在於，機器映像可儲存多個磁碟內容，並儲存創建執行個體所有需要的資料Google現在提供用戶以機器映像檔（Machine Image），更方便地創建Compute Engine執行個體。機器映像檔是一個新型態的Compute Engine資源，其中包含了創建、備份和還原虛擬機器所需要的所有資訊，可有效減少用戶管理環境的時間。Google提到，即便用戶花了許多時間建立用來創建新執行個體的映像檔，其中也包含了磁碟資料等各種重要資訊，但是用戶仍要手動擷取執行個體配置和元資料，來創建新的虛擬機器，不過，利用機器映像檔便能消除這些額外的步驟。機器映像檔與一般映像檔的不同之處，在於機器映像檔包含了更全面的資源。一般映像檔中只含有單一磁碟的內容，像是含有啟動磁碟內容的映像檔，便可以用來創建預配置應用程式的磁碟。而機器映像檔則可以包含多個磁碟，以及所有創建新執行個體需要的資訊，包括執行個體屬性、所有附加的磁碟、執行個體的元資料，以及用來創建執行個體的服務帳戶權限。機器映像檔中包含額外的資訊，不只能簡化了映像檔創建工作，同時也為進階功能提供了基礎。Google提到，備份執行個體不僅是備份磁碟資料，由於需要重新創建執行個體，因此還要機器類型和網路標籤等執行個體屬性，而機器映像檔能夠更簡單地擷取這些資訊。從執行個體創建機器映像檔時，系統會將映像檔資訊和磁碟資料儲存在單個資源中，而當用戶需要恢復執行個體時，用戶僅需要提供機器映像檔以及新的執行個體名稱就可以了。除了儲存完整的執行個體屬性和資料之外，機器映像檔還使用建構在增量快照（Incremental Snapshot）上的備份技術，可快速且有效率地備份執行個體。Google表示，機器映像檔可讓用戶啟動需要的執行個體數量，而且以來源執行個體完全相同的方式進行配置，或是用戶也能與其他專案共享機器映像檔，當需要變更虛擬機器的屬性，則可以使用機器映像檔覆寫功能修改。Compute Engine可讓用戶指定機器映像檔的儲存位置，以符合企業的可用性與法遵目標。2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "【提供靈活的磁碟複本應用】公有雲區塊儲存的快照與備份功能 ": "快照雖然是一項很成熟的儲存技術，但目前各公有雲服務商區塊儲存的快照功能，在架構與功能上仍存在相當大的差異，需要注意這幾個面向資料來源：iThome整理，2020年1月如同傳統儲存陣列平臺，公有雲的區塊儲存平臺也提供了一系列資料服務功能，來為磁碟區提供加值應用，其中最重要的資料服務功能，便是快照（snapshot）。快照可以為磁碟區擷取特定時間下完全一致的唯讀複本，從而提供這4個面向的應用：（1）做為災難備援，以快照複本做為備份，當原始磁碟區資料遺失或損毀時，利用快照還原磁碟區資料內容。（2）用於資料歸檔或備份，長期保存磁碟區資料內容。（3）用於資料遷移，在多個服務區域之間移動磁碟區資料。（4）用於資料複製，透過快照快速產生多個原始磁碟區複本，而公有雲區塊儲存服務提供的快照功能，屬於儲存端的快照，不會影響到前端執行個體或虛擬機器的效能。快照雖然是一項很成熟的儲存技術，但目前各公有雲服務商區塊儲存的快照功能，在架構與功能上仍存在相當大的差異，需要注意這幾個面向：● 快照份數限制：所有服務商都會限制快照的份數，但有些服務商是以帳號來限定快照份數，也就是某個服務區域內的某個帳號下，最多允許保存某個數量的快照（如AWS EBS、Azure與Oracle）；另一些服務商則是以磁碟區來限定快照份數，如一個磁碟區最多允許保存多少份快照（如IBM與阿里雲）。● 快照的儲存方式：也就是快照存放的位置，以及快照的儲存是否具備冗餘性（redundancy）。多數公有雲區塊儲存服務的快照複本，也是存放在區塊儲存服務自身的儲存區域內，但AWS EBS與Oralce Block Volume Service則不然，是將快照另外存放於物件儲存服務空間內（如AWS EBS的快照是存放於S3），以減少快照耗用的儲存成本（區塊儲存空間的成本一般略高於物件儲存空間）。而在快照儲存的冗餘性方面，有些服務商（如AWS、Azure與Google Cloud）會將快照以多區域方式存放，讓快照複本具備更高的可用性。● 快照的存取：一般來說，快照必須掛載到執行個體上成為磁碟區，才能讀取其中的資料，不過，AWS提供了稱作EBS Direct APIs for Snapshots的工具，可以讓用戶直接讀取位於S3儲存區中的快照複本，而無須將快照掛載起來，顯著提高了使用快照的便利性與靈活性。● 是否支援增量式（Incremental）快照：多數公有服務商的快照功能都是增量式的，除了第一次快照為完整的複製外，後續快照都只會記錄異動的資料，從而大幅減少快照耗用的儲存空間資源。不過Azure的快照仍是完整的磁碟複製，一直到2019年中，才開始在部份地區提供預覽版的增量式快照，使用方式上也和Azure原有的快照有所差異。● 快照加密：多數服務商都提供快照加密，原則上，只要來源端磁碟是加密的，那麼其快照複本也是加密的。● 快照的跨區域遠端複製：部份服務商提供將快照複製到另一區域的功能（包括AWS、Azure、Google Cloud與Oracle Cloud），可藉此提供資料遷移或異地備援應用，利用將快照遠端複製到另一區域，便能在另一區域建立相同的磁碟區，構成簡單的資料擴展或異地備援應用。● 快照的共享：一般情況下，只有同一帳號的用戶能存取快照複本，不過，AWS與Google提供了在不同帳號間共享快照的特殊功能。用戶可以將快照複本授權給另一帳號的用戶存取，從而讓其他用戶可以依據快照複本建立相同的磁碟區，而不會影響原始磁碟區，藉此提供簡便的資料分享手段。集中備份管理的需求與解決方案原則上，公有雲區塊儲存服務內含的快照功能，搭配快照複本的多地區存放，以及跨區域的複製功能，快照即可扮演備份的角色，無需另外使用備份產品（Oracle Cloud便直接以備份一詞，來指稱其區塊儲存的快照功能）。問題在於，區塊儲存的快照功能只能涵蓋自身的區塊磁碟區，若用戶的公有雲應用環境，同時涉及不同類型的儲存服務（區塊、物件等）或應用軟體服務，而這些服務各有各的快照與保護功能，用戶使用上十分複雜，還是需要統一的管理工具，來集中管理這些不同服務的備份。針對統合公有雲上不同應用服務的備份需求，AWS與Azure兩大服務商，都提供了專門的集中備份管理工具，也就是AWS Backup與Azure Backup。其中AWS Backup，是AWS環境的備份應用集中管理平臺，可以將不同AWS服務各自既有的快照與備份功能，統合在單一管理介面下，包括EBS區塊儲存服務的快照、Storage Gateway的磁碟區快照，以及RDS資料庫與DynamoDB資料庫快照等，並為EFS提供備份功能。透過AWS Backup主控臺即可設定自動化的備份政策，免除手動指令的需求。特別的是，由於AWS Backup也支援Storage Gateway掛載到用戶本地端的磁碟區，用戶可藉此將本地端資料備份到雲端，構成混合雲的備份應用。Azure Backup則是Azure內含的備份軟體功能，屬於VM端的備份工具，能支援Azure自身的VM，或安裝了MARS代理程式的用戶端實體主機與Windows VM，提供整臺VM、或檔案、資料夾與系統屬性的備份，可選擇LRS本地備援儲存體或GRS異地備援儲存體，來作為備份儲存區。 相關報導  透視公有雲區塊儲存服務2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29",
        "【雲端儲存服務：Pure Storage CBS】雲端區塊儲存服務新選擇，提供堅實的多重高可用性架構設計 ": "FlashArray快閃儲存陣列移植AWS的雲端化版本，完整支援Pure Storage平臺架構與功能等待了近1年時間後，Pure Storage的雲端區塊儲存服務——Cloud Block Store（CBS），終於在去年底（2019）正式上線。過去一年多以來，Pure Storage在整合公有雲平臺方面動作連連，於2018年底宣布了稱作「Pure Storage Cloud Data Services」的一系列雲端儲存服務，而CBS便是其中之一。CBS是當前興起中的新類型儲存產品——「雲端儲存陣列」的一員。這種產品的本質，其實就是傳統儲存陣列廠商將其儲存陣列系統移植到公有雲上，成為「雲端化」儲存陣列而成，透過公有雲平臺來提供儲存空間服務。而CBS便是Pure Storage將旗下的FlashArray全快閃儲存陣列，移植到AWS公有雲平臺上的產品，可在AWS上提供基於iSCSI的區塊儲存空間服務，目前有10TB、20TB與50TB等3種容量授權可選，並憑藉著與FlashArray儲存陣列相同的Purity//FA儲存作業系統，具備了Thin Provisioning、壓縮與重複資料刪除等進階功能。目前CBS雖然只支援AWS平臺，但依照Pure Storage的規畫，日後也將在Azure與Google Cloud上推出相同的服務。CBS是Pure Storage FlashArray全快閃儲存陣列，移植到AWS而成的雲端化儲存陣列，可在AWS上提供基於Pure Storage儲存系統的區塊儲存服務，並含有完整的資料服務功能。雲端化的儲存陣列公有雲服務的盛行已是大勢所趨，傳統儲存陣列廠商面對這個新興威脅，一個出路便是「打不過他，就加入他」，把自身的儲存陣列平臺移植到公有雲平臺上。公有雲服務商雖然自身提供了原生的儲存服務，但老牌的儲存陣列平臺，有著用戶熟悉、系統成熟、資料服務功能豐富完整的優點，而移植到公有雲以後，不僅保有儲存陣列原本的優點，還能兼有雲端服務的維運負擔輕、按需訂購彈性等優點。以CBS來說，相較於AWS自身原生的兩種區塊儲存服務——執行個體儲存空間（Instance Stores），以及EBS（Elastic Block Store），目的同樣都是提供區塊儲存服務，但能提供後兩者沒有的豐富資料服務功能。AWS執行個體儲存空間，是一種執行個體直連的本地端儲存空間，有硬碟、SAS SSD與NVMe SSD等型式，具備低延遲的特點，但組態固定，缺乏彈性，也沒有因應磁碟裝置故障的冗餘能力。至於EBS儲存區，則有著類型選擇豐富（有io1、gp2、st1與sc1等4種）、組態彈性（500GB～16TB），以及透過分散複制機制所提供的高可用性，還具備基本的資料服務功能（快照與加密）。而CBS實際上是建立在前兩者的基礎上——以EBS的io1儲存區作為NVRAM寫入緩衝角色，以執行個體本機的NVMe SSD作為讀取快取與寫入儲存區，再結合S3物件儲存作為備援的持久儲存區，並能透過Pure Storage的ActiveCluster複製功能，跨不同AWS可用區域（AZ）建立異地的高可用性CBS群組，兼具了效能與可靠性。更重要的是，CBS還能憑藉Pure Storage自身專屬的Purity//FA儲存平臺，提供目前AWS原生儲存服務還沒有的即時壓縮、重複資料刪除等資料縮減功能，藉此改善儲存空間耗用經濟性。因此CBS這類雲端儲存陣列產品的問世，也讓用戶在公有雲上的應用，除了使用各公有雲自身原生的儲存服務外，也多了Pure Storage這些第三方廠商的解決方案，各自基於專屬儲存平臺，提供了公有雲儲存服務新選擇。獨具一格的雲端部署架構如前所述，CBS這類雲端儲存陣列產品，是將傳統儲存陣列平臺移植到公有雲環境而成，從而為公有雲上的運算單元，提供基於傳統儲存陣列平臺的儲存空間服務。而要實現這樣的目的，關鍵便在於如何讓傳統儲存陣列平臺「移植」部署到雲端環境，從而化身為公有雲上的儲存服務。將儲存陣列移植到公有雲上的方式，主要分為兩種。一種方式為實體部署，也就是在公有雲服務商資料中心部署實體儲存設備。例如NetApp的Cloud Volumes Service（CVS）、HPE的Cloud Volumes，都屬於這種類型。另一種方式為軟體定義部署，也就是利用公有雲的執行個體與儲存空間，來運行儲存陣列系統軟體。如NetApp的Cloud Volumes ONTAP（CVO）、Dell EMC的UnityVSA Cloud Edition，以及我們這裡介紹的Pure Storage CBS，都屬於這種類型。不過，即使同樣屬於軟體定義部署，但個別產品的實作方式也大相逕庭，而CBS可說是最特別的一種。NetApp CVO算是軟體定義部署式雲端儲存陣列的標準範本，使用1臺雲端運算單元來運行NetApp的ONTAP系統，擔任儲存控制器角色，並掛載公有雲的區塊儲存區來作為儲存空間。為了提高可用性，還可將2臺CVO組成高可用性群組。而CBS則動用了AWS的EC2執行個體、執行個體本機儲存區、EBS區塊儲存區，以及S3物件儲存區，來扮演儲存控制器、寫入緩衝、讀取快取等角色，每套CBS單元至少需耗用9臺或16臺執行個體（2臺用於控制器，7或14臺用於虛擬磁碟）、7個EBS服務的區塊磁碟區，與一定容量的S3儲存區。雖然CBS耗用的資源相對較大，成本相對也較高，但藉此在AWS上再現了FlashArray全快閃儲存陣列的架構，理應更能保證效能與可用性，以因應Tier1的關鍵應用儲存需求。靈活的混合雲應用方式CBS這類雲端儲存陣列，除了能為公有雲的儲存服務，提供基於第3方儲存廠商平臺的新選擇外，另一個重點是能結合用戶的本地端儲存設備，構成高度整合的混合雲架構。以CBS來說，便能與用戶本地端的FlashArray儲存陣列，構成緊密的混合雲應用架構。CBS與FlashArray的核心，同樣都是基於Purity//FA作業系統，因此可以相互連結，構成異地備援，在儲存服務這一層級，直接透過磁碟區的遠端複製，在本地端FlashArray與雲端的CBS之間，交換或遷移資料。另外，CBS也能結合Pure Storage的CloudSnap雲端快照儲存服務，提供經濟的混合雲應用。用戶平時可將本地端FlashArray的資料。透過CloudSnap上傳到S3儲存空間保存，待需要異地備援時，再訂購與啟用CBS，然後於CBS上掛載CloudSnap在S3保存的本地端FlashArray快照，便能迅速完成CBS與本地端間的站點資料同步。 Cloud Block Store的版本與規格 在AWS環境中運行的CBS雲端儲存陣列，是以AWS的資源架構而成，分別使用EC2的c5n與i3執行個體，以及EBS的io1區塊儲存區，來分別扮演儲存控制器、Flash儲存模組、讀取快取，以及NVRAM模組等角色。Pure Storage提出了兩種CBS組成規格——CBS //V10A-R1與CBS //V20A-R1，分別採用不同等級的EC2執行個體與EBS io1儲存區。其中較低階的CBS //V10A-R1，Pure Storage建議使用2臺c5n.9xlarge執行個體來作為儲存控制器，搭配作為虛擬磁碟機的7或14臺i3.2xlarge執行個體，再加上作為NVRAM的7個60GB EBS io1磁碟區。其中，作為控制器的c5n.9xlarge執行個體，可提供50Gbps的總網路頻寬，每個連接埠的頻寬為5Gbps，整個系統則可提供13.8TB～15.2TB的可用容量。至於較高階的CBS //V20A-R1，控制器是使用2臺規格更高的c5n.18xlarge執行個體來擔任，搭配作為虛擬磁碟機的7或14臺i3.4xlarge執行個體，或是7臺i3.8xlarge執行個體，加上作為NVRAM的7個120GB EBS io1磁碟區。其中，作為控制器的c5n.18xlarge執行個體，可提供100Gbps的總網路頻寬，每個連接埠的頻寬為5Gbps，整個系統能提供55.2TB～60.8TB的可用容量。CBS使用的執行個體規格Pure Storage建議用於扮演CBS儲存控制器角色的兩種執行個體——c5n.9xlarge與c5n.18xlarge，都屬於c5n系列運算優化型執行個體，是EC2服務中針對HPC、資料湖等應用，特別強調運算能力與網路傳輸頻寬的執行個體，基於3 GHz的Intel Xeon Platinum 處理器，分別可提供36個與72個vCPU、96GB與192GB記憶體，以及50Gbps與100Gbps傳輸頻寬，可保證CBS的I/O效能，並因應資料刪減相關功能帶來的運算負荷。而CBS用於擔任虛擬磁碟機角色的3種執行個體——i3.2xlarge、i3.4xlarge與i3.8xlarge，則屬於i3系列儲存優化執行個體，特別強調本機儲存能力，均配置了直連的NVMe SSD，但處理器規格與網路頻寬相對較低（10Gbps以下） 。另外Pure Storage還建議，用戶在訂購供CBS使用的執行個體時（包含控制器與虛擬磁碟），選用可轉換型式的預留執行個體（Convertible Reserve Instance），而非標準預留執行個體（Standard Reserve Instance），以便運用可轉換預留執行個體便於變更屬性的特性，在日後升級為更高階的執行個體。 Cloud Block Store的訂閱形式 如同多數的公有雲服務產品，CBS的訂購方式，也分為公有雲服務商與儲存廠商等兩個來源。「Pure as-a-Service」服務是一種混合雲的授權，在「Pure Storage ES2」採購項目下，提供了在1年（以上）合約期限內，100TB容量起跳的混合雲使用空間授權（雲端CBS＋本地端FlashArray），用戶從這裡取得CBS的授權後，再到AWS市集中的「Cloud Block Store - Product Deployment」訂閱項目下完成部署。更單純的方式，是直接從AWS的市集訂閱CBS服務，先在「Cloud Block Store」訂閱項目下，購買使用空間授權，然後再到「Cloud Block Store - Product Deployment」項目下完成部署。AWS提供了4種等級的CBS授權——Small、Medium、Large與按使用量計價的Pay-as-you-go。其中Small等級授權的預留容量上限是10TB，Medium等級是20TB，Large等級為50TB，訂閱期限有1個月或12個月兩種可選。比較特別的是Pay-as-you-go授權，適合想要體驗CBS的用戶，這種模式不需要一次購買定量的空間，頭1個月10TB內不收取費用，從第2個月起，再按每單位每GB來計價，訂閱期限以1個月為基準。除了前述4種等級的容量授權費用外，CBS還有基本設定費（Basic Setup）、超過預留容量上限的超量（Overage） 使用費，以及加值服務費（Professional services）等額外費用。其中，加值服務是一系列幫助用戶部署CBS的諮詢與協助服務，包含初期的需求評估、部署前準備、部署作業執行、部署後作業等服務，同時，又分為基本加值服務（Basic Professional services），以及進階加值服務（Advanced Professional services），而前述的基本設定（Basic Setup）費用所對應的部份，就等於這裡所提及的基本加值服務。Cloud Block Store 的採購模式用戶可透過Pure Storage的「Pure as-a-Service」服務，或直接從AWS市集訂閱CBS的授權，前者可提供較長的訂閱期限（1～3年），後者則提供較靈活的按月訂閱與1年期訂閱。圖片來源／Pure StorageCloud Block Store 的採購層級CBS的授權以容量作為層級區分基準，分為Small（10TB）、Medium（20TB）與Large（50TB），再加上按使用量計價的Pay-as-you-go等4種層級。圖片來源／AWS Cloud Block Store系統管理與軟體功能 由於CBS是FlashArray儲存陣列移植AWS的「雲端化」版本，核心相同，所以，系統管理方式與軟體功能，基本上，也是與Pure Storage自家的FlashArray儲存陣列相同。在系統管理方面，如同本地端的FlashArray儲存陣列，CBS也是透過自身內含的網頁控制臺，來進行基本的監控與設定作業，管理介面與FlashArray完全一致。除此之外，用戶還能利用Pure Storage的Pure 1雲端AI管理平臺來管理CBS，包括從雲端集中監控CBS的運行，以及使用Pure 1的效能分析、資源耗用預測等功能，來檢核與預估CBS系統的使用情況。在軟體方面，CBS運行的是FlashArray的作業系統Purity//FA的修改版本，僅有核心的部份稍微不同，同時，也擁有FlashArray幾乎全部的軟體功能，只有下列2項不提供——Purity//RUN與Windows File Services（WFS）。其中的Purity//RUN是一項輕量的虛擬化功能，可以透過Container或VM的形式，使用部份控制器處理器與記憶體資源來執行用戶需要的應用功能。而WFS則是架構在Purity//RUN上的服務，可以運行CIFS/SMB與NFS等檔案服務，讓FlashArray扮演NAS的角色。由於目前Pure Storage將CBS定位於專門提供區塊儲存服務（從產品名稱即清楚表明），因而不提供前述兩項附加功能。CBS的網頁控制臺如同本地端的FlashArray儲存陣列，雲端上的CBS也提供了相同的網頁式控制臺，管理者可藉此執行基本的系統管理與設定工作，包括磁碟區設定、磁碟區掛載、系統運行監控等基本管理功能，以及快照、遠端複製等進階資料服務功能，無論操作介面還是操作方式，都與FlashArray儲存陣列的網頁控制臺一致。透過Pure 1雲端平臺管理CBS用戶也能透過Pure Storage的Pure 1雲端AI管理平臺，從遠端監控CBS的運行，並使用效能分析、資源耗用預測等功能。圖片來源／Pure Storage Cloud Block Store的運作架構 我們可將CBS這款產品，視為Pure Storage將FlashArray快閃儲存陣列，移植到AWS平臺的「雲端化」版本。FlashArray儲存陣列的軟體，是以Pure Storage專屬的Purity//FA儲存作業系統為核心；硬體部份，則由內含控制器、NVRAM與Flash儲存模組的Base機箱，加上外接的擴充儲存櫃組成。每臺FlashArray儲存陣列，含有這4種主要元件：● 控制器：負責運行Purity//FA儲存作業系統，以及提供前、後端I/O介面，每臺Base機箱含有2組控制器，構成Active—Standby的高可用性架構。● NVRAM模組：NVRAM模組由DRAM、備份用Flash模組與供電用的超級電容組成，目的是為寫入I/O提供一個高效能、且能預防斷電的緩衝儲存區。每臺Base機箱最多可以安裝4組NVRAM模組，並且以互為備援的方式，透過NVMe介面兩兩配置給2組控制器使用。● 讀取快取記憶體：FlashArray陣列的讀取快取記憶體可分為兩種——控制器內含的DRAM，以及控制器外的DMM模組。受限於容量與成本，控制器內含的DRAM，主要用於metadata的讀取快取，至於一般資料的讀取I/O，則主要是直接從底層的Flash儲存模組來讀取，因此也導致較大的延遲。不過，Pure Storage在2019年9月，推出基於Intel Optane儲存級記憶體的DMM模組（DirectMemory Modules），專用於讀取I/O的快取，安裝在Flash模組磁碟槽中，配置給控制器使用，藉此可讓讀取延遲獲得5倍的改善，但目前只有少數FlashArray//X系列支援DMM模組。● Flash儲存模組：包括SAS介面的SSD，或NVMe介面的DFM模組（DirectFlash Modules）兩種，以10個模組的10 module pack為基本單位。而到了CBS，Pure Storage為了在AWS環境，「重現」FlashArray儲存陣列的架構及系統功能，使用AWS EC2、EBS與S3的資源，組成CBS的「控制器」與「虛擬磁碟機」等2種元件，進而扮演儲存控制器、NVRAM、讀取快取與Flash儲存模組等角色。CBS的控制器CBS使用2臺AWS EC2 c5n執行個體，來擔任FlashArray儲存陣列的兩組控制器角色。每臺c5n擁有總頻寬50Gbps或100Gbps的網路介面，可兼用於系統管理或iSCSI傳輸連接。CBS的虛擬磁碟CBS使用獨立的AWS EC2的i3執行個體，以此構成了稱作「虛擬磁碟機（Virtual Drive）」的儲存單元，並同時扮演了Flash儲存模組、NVRAM模組與讀取快取記憶體等3個角色，這種充當虛擬磁碟機的i3執行個體，後端都掛載了3種儲存裝置：（1）i3執行個體內含直連的1～3臺NVMe SSD本機磁碟。（2）EBS區塊儲存服務掛載的io1磁碟區。（3）S3物件儲存區（標準型）。i3執行個體直連的NVMe SSD，擁有低延遲與高頻寬，被CBS用於讀取快取記憶體，以及寫入資料的儲存區等兩種角色。不過，這屬於沒有冗餘能力的Instance Store空間，可靠性不足，對於讀取快取角色來說，即使失效，也只會損及讀取效能而已，但若做為資料寫入儲存區，一旦失效，便會影響資料的完整性。因此，CBS為虛擬磁碟提供多重冗餘的保護。至於用於承接寫入I/O的NVRAM角色，CBS使用EBS區塊儲存服務的io1儲存區來承擔。io1是EBS的高效能型SSD儲存服務，擁有EBS的高可用性架構，足以扛起NVRAM的重責大任。而S3物件儲存空間，則被CBS用作資料寫入資料的備援用保存區。當虛擬磁碟正常運作時，所有讀寫I/O都是在虛擬磁碟這一層級完成，但若虛擬磁碟完全失效，用戶可從S3儲存區取回資料。S3的低成本與極高耐久性，十分適合作為持久儲存區使用。而且S3是獨立的空間，即使CBS控制器與虛擬磁碟完全失效，也不會影響S3儲存區資料，提供了最後一層的保障。CBS的運作與保護機制運作時，作為虛擬磁碟機的i3執行個體，分別透過EBS io1儲存區與本機NVMe SSD，扮演寫入緩衝與讀取快取角色，寫入資料則由NVMe SSD保存，同時虛擬磁碟還會將寫入資料複製一份，送到最後端的S3物件儲存區，作為備援保存之用。為了提高整個架構的可用性，CBS各個環節都採用了多重配置。在儲存控制器層級，採用雙控制器組態，單一控制器失效不會影響CBS服務；在虛擬磁碟機層級，CBS基本組態使用7臺i3執行個體，也就是7臺虛擬磁碟機，構成具備失效冗餘能力的虛擬儲存櫃（Virtual Shelf），在作為控制器的c5n執行個體管理下，任何擔任虛擬磁碟機的i3執行個體失效，可由群組中其他i3執行個體備援，而整個群組的冗餘能力，可容許2臺虛擬磁碟機（i3執行個體）失效。CBS最大能組成含有14臺虛擬磁碟機的儲存群組，但其中只有前7臺虛擬磁碟機，會掛載作為NVRAM的io1儲存區。更進一步，即使有3臺以上的虛擬磁碟失效，導致CBS服務終止，用戶也還能從後端的S3儲存區取回資料。如果用戶需要更高的可用性，還可在兩個以上AZ服務區建立CBS，再利用ActiveCluster功能同步資料，達到兩地雙中心的高可用性架構。同時，他們也可透過非同步複製，將第二地AZ作為異地備援中心。Cloud Block Store vs. FlashArray儲存陣列架構對照CBS使用了AWS的EC2、EBS與S3等雲端服務資源，於AWS環境「重構」出FlashArray全快閃儲存陣列的架構與功能。首先，由2臺EC2的c5n執行個體，扮演FlashArray陣列的雙控制器角色；接著，以EC2 i3執行個體構成虛擬磁碟機（Virtual Drive），由7臺虛擬磁碟機組成具備冗餘能力的虛擬儲存櫃（Virtual Shelf），可容許2臺虛擬磁碟失效。而這些虛擬磁碟機單元還連接了EBS io1儲存區與本機NVMe SSD，分別用於NVRAM寫入緩衝區、讀取快取記憶體與資料寫入儲存區。 產品資訊［規格與售價時有異動，正確資訊請洽廠商］Pure Storage CBS●原廠：Pure Storage●建議售價：Small級（10TB，每月1800美元，每年18000美元），Medium級（20TB，每月3000美元，每年30000美元），Large級（50TB，每月6000美元，每年60000美元），Pay-as-you-go（首月10TB內免費，自第2個月起，每單元、每月、每GB 0.2美元）●適用平臺：AWS●支援傳輸協定：iSCSI2020-04-282020-04-272020-04-282020-04-292020-04-282020-04-282020-04-282020-04-272020-04-272020-04-29"
    }
}